{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gdown 'https://drive.google.com/uc?id=10f3jNWltQyham_ebppXWfmyMftcFm8KS' -O '/home/crueang/Chaks/AIOT_project/data/office-31.zip'\n",
    "# !unzip '/home/crueang/Chaks/AIOT_project/data/Office-31.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = '/home/crueang/Chaks/AIOT_project/data/Office-31'\n",
    "HOME = '/home/crueang/Chaks/AIOT_project'\n",
    "\n",
    "NUM_CLASSES = 31\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['back_pack', 'bike', 'bike_helmet', 'bookcase', 'bottle', 'calculator', 'desk_chair', 'desk_lamp', 'desktop_computer', 'file_cabinet', 'headphones', 'keyboard', 'laptop_computer', 'letter_tray', 'mobile_phone', 'monitor', 'mouse', 'mug', 'paper_notebook', 'pen', 'phone', 'printer', 'projector', 'punchers', 'ring_binder', 'ruler', 'scissors', 'speaker', 'stapler', 'tape_dispenser', 'trash_can']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.models import mobilenet_v3_large, mobilenet_v3_small\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    torchvision.models.MobileNet_V3_Small_Weights.IMAGENET1K_V1.transforms(),\n",
    "])\n",
    "\n",
    "amazon_dataset = ImageFolder(root=f'{DATASET_DIR}/amazon', transform=transform)\n",
    "dslr_dataset = ImageFolder(root=f'{DATASET_DIR}/dslr', transform=transform)\n",
    "webcam_dataset = ImageFolder(root=f'{DATASET_DIR}/webcam', transform=transform)\n",
    "\n",
    "classes = webcam_dataset.classes\n",
    "\n",
    "\n",
    "data_loader = DataLoader(amazon_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "print(classes)\n",
    "\n",
    "# source_dataset, target_dataset, test_dataset = random_split(labeled_dataset, [1850, 1850, 410])\n",
    "\n",
    "# print(len(source_dataset), len(target_dataset), len(test_dataset))\n",
    "\n",
    "# Dl_source = DataLoader(source_dataset, BATCH_SIZE, shuffle=True)\n",
    "# Dl_target = DataLoader(target_dataset, BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title FLOPS computation\n",
    "# Code from https://github.com/Eric-mingjie/rethinking-network-pruning/blob/master/imagenet/l1-norm-pruning/compute_flops.py\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def print_model_param_nums(model=None):\n",
    "    if model == None:\n",
    "        model = torchvision.models.alexnet()\n",
    "    total = sum([param.nelement() if param.requires_grad else 0 for param in model.parameters()])\n",
    "    print('  + Number of params: %.4fM' % (total / 1e6))\n",
    "\n",
    "def count_model_param_flops(model=None, input_res=224, multiply_adds=True, device='cpu'):\n",
    "\n",
    "    prods = {}\n",
    "    def save_hook(name):\n",
    "        def hook_per(self, input, output):\n",
    "            prods[name] = np.prod(input[0].shape)\n",
    "        return hook_per\n",
    "\n",
    "    list_1=[]\n",
    "    def simple_hook(self, input, output):\n",
    "        list_1.append(np.prod(input[0].shape))\n",
    "    list_2={}\n",
    "    def simple_hook2(self, input, output):\n",
    "        list_2['names'] = np.prod(input[0].shape)\n",
    "\n",
    "\n",
    "    list_conv=[]\n",
    "    def conv_hook(self, input, output):\n",
    "        batch_size, input_channels, input_height, input_width = input[0].size()\n",
    "        output_channels, output_height, output_width = output[0].size()\n",
    "\n",
    "        kernel_ops = self.kernel_size[0] * self.kernel_size[1] * (self.in_channels / self.groups)\n",
    "        bias_ops = 1 if self.bias is not None else 0\n",
    "\n",
    "        params = output_channels * (kernel_ops + bias_ops)\n",
    "        # flops = (kernel_ops * (2 if multiply_adds else 1) + bias_ops) * output_channels * output_height * output_width * batch_size\n",
    "\n",
    "        num_weight_params = (self.weight.data != 0).float().sum()\n",
    "        flops = (num_weight_params * (2 if multiply_adds else 1) + bias_ops * output_channels) * output_height * output_width * batch_size\n",
    "\n",
    "        list_conv.append(flops)\n",
    "\n",
    "    list_linear=[]\n",
    "    def linear_hook(self, input, output):\n",
    "        batch_size = input[0].size(0) if input[0].dim() == 2 else 1\n",
    "\n",
    "        weight_ops = self.weight.nelement() * (2 if multiply_adds else 1)\n",
    "        bias_ops = self.bias.nelement()\n",
    "\n",
    "        flops = batch_size * (weight_ops + bias_ops)\n",
    "        list_linear.append(flops)\n",
    "\n",
    "    list_bn=[]\n",
    "    def bn_hook(self, input, output):\n",
    "        list_bn.append(input[0].nelement() * 2)\n",
    "\n",
    "    list_relu=[]\n",
    "    def relu_hook(self, input, output):\n",
    "        list_relu.append(input[0].nelement())\n",
    "\n",
    "    list_pooling=[]\n",
    "    def pooling_hook(self, input, output):\n",
    "        batch_size, input_channels, input_height, input_width = input[0].size()\n",
    "        output_channels, output_height, output_width = output[0].size()\n",
    "\n",
    "        kernel_ops = self.kernel_size * self.kernel_size\n",
    "        bias_ops = 0\n",
    "        params = 0\n",
    "        flops = (kernel_ops + bias_ops) * output_channels * output_height * output_width * batch_size\n",
    "\n",
    "        list_pooling.append(flops)\n",
    "\n",
    "    list_upsample=[]\n",
    "\n",
    "    # For bilinear upsample\n",
    "    def upsample_hook(self, input, output):\n",
    "        batch_size, input_channels, input_height, input_width = input[0].size()\n",
    "        output_channels, output_height, output_width = output[0].size()\n",
    "\n",
    "        flops = output_height * output_width * output_channels * batch_size * 12\n",
    "        list_upsample.append(flops)\n",
    "\n",
    "    def foo(net):\n",
    "        childrens = list(net.children())\n",
    "        if not childrens:\n",
    "            if isinstance(net, torch.nn.Conv2d):\n",
    "                net.register_forward_hook(conv_hook)\n",
    "            if isinstance(net, torch.nn.Linear):\n",
    "                net.register_forward_hook(linear_hook)\n",
    "            if isinstance(net, torch.nn.BatchNorm2d):\n",
    "                net.register_forward_hook(bn_hook)\n",
    "            if isinstance(net, torch.nn.ReLU):\n",
    "                net.register_forward_hook(relu_hook)\n",
    "            if isinstance(net, torch.nn.MaxPool2d) or isinstance(net, torch.nn.AvgPool2d):\n",
    "                net.register_forward_hook(pooling_hook)\n",
    "            if isinstance(net, torch.nn.Upsample):\n",
    "                net.register_forward_hook(upsample_hook)\n",
    "            return\n",
    "        for c in childrens:\n",
    "            foo(c)\n",
    "\n",
    "    if model == None:\n",
    "        model = torchvision.models.alexnet()\n",
    "    foo(model)\n",
    "    input = Variable(torch.rand(3,input_res,input_res).unsqueeze(0), requires_grad = True).to(device)\n",
    "    out = model(input)\n",
    "\n",
    "\n",
    "    total_flops = (sum(list_conv) + sum(list_linear) + sum(list_bn) + sum(list_relu) + sum(list_pooling) + sum(list_upsample))\n",
    "\n",
    "    print('Number of FLOPs: %.6f GFLOPs (%.2f MFLOPs)' % (total_flops / 1e9, total_flops / 1e6))\n",
    "\n",
    "    return total_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 112, 112]             432\n",
      "       BatchNorm2d-2         [-1, 16, 112, 112]              32\n",
      "         Hardswish-3         [-1, 16, 112, 112]               0\n",
      "            Conv2d-4           [-1, 16, 56, 56]             144\n",
      "       BatchNorm2d-5           [-1, 16, 56, 56]              32\n",
      "              ReLU-6           [-1, 16, 56, 56]               0\n",
      " AdaptiveAvgPool2d-7             [-1, 16, 1, 1]               0\n",
      "            Conv2d-8              [-1, 8, 1, 1]             136\n",
      "              ReLU-9              [-1, 8, 1, 1]               0\n",
      "           Conv2d-10             [-1, 16, 1, 1]             144\n",
      "      Hardsigmoid-11             [-1, 16, 1, 1]               0\n",
      "SqueezeExcitation-12           [-1, 16, 56, 56]               0\n",
      "           Conv2d-13           [-1, 16, 56, 56]             256\n",
      "      BatchNorm2d-14           [-1, 16, 56, 56]              32\n",
      " InvertedResidual-15           [-1, 16, 56, 56]               0\n",
      "           Conv2d-16           [-1, 72, 56, 56]           1,152\n",
      "      BatchNorm2d-17           [-1, 72, 56, 56]             144\n",
      "             ReLU-18           [-1, 72, 56, 56]               0\n",
      "           Conv2d-19           [-1, 72, 28, 28]             648\n",
      "      BatchNorm2d-20           [-1, 72, 28, 28]             144\n",
      "             ReLU-21           [-1, 72, 28, 28]               0\n",
      "           Conv2d-22           [-1, 24, 28, 28]           1,728\n",
      "      BatchNorm2d-23           [-1, 24, 28, 28]              48\n",
      " InvertedResidual-24           [-1, 24, 28, 28]               0\n",
      "           Conv2d-25           [-1, 88, 28, 28]           2,112\n",
      "      BatchNorm2d-26           [-1, 88, 28, 28]             176\n",
      "             ReLU-27           [-1, 88, 28, 28]               0\n",
      "           Conv2d-28           [-1, 88, 28, 28]             792\n",
      "      BatchNorm2d-29           [-1, 88, 28, 28]             176\n",
      "             ReLU-30           [-1, 88, 28, 28]               0\n",
      "           Conv2d-31           [-1, 24, 28, 28]           2,112\n",
      "      BatchNorm2d-32           [-1, 24, 28, 28]              48\n",
      " InvertedResidual-33           [-1, 24, 28, 28]               0\n",
      "           Conv2d-34           [-1, 96, 28, 28]           2,304\n",
      "      BatchNorm2d-35           [-1, 96, 28, 28]             192\n",
      "        Hardswish-36           [-1, 96, 28, 28]               0\n",
      "           Conv2d-37           [-1, 96, 14, 14]           2,400\n",
      "      BatchNorm2d-38           [-1, 96, 14, 14]             192\n",
      "        Hardswish-39           [-1, 96, 14, 14]               0\n",
      "AdaptiveAvgPool2d-40             [-1, 96, 1, 1]               0\n",
      "           Conv2d-41             [-1, 24, 1, 1]           2,328\n",
      "             ReLU-42             [-1, 24, 1, 1]               0\n",
      "           Conv2d-43             [-1, 96, 1, 1]           2,400\n",
      "      Hardsigmoid-44             [-1, 96, 1, 1]               0\n",
      "SqueezeExcitation-45           [-1, 96, 14, 14]               0\n",
      "           Conv2d-46           [-1, 40, 14, 14]           3,840\n",
      "      BatchNorm2d-47           [-1, 40, 14, 14]              80\n",
      " InvertedResidual-48           [-1, 40, 14, 14]               0\n",
      "           Conv2d-49          [-1, 240, 14, 14]           9,600\n",
      "      BatchNorm2d-50          [-1, 240, 14, 14]             480\n",
      "        Hardswish-51          [-1, 240, 14, 14]               0\n",
      "           Conv2d-52          [-1, 240, 14, 14]           6,000\n",
      "      BatchNorm2d-53          [-1, 240, 14, 14]             480\n",
      "        Hardswish-54          [-1, 240, 14, 14]               0\n",
      "AdaptiveAvgPool2d-55            [-1, 240, 1, 1]               0\n",
      "           Conv2d-56             [-1, 64, 1, 1]          15,424\n",
      "             ReLU-57             [-1, 64, 1, 1]               0\n",
      "           Conv2d-58            [-1, 240, 1, 1]          15,600\n",
      "      Hardsigmoid-59            [-1, 240, 1, 1]               0\n",
      "SqueezeExcitation-60          [-1, 240, 14, 14]               0\n",
      "           Conv2d-61           [-1, 40, 14, 14]           9,600\n",
      "      BatchNorm2d-62           [-1, 40, 14, 14]              80\n",
      " InvertedResidual-63           [-1, 40, 14, 14]               0\n",
      "           Conv2d-64          [-1, 240, 14, 14]           9,600\n",
      "      BatchNorm2d-65          [-1, 240, 14, 14]             480\n",
      "        Hardswish-66          [-1, 240, 14, 14]               0\n",
      "           Conv2d-67          [-1, 240, 14, 14]           6,000\n",
      "      BatchNorm2d-68          [-1, 240, 14, 14]             480\n",
      "        Hardswish-69          [-1, 240, 14, 14]               0\n",
      "AdaptiveAvgPool2d-70            [-1, 240, 1, 1]               0\n",
      "           Conv2d-71             [-1, 64, 1, 1]          15,424\n",
      "             ReLU-72             [-1, 64, 1, 1]               0\n",
      "           Conv2d-73            [-1, 240, 1, 1]          15,600\n",
      "      Hardsigmoid-74            [-1, 240, 1, 1]               0\n",
      "SqueezeExcitation-75          [-1, 240, 14, 14]               0\n",
      "           Conv2d-76           [-1, 40, 14, 14]           9,600\n",
      "      BatchNorm2d-77           [-1, 40, 14, 14]              80\n",
      " InvertedResidual-78           [-1, 40, 14, 14]               0\n",
      "           Conv2d-79          [-1, 120, 14, 14]           4,800\n",
      "      BatchNorm2d-80          [-1, 120, 14, 14]             240\n",
      "        Hardswish-81          [-1, 120, 14, 14]               0\n",
      "           Conv2d-82          [-1, 120, 14, 14]           3,000\n",
      "      BatchNorm2d-83          [-1, 120, 14, 14]             240\n",
      "        Hardswish-84          [-1, 120, 14, 14]               0\n",
      "AdaptiveAvgPool2d-85            [-1, 120, 1, 1]               0\n",
      "           Conv2d-86             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-87             [-1, 32, 1, 1]               0\n",
      "           Conv2d-88            [-1, 120, 1, 1]           3,960\n",
      "      Hardsigmoid-89            [-1, 120, 1, 1]               0\n",
      "SqueezeExcitation-90          [-1, 120, 14, 14]               0\n",
      "           Conv2d-91           [-1, 48, 14, 14]           5,760\n",
      "      BatchNorm2d-92           [-1, 48, 14, 14]              96\n",
      " InvertedResidual-93           [-1, 48, 14, 14]               0\n",
      "           Conv2d-94          [-1, 144, 14, 14]           6,912\n",
      "      BatchNorm2d-95          [-1, 144, 14, 14]             288\n",
      "        Hardswish-96          [-1, 144, 14, 14]               0\n",
      "           Conv2d-97          [-1, 144, 14, 14]           3,600\n",
      "      BatchNorm2d-98          [-1, 144, 14, 14]             288\n",
      "        Hardswish-99          [-1, 144, 14, 14]               0\n",
      "AdaptiveAvgPool2d-100            [-1, 144, 1, 1]               0\n",
      "          Conv2d-101             [-1, 40, 1, 1]           5,800\n",
      "            ReLU-102             [-1, 40, 1, 1]               0\n",
      "          Conv2d-103            [-1, 144, 1, 1]           5,904\n",
      "     Hardsigmoid-104            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-105          [-1, 144, 14, 14]               0\n",
      "          Conv2d-106           [-1, 48, 14, 14]           6,912\n",
      "     BatchNorm2d-107           [-1, 48, 14, 14]              96\n",
      "InvertedResidual-108           [-1, 48, 14, 14]               0\n",
      "          Conv2d-109          [-1, 288, 14, 14]          13,824\n",
      "     BatchNorm2d-110          [-1, 288, 14, 14]             576\n",
      "       Hardswish-111          [-1, 288, 14, 14]               0\n",
      "          Conv2d-112            [-1, 288, 7, 7]           7,200\n",
      "     BatchNorm2d-113            [-1, 288, 7, 7]             576\n",
      "       Hardswish-114            [-1, 288, 7, 7]               0\n",
      "AdaptiveAvgPool2d-115            [-1, 288, 1, 1]               0\n",
      "          Conv2d-116             [-1, 72, 1, 1]          20,808\n",
      "            ReLU-117             [-1, 72, 1, 1]               0\n",
      "          Conv2d-118            [-1, 288, 1, 1]          21,024\n",
      "     Hardsigmoid-119            [-1, 288, 1, 1]               0\n",
      "SqueezeExcitation-120            [-1, 288, 7, 7]               0\n",
      "          Conv2d-121             [-1, 96, 7, 7]          27,648\n",
      "     BatchNorm2d-122             [-1, 96, 7, 7]             192\n",
      "InvertedResidual-123             [-1, 96, 7, 7]               0\n",
      "          Conv2d-124            [-1, 576, 7, 7]          55,296\n",
      "     BatchNorm2d-125            [-1, 576, 7, 7]           1,152\n",
      "       Hardswish-126            [-1, 576, 7, 7]               0\n",
      "          Conv2d-127            [-1, 576, 7, 7]          14,400\n",
      "     BatchNorm2d-128            [-1, 576, 7, 7]           1,152\n",
      "       Hardswish-129            [-1, 576, 7, 7]               0\n",
      "AdaptiveAvgPool2d-130            [-1, 576, 1, 1]               0\n",
      "          Conv2d-131            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-132            [-1, 144, 1, 1]               0\n",
      "          Conv2d-133            [-1, 576, 1, 1]          83,520\n",
      "     Hardsigmoid-134            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-135            [-1, 576, 7, 7]               0\n",
      "          Conv2d-136             [-1, 96, 7, 7]          55,296\n",
      "     BatchNorm2d-137             [-1, 96, 7, 7]             192\n",
      "InvertedResidual-138             [-1, 96, 7, 7]               0\n",
      "          Conv2d-139            [-1, 576, 7, 7]          55,296\n",
      "     BatchNorm2d-140            [-1, 576, 7, 7]           1,152\n",
      "       Hardswish-141            [-1, 576, 7, 7]               0\n",
      "          Conv2d-142            [-1, 576, 7, 7]          14,400\n",
      "     BatchNorm2d-143            [-1, 576, 7, 7]           1,152\n",
      "       Hardswish-144            [-1, 576, 7, 7]               0\n",
      "AdaptiveAvgPool2d-145            [-1, 576, 1, 1]               0\n",
      "          Conv2d-146            [-1, 144, 1, 1]          83,088\n",
      "            ReLU-147            [-1, 144, 1, 1]               0\n",
      "          Conv2d-148            [-1, 576, 1, 1]          83,520\n",
      "     Hardsigmoid-149            [-1, 576, 1, 1]               0\n",
      "SqueezeExcitation-150            [-1, 576, 7, 7]               0\n",
      "          Conv2d-151             [-1, 96, 7, 7]          55,296\n",
      "     BatchNorm2d-152             [-1, 96, 7, 7]             192\n",
      "InvertedResidual-153             [-1, 96, 7, 7]               0\n",
      "          Conv2d-154            [-1, 576, 7, 7]          55,296\n",
      "     BatchNorm2d-155            [-1, 576, 7, 7]           1,152\n",
      "       Hardswish-156            [-1, 576, 7, 7]               0\n",
      "AdaptiveAvgPool2d-157            [-1, 576, 1, 1]               0\n",
      "          Linear-158                 [-1, 1024]         590,848\n",
      "       Hardswish-159                 [-1, 1024]               0\n",
      "         Dropout-160                 [-1, 1024]               0\n",
      "          Linear-161                   [-1, 31]          31,775\n",
      "================================================================\n",
      "Total params: 1,549,631\n",
      "Trainable params: 1,549,631\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 34.60\n",
      "Params size (MB): 5.91\n",
      "Estimated Total Size (MB): 41.09\n",
      "----------------------------------------------------------------\n",
      "Number of FLOPs: 0.114337 GFLOPs (114.34 MFLOPs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.1434e+08)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbv_3_small_ref = mobilenet_v3_small(weights='DEFAULT')\n",
    "mbv_3_small_ref.classifier[-1] = nn.Linear(mbv_3_small_ref.classifier[-1].in_features, NUM_CLASSES)\n",
    "mbv_3_small_ref = mbv_3_small_ref.to(device)\n",
    "summary(mbv_3_small_ref, (3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "count_model_param_flops(model=mbv_3_small_ref.cpu().eval(), input_res=IMAGE_SIZE, multiply_adds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(dslr_dataset, [0.8,0.2])\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mbv_3_small_ref.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "check_point_path = f'{HOME}/cp/baseline/mbv3_small_ref2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def train(model, opt, loss_fn, train_loader, test_loader, epochs=10, checkpoint_path=None, device='cpu'):\n",
    "    training_logs = {\"train_loss\": [], \"validate_loss\": [], \"train_acc\": [], \"validate_acc\": []}\n",
    "    epoch_number = 0\n",
    "    best_test_loss = float('inf')\n",
    "    model = model.to(device)\n",
    "\n",
    "    if checkpoint_path:\n",
    "      if os.path.exists(checkpoint_path + 'model.pth'):\n",
    "        model.load_state_dict(torch.load(checkpoint_path + 'model.pth', weights_only=True, map_location=device))\n",
    "\n",
    "      if os.path.exists(checkpoint_path + 'opt.pth'):\n",
    "        opt.load_state_dict(torch.load(checkpoint_path + 'opt.pth', weights_only=True, map_location=device))\n",
    "\n",
    "      if os.path.exists(checkpoint_path + 'training_logs.pth'):\n",
    "        training_logs = torch.load(checkpoint_path + 'training_logs.pth', weights_only=True)\n",
    "        epoch_number = len(training_logs['train_loss'])\n",
    "        best_test_loss = min(best_test_loss, min(training_logs['validate_loss']))\n",
    "        print('best_test_acc', max(training_logs['validate_acc']))\n",
    "\n",
    "    for i in range(epoch_number):\n",
    "        print(f\"Epochs {i+1}\".ljust(10), end='')\n",
    "        for k, v in training_logs.items():\n",
    "            print(f\"{k}: {v[i]:.5f}\", end=\" \")\n",
    "        print()\n",
    "\n",
    "    print(\"🤖Training on\", device)\n",
    "    for epoch in range(epoch_number, epochs):\n",
    "\n",
    "        train_loss, train_correct = 0, 0\n",
    "        model.train()\n",
    "        train_bar = tqdm(train_loader, desc=f'🚀Training Epoch [{epoch+1}/{epochs}]', unit='batch')\n",
    "        for images, label in train_bar:\n",
    "            images = images.to(device)\n",
    "            label = label.to(device)\n",
    "            opt.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, label)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            train_loss += loss.item()\n",
    "            train_correct += (outputs.argmax(1) == label).float().sum().item()\n",
    "            \n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        avg_train_acc = train_correct / len(train_loader.dataset)\n",
    "        print(f'\\n\\tTrain loss: {avg_train_loss}')\n",
    "        print(f'\\tTrain acc: {avg_train_acc}')\n",
    "        training_logs[\"train_loss\"].append(avg_train_loss)\n",
    "        training_logs[\"train_acc\"].append(avg_train_acc)\n",
    "\n",
    "        test_loss, test_correct = 0, 0\n",
    "        model.eval()\n",
    "        test_bar = tqdm(test_loader,desc='📄Testing',unit='batch')\n",
    "        with torch.no_grad():\n",
    "          for images, label in test_bar:\n",
    "            images = images.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, label)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            test_correct += (outputs.argmax(1) == label).float().sum().item()\n",
    "            \n",
    "        avg_test_loss = test_loss / len(test_loader.dataset)\n",
    "        avg_test_acc = test_correct / len(test_loader.dataset)\n",
    "        print(f'\\tTest loss: {avg_test_loss}')\n",
    "        print(f'\\tTest acc: {avg_test_acc}')\n",
    "        training_logs[\"validate_loss\"].append(avg_test_loss)\n",
    "        training_logs[\"validate_acc\"].append(avg_test_acc)\n",
    "\n",
    "        if checkpoint_path:\n",
    "            torch.save(model.state_dict(), checkpoint_path + \"model.pth\")\n",
    "            torch.save(opt.state_dict(), checkpoint_path + \"opt.pth\")\n",
    "            torch.save(training_logs, checkpoint_path + 'training_logs.pth')\n",
    "            if best_test_loss > avg_test_loss:\n",
    "               torch.save(model.state_dict(), checkpoint_path + \"best_model.pth\")\n",
    "               best_test_loss = avg_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_test_acc 0.9696969696969697\n",
      "Epochs 1  train_loss: 0.12932 validate_loss: 0.10538 train_acc: 0.47870 validate_acc: 0.59596 \n",
      "Epochs 2  train_loss: 0.01843 validate_loss: 0.06013 train_acc: 0.93734 validate_acc: 0.78788 \n",
      "Epochs 3  train_loss: 0.00409 validate_loss: 0.04757 train_acc: 0.98997 validate_acc: 0.79798 \n",
      "Epochs 4  train_loss: 0.00227 validate_loss: 0.01379 train_acc: 0.99248 validate_acc: 0.95960 \n",
      "Epochs 5  train_loss: 0.00072 validate_loss: 0.00962 train_acc: 1.00000 validate_acc: 0.96970 \n",
      "Epochs 6  train_loss: 0.00052 validate_loss: 0.01484 train_acc: 1.00000 validate_acc: 0.92929 \n",
      "Epochs 7  train_loss: 0.00037 validate_loss: 0.00712 train_acc: 1.00000 validate_acc: 0.95960 \n",
      "Epochs 8  train_loss: 0.00119 validate_loss: 0.02715 train_acc: 0.99248 validate_acc: 0.90909 \n",
      "Epochs 9  train_loss: 0.00136 validate_loss: 0.08175 train_acc: 0.98997 validate_acc: 0.77778 \n",
      "Epochs 10 train_loss: 0.01104 validate_loss: 0.06109 train_acc: 0.94987 validate_acc: 0.72727 \n",
      "Epochs 11 train_loss: 0.01254 validate_loss: 0.08693 train_acc: 0.93985 validate_acc: 0.70707 \n",
      "Epochs 12 train_loss: 0.01099 validate_loss: 0.09172 train_acc: 0.94486 validate_acc: 0.73737 \n",
      "Epochs 13 train_loss: 0.01164 validate_loss: 0.07154 train_acc: 0.95489 validate_acc: 0.86869 \n",
      "Epochs 14 train_loss: 0.00793 validate_loss: 0.06604 train_acc: 0.95238 validate_acc: 0.77778 \n",
      "Epochs 15 train_loss: 0.00730 validate_loss: 0.05812 train_acc: 0.96992 validate_acc: 0.82828 \n",
      "Epochs 16 train_loss: 0.00628 validate_loss: 0.11549 train_acc: 0.97243 validate_acc: 0.76768 \n",
      "Epochs 17 train_loss: 0.00375 validate_loss: 0.06397 train_acc: 0.98997 validate_acc: 0.93939 \n",
      "Epochs 18 train_loss: 0.00423 validate_loss: 0.07607 train_acc: 0.98246 validate_acc: 0.84848 \n",
      "Epochs 19 train_loss: 0.00125 validate_loss: 0.03520 train_acc: 0.99499 validate_acc: 0.91919 \n",
      "Epochs 20 train_loss: 0.00121 validate_loss: 0.02945 train_acc: 0.99248 validate_acc: 0.94949 \n",
      "Epochs 21 train_loss: 0.00161 validate_loss: 0.02231 train_acc: 0.99248 validate_acc: 0.95960 \n",
      "Epochs 22 train_loss: 0.00207 validate_loss: 0.02962 train_acc: 0.99248 validate_acc: 0.95960 \n",
      "Epochs 23 train_loss: 0.00228 validate_loss: 0.02240 train_acc: 0.99248 validate_acc: 0.90909 \n",
      "Epochs 24 train_loss: 0.00088 validate_loss: 0.01495 train_acc: 0.99749 validate_acc: 0.94949 \n",
      "Epochs 25 train_loss: 0.00029 validate_loss: 0.01613 train_acc: 0.99749 validate_acc: 0.92929 \n",
      "Epochs 26 train_loss: 0.00029 validate_loss: 0.01886 train_acc: 1.00000 validate_acc: 0.90909 \n",
      "Epochs 27 train_loss: 0.00017 validate_loss: 0.01612 train_acc: 1.00000 validate_acc: 0.92929 \n",
      "Epochs 28 train_loss: 0.00032 validate_loss: 0.02148 train_acc: 1.00000 validate_acc: 0.92929 \n",
      "Epochs 29 train_loss: 0.00017 validate_loss: 0.01803 train_acc: 0.99749 validate_acc: 0.94949 \n",
      "Epochs 30 train_loss: 0.00010 validate_loss: 0.01889 train_acc: 1.00000 validate_acc: 0.93939 \n",
      "Epochs 31 train_loss: 0.00003 validate_loss: 0.02102 train_acc: 1.00000 validate_acc: 0.93939 \n",
      "Epochs 32 train_loss: 0.00012 validate_loss: 0.03036 train_acc: 1.00000 validate_acc: 0.92929 \n",
      "Epochs 33 train_loss: 0.00015 validate_loss: 0.02999 train_acc: 1.00000 validate_acc: 0.93939 \n",
      "Epochs 34 train_loss: 0.00004 validate_loss: 0.02562 train_acc: 1.00000 validate_acc: 0.93939 \n",
      "Epochs 35 train_loss: 0.00004 validate_loss: 0.02375 train_acc: 1.00000 validate_acc: 0.94949 \n",
      "Epochs 36 train_loss: 0.00005 validate_loss: 0.02241 train_acc: 1.00000 validate_acc: 0.94949 \n",
      "Epochs 37 train_loss: 0.00003 validate_loss: 0.02361 train_acc: 1.00000 validate_acc: 0.91919 \n",
      "Epochs 38 train_loss: 0.00005 validate_loss: 0.02280 train_acc: 1.00000 validate_acc: 0.90909 \n",
      "Epochs 39 train_loss: 0.00001 validate_loss: 0.02287 train_acc: 1.00000 validate_acc: 0.90909 \n",
      "Epochs 40 train_loss: 0.00003 validate_loss: 0.02272 train_acc: 1.00000 validate_acc: 0.90909 \n",
      "Epochs 41 train_loss: 0.00002 validate_loss: 0.02224 train_acc: 1.00000 validate_acc: 0.90909 \n",
      "Epochs 42 train_loss: 0.00001 validate_loss: 0.02148 train_acc: 1.00000 validate_acc: 0.90909 \n",
      "Epochs 43 train_loss: 0.00002 validate_loss: 0.02043 train_acc: 1.00000 validate_acc: 0.92929 \n",
      "Epochs 44 train_loss: 0.00001 validate_loss: 0.01983 train_acc: 1.00000 validate_acc: 0.92929 \n",
      "Epochs 45 train_loss: 0.00001 validate_loss: 0.01983 train_acc: 1.00000 validate_acc: 0.92929 \n",
      "Epochs 46 train_loss: 0.00001 validate_loss: 0.01957 train_acc: 1.00000 validate_acc: 0.92929 \n",
      "Epochs 47 train_loss: 0.00001 validate_loss: 0.01963 train_acc: 1.00000 validate_acc: 0.92929 \n",
      "Epochs 48 train_loss: 0.00003 validate_loss: 0.01389 train_acc: 1.00000 validate_acc: 0.93939 \n",
      "Epochs 49 train_loss: 0.00001 validate_loss: 0.01391 train_acc: 1.00000 validate_acc: 0.93939 \n",
      "Epochs 50 train_loss: 0.00001 validate_loss: 0.01414 train_acc: 1.00000 validate_acc: 0.93939 \n",
      "🤖Training on cpu\n"
     ]
    }
   ],
   "source": [
    "train(mbv_3_small_ref, optimizer, criterion, train_loader, test_loader, 50, checkpoint_path=check_point_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "         Hardswish-3           [-1, 16, 32, 32]               0\n",
      "            Conv2d-4           [-1, 16, 32, 32]             144\n",
      "       BatchNorm2d-5           [-1, 16, 32, 32]              32\n",
      "              ReLU-6           [-1, 16, 32, 32]               0\n",
      "            Conv2d-7           [-1, 16, 32, 32]             256\n",
      "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
      "  InvertedResidual-9           [-1, 16, 32, 32]               0\n",
      "           Conv2d-10           [-1, 64, 32, 32]           1,024\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "             ReLU-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13           [-1, 64, 16, 16]             576\n",
      "      BatchNorm2d-14           [-1, 64, 16, 16]             128\n",
      "             ReLU-15           [-1, 64, 16, 16]               0\n",
      "           Conv2d-16           [-1, 24, 16, 16]           1,536\n",
      "      BatchNorm2d-17           [-1, 24, 16, 16]              48\n",
      " InvertedResidual-18           [-1, 24, 16, 16]               0\n",
      "           Conv2d-19           [-1, 72, 16, 16]           1,728\n",
      "      BatchNorm2d-20           [-1, 72, 16, 16]             144\n",
      "             ReLU-21           [-1, 72, 16, 16]               0\n",
      "           Conv2d-22           [-1, 72, 16, 16]             648\n",
      "      BatchNorm2d-23           [-1, 72, 16, 16]             144\n",
      "             ReLU-24           [-1, 72, 16, 16]               0\n",
      "           Conv2d-25           [-1, 24, 16, 16]           1,728\n",
      "      BatchNorm2d-26           [-1, 24, 16, 16]              48\n",
      " InvertedResidual-27           [-1, 24, 16, 16]               0\n",
      "           Conv2d-28           [-1, 72, 16, 16]           1,728\n",
      "      BatchNorm2d-29           [-1, 72, 16, 16]             144\n",
      "             ReLU-30           [-1, 72, 16, 16]               0\n",
      "           Conv2d-31             [-1, 72, 8, 8]           1,800\n",
      "      BatchNorm2d-32             [-1, 72, 8, 8]             144\n",
      "             ReLU-33             [-1, 72, 8, 8]               0\n",
      "AdaptiveAvgPool2d-34             [-1, 72, 1, 1]               0\n",
      "           Conv2d-35             [-1, 24, 1, 1]           1,752\n",
      "             ReLU-36             [-1, 24, 1, 1]               0\n",
      "           Conv2d-37             [-1, 72, 1, 1]           1,800\n",
      "      Hardsigmoid-38             [-1, 72, 1, 1]               0\n",
      "SqueezeExcitation-39             [-1, 72, 8, 8]               0\n",
      "           Conv2d-40             [-1, 40, 8, 8]           2,880\n",
      "      BatchNorm2d-41             [-1, 40, 8, 8]              80\n",
      " InvertedResidual-42             [-1, 40, 8, 8]               0\n",
      "           Conv2d-43            [-1, 120, 8, 8]           4,800\n",
      "      BatchNorm2d-44            [-1, 120, 8, 8]             240\n",
      "             ReLU-45            [-1, 120, 8, 8]               0\n",
      "           Conv2d-46            [-1, 120, 8, 8]           3,000\n",
      "      BatchNorm2d-47            [-1, 120, 8, 8]             240\n",
      "             ReLU-48            [-1, 120, 8, 8]               0\n",
      "AdaptiveAvgPool2d-49            [-1, 120, 1, 1]               0\n",
      "           Conv2d-50             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-51             [-1, 32, 1, 1]               0\n",
      "           Conv2d-52            [-1, 120, 1, 1]           3,960\n",
      "      Hardsigmoid-53            [-1, 120, 1, 1]               0\n",
      "SqueezeExcitation-54            [-1, 120, 8, 8]               0\n",
      "           Conv2d-55             [-1, 40, 8, 8]           4,800\n",
      "      BatchNorm2d-56             [-1, 40, 8, 8]              80\n",
      " InvertedResidual-57             [-1, 40, 8, 8]               0\n",
      "           Conv2d-58            [-1, 120, 8, 8]           4,800\n",
      "      BatchNorm2d-59            [-1, 120, 8, 8]             240\n",
      "             ReLU-60            [-1, 120, 8, 8]               0\n",
      "           Conv2d-61            [-1, 120, 8, 8]           3,000\n",
      "      BatchNorm2d-62            [-1, 120, 8, 8]             240\n",
      "             ReLU-63            [-1, 120, 8, 8]               0\n",
      "AdaptiveAvgPool2d-64            [-1, 120, 1, 1]               0\n",
      "           Conv2d-65             [-1, 32, 1, 1]           3,872\n",
      "             ReLU-66             [-1, 32, 1, 1]               0\n",
      "           Conv2d-67            [-1, 120, 1, 1]           3,960\n",
      "      Hardsigmoid-68            [-1, 120, 1, 1]               0\n",
      "SqueezeExcitation-69            [-1, 120, 8, 8]               0\n",
      "           Conv2d-70             [-1, 40, 8, 8]           4,800\n",
      "      BatchNorm2d-71             [-1, 40, 8, 8]              80\n",
      " InvertedResidual-72             [-1, 40, 8, 8]               0\n",
      "           Conv2d-73            [-1, 240, 8, 8]           9,600\n",
      "      BatchNorm2d-74            [-1, 240, 8, 8]             480\n",
      "        Hardswish-75            [-1, 240, 8, 8]               0\n",
      "           Conv2d-76            [-1, 240, 4, 4]           2,160\n",
      "      BatchNorm2d-77            [-1, 240, 4, 4]             480\n",
      "        Hardswish-78            [-1, 240, 4, 4]               0\n",
      "           Conv2d-79             [-1, 80, 4, 4]          19,200\n",
      "      BatchNorm2d-80             [-1, 80, 4, 4]             160\n",
      " InvertedResidual-81             [-1, 80, 4, 4]               0\n",
      "           Conv2d-82            [-1, 200, 4, 4]          16,000\n",
      "      BatchNorm2d-83            [-1, 200, 4, 4]             400\n",
      "        Hardswish-84            [-1, 200, 4, 4]               0\n",
      "           Conv2d-85            [-1, 200, 4, 4]           1,800\n",
      "      BatchNorm2d-86            [-1, 200, 4, 4]             400\n",
      "        Hardswish-87            [-1, 200, 4, 4]               0\n",
      "           Conv2d-88             [-1, 80, 4, 4]          16,000\n",
      "      BatchNorm2d-89             [-1, 80, 4, 4]             160\n",
      " InvertedResidual-90             [-1, 80, 4, 4]               0\n",
      "           Conv2d-91            [-1, 184, 4, 4]          14,720\n",
      "      BatchNorm2d-92            [-1, 184, 4, 4]             368\n",
      "        Hardswish-93            [-1, 184, 4, 4]               0\n",
      "           Conv2d-94            [-1, 184, 4, 4]           1,656\n",
      "      BatchNorm2d-95            [-1, 184, 4, 4]             368\n",
      "        Hardswish-96            [-1, 184, 4, 4]               0\n",
      "           Conv2d-97             [-1, 80, 4, 4]          14,720\n",
      "      BatchNorm2d-98             [-1, 80, 4, 4]             160\n",
      " InvertedResidual-99             [-1, 80, 4, 4]               0\n",
      "          Conv2d-100            [-1, 184, 4, 4]          14,720\n",
      "     BatchNorm2d-101            [-1, 184, 4, 4]             368\n",
      "       Hardswish-102            [-1, 184, 4, 4]               0\n",
      "          Conv2d-103            [-1, 184, 4, 4]           1,656\n",
      "     BatchNorm2d-104            [-1, 184, 4, 4]             368\n",
      "       Hardswish-105            [-1, 184, 4, 4]               0\n",
      "          Conv2d-106             [-1, 80, 4, 4]          14,720\n",
      "     BatchNorm2d-107             [-1, 80, 4, 4]             160\n",
      "InvertedResidual-108             [-1, 80, 4, 4]               0\n",
      "          Conv2d-109            [-1, 480, 4, 4]          38,400\n",
      "     BatchNorm2d-110            [-1, 480, 4, 4]             960\n",
      "       Hardswish-111            [-1, 480, 4, 4]               0\n",
      "          Conv2d-112            [-1, 480, 4, 4]           4,320\n",
      "     BatchNorm2d-113            [-1, 480, 4, 4]             960\n",
      "       Hardswish-114            [-1, 480, 4, 4]               0\n",
      "AdaptiveAvgPool2d-115            [-1, 480, 1, 1]               0\n",
      "          Conv2d-116            [-1, 120, 1, 1]          57,720\n",
      "            ReLU-117            [-1, 120, 1, 1]               0\n",
      "          Conv2d-118            [-1, 480, 1, 1]          58,080\n",
      "     Hardsigmoid-119            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-120            [-1, 480, 4, 4]               0\n",
      "          Conv2d-121            [-1, 112, 4, 4]          53,760\n",
      "     BatchNorm2d-122            [-1, 112, 4, 4]             224\n",
      "InvertedResidual-123            [-1, 112, 4, 4]               0\n",
      "          Conv2d-124            [-1, 672, 4, 4]          75,264\n",
      "     BatchNorm2d-125            [-1, 672, 4, 4]           1,344\n",
      "       Hardswish-126            [-1, 672, 4, 4]               0\n",
      "          Conv2d-127            [-1, 672, 4, 4]           6,048\n",
      "     BatchNorm2d-128            [-1, 672, 4, 4]           1,344\n",
      "       Hardswish-129            [-1, 672, 4, 4]               0\n",
      "AdaptiveAvgPool2d-130            [-1, 672, 1, 1]               0\n",
      "          Conv2d-131            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-132            [-1, 168, 1, 1]               0\n",
      "          Conv2d-133            [-1, 672, 1, 1]         113,568\n",
      "     Hardsigmoid-134            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-135            [-1, 672, 4, 4]               0\n",
      "          Conv2d-136            [-1, 112, 4, 4]          75,264\n",
      "     BatchNorm2d-137            [-1, 112, 4, 4]             224\n",
      "InvertedResidual-138            [-1, 112, 4, 4]               0\n",
      "          Conv2d-139            [-1, 672, 4, 4]          75,264\n",
      "     BatchNorm2d-140            [-1, 672, 4, 4]           1,344\n",
      "       Hardswish-141            [-1, 672, 4, 4]               0\n",
      "          Conv2d-142            [-1, 672, 2, 2]          16,800\n",
      "     BatchNorm2d-143            [-1, 672, 2, 2]           1,344\n",
      "       Hardswish-144            [-1, 672, 2, 2]               0\n",
      "AdaptiveAvgPool2d-145            [-1, 672, 1, 1]               0\n",
      "          Conv2d-146            [-1, 168, 1, 1]         113,064\n",
      "            ReLU-147            [-1, 168, 1, 1]               0\n",
      "          Conv2d-148            [-1, 672, 1, 1]         113,568\n",
      "     Hardsigmoid-149            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-150            [-1, 672, 2, 2]               0\n",
      "          Conv2d-151            [-1, 160, 2, 2]         107,520\n",
      "     BatchNorm2d-152            [-1, 160, 2, 2]             320\n",
      "InvertedResidual-153            [-1, 160, 2, 2]               0\n",
      "          Conv2d-154            [-1, 960, 2, 2]         153,600\n",
      "     BatchNorm2d-155            [-1, 960, 2, 2]           1,920\n",
      "       Hardswish-156            [-1, 960, 2, 2]               0\n",
      "          Conv2d-157            [-1, 960, 2, 2]          24,000\n",
      "     BatchNorm2d-158            [-1, 960, 2, 2]           1,920\n",
      "       Hardswish-159            [-1, 960, 2, 2]               0\n",
      "AdaptiveAvgPool2d-160            [-1, 960, 1, 1]               0\n",
      "          Conv2d-161            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-162            [-1, 240, 1, 1]               0\n",
      "          Conv2d-163            [-1, 960, 1, 1]         231,360\n",
      "     Hardsigmoid-164            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-165            [-1, 960, 2, 2]               0\n",
      "          Conv2d-166            [-1, 160, 2, 2]         153,600\n",
      "     BatchNorm2d-167            [-1, 160, 2, 2]             320\n",
      "InvertedResidual-168            [-1, 160, 2, 2]               0\n",
      "          Conv2d-169            [-1, 960, 2, 2]         153,600\n",
      "     BatchNorm2d-170            [-1, 960, 2, 2]           1,920\n",
      "       Hardswish-171            [-1, 960, 2, 2]               0\n",
      "          Conv2d-172            [-1, 960, 2, 2]          24,000\n",
      "     BatchNorm2d-173            [-1, 960, 2, 2]           1,920\n",
      "       Hardswish-174            [-1, 960, 2, 2]               0\n",
      "AdaptiveAvgPool2d-175            [-1, 960, 1, 1]               0\n",
      "          Conv2d-176            [-1, 240, 1, 1]         230,640\n",
      "            ReLU-177            [-1, 240, 1, 1]               0\n",
      "          Conv2d-178            [-1, 960, 1, 1]         231,360\n",
      "     Hardsigmoid-179            [-1, 960, 1, 1]               0\n",
      "SqueezeExcitation-180            [-1, 960, 2, 2]               0\n",
      "          Conv2d-181            [-1, 160, 2, 2]         153,600\n",
      "     BatchNorm2d-182            [-1, 160, 2, 2]             320\n",
      "InvertedResidual-183            [-1, 160, 2, 2]               0\n",
      "          Conv2d-184            [-1, 960, 2, 2]         153,600\n",
      "     BatchNorm2d-185            [-1, 960, 2, 2]           1,920\n",
      "       Hardswish-186            [-1, 960, 2, 2]               0\n",
      "AdaptiveAvgPool2d-187            [-1, 960, 1, 1]               0\n",
      "          Linear-188                 [-1, 1280]       1,230,080\n",
      "       Hardswish-189                 [-1, 1280]               0\n",
      "         Dropout-190                 [-1, 1280]               0\n",
      "          Linear-191                   [-1, 31]          39,711\n",
      "================================================================\n",
      "Total params: 4,241,743\n",
      "Trainable params: 4,241,743\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 8.74\n",
      "Params size (MB): 16.18\n",
      "Estimated Total Size (MB): 24.97\n",
      "----------------------------------------------------------------\n",
      "Number of FLOPs: 0.041172 GFLOPs (41.17 MFLOPs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(41171960.)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbv_3_large_ref = mobilenet_v3_large(weights=None, num_classes=31)\n",
    "# mbv_3_large_ref.classifier[-1] = nn.Linear(mbv_3_large_ref.classifier[-1].in_features, NUM_CLASSES)\n",
    "mbv_3_large_ref = mbv_3_large_ref.to(device)\n",
    "summary(mbv_3_large_ref, (3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "count_model_param_flops(model=mbv_3_large_ref.cpu().eval(), input_res=64, multiply_adds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = torch.utils.data.random_split(dslr_dataset, [0.8,0.2])\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mbv_3_small_ref.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "check_point_path = f'{HOME}/cp/baseline/mbv3_large_ref/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀Training Epoch [1/50]:   0%|          | 0/25 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀Training Epoch [1/50]:  44%|████▍     | 11/25 [00:02<00:02,  5.17batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(mbv_3_large_ref, optimizer, criterion, train_loader, test_loader, \u001b[38;5;241m50\u001b[39m, check_point_path, device)\n",
      "Cell \u001b[0;32mIn[21], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, opt, loss_fn, train_loader, test_loader, epochs, checkpoint_path, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     31\u001b[0m train_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m🚀Training Epoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, label \u001b[38;5;129;01min\u001b[39;00m train_bar:\n\u001b[1;32m     33\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     34\u001b[0m     label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/datasets/folder.py:247\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/_presets.py:61\u001b[0m, in \u001b[0;36mImageClassification.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcenter_crop(img, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrop_size)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, Tensor):\n\u001b[0;32m---> 61\u001b[0m     img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpil_to_tensor(img)\n\u001b[1;32m     62\u001b[0m img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconvert_image_dtype(img, torch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[1;32m     63\u001b[0m img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(img, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/functional.py:209\u001b[0m, in \u001b[0;36mpil_to_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mas_tensor(nppic)\n\u001b[1;32m    208\u001b[0m \u001b[38;5;66;03m# handle PIL Image\u001b[39;00m\n\u001b[0;32m--> 209\u001b[0m img \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(np\u001b[38;5;241m.\u001b[39marray(pic, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    210\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mview(pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m1\u001b[39m], pic\u001b[38;5;241m.\u001b[39msize[\u001b[38;5;241m0\u001b[39m], F_pil\u001b[38;5;241m.\u001b[39mget_image_num_channels(pic))\n\u001b[1;32m    211\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(mbv_3_large_ref, optimizer, criterion, train_loader, test_loader, 50, check_point_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LTAEBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, mlp_ratio=4, dropout=0.1):\n",
    "        super(LTAEBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n",
    "        self.fc1 = nn.Linear(embed_dim, embed_dim * mlp_ratio)\n",
    "        self.fc2 = nn.Linear(embed_dim * mlp_ratio, embed_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        x = self.norm1(x + self.dropout1(attn_output))\n",
    "        ff_output = self.fc2(self.dropout2(F.gelu(self.fc1(x))))\n",
    "        x = self.norm2(x + ff_output)\n",
    "        return x\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio, activation, use_ltae=False):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.use_ltae = use_ltae\n",
    "        hidden_channels = in_channels * expand_ratio\n",
    "        activation_layer = nn.Hardswish() if activation == \"HS\" else nn.ReLU()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, hidden_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(hidden_channels),\n",
    "            activation_layer,\n",
    "            nn.Conv2d(hidden_channels, hidden_channels, kernel_size=3, stride=stride, padding=1, groups=hidden_channels),\n",
    "            nn.BatchNorm2d(hidden_channels),\n",
    "            activation_layer\n",
    "        )\n",
    "\n",
    "        if use_ltae:\n",
    "            self.ltae = LTAEBlock(embed_dim=hidden_channels, num_heads=expand_ratio)\n",
    "        \n",
    "        self.pointwise = nn.Sequential(\n",
    "            nn.Conv2d(hidden_channels, out_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            activation_layer\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)  # Apply convolution\n",
    "        if self.use_ltae:\n",
    "            batch_size, channels, height, width = x.size()\n",
    "            # Reshape x for LTAE block\n",
    "            x = x.view(batch_size, channels, -1).permute(0, 2, 1)  # (batch, height*width, channels)\n",
    "            x = self.ltae(x)  # Apply LTAE\n",
    "            x = x.permute(0, 2, 1).view(batch_size, channels, height, width)  # Reshape back\n",
    "            \n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "        \n",
    "class LTAEMobileNetV3Small(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(LTAEMobileNetV3Small, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.hs = nn.Hardsigmoid()\n",
    "\n",
    "        # Define layers of MobileNetV3 Small with inverted residual blocks and LTAE replacing SE\n",
    "        self.blocks = nn.ModuleList([\n",
    "            InvertedResidual(16, 16, stride=1, expand_ratio=1, activation=\"RE\", use_ltae=True),\n",
    "            InvertedResidual(16, 24, stride=2, expand_ratio=1, activation=\"RE\", use_ltae=False),\n",
    "            InvertedResidual(24, 24, stride=1, expand_ratio=1, activation=\"RE\", use_ltae=False),\n",
    "            InvertedResidual(24, 40, stride=2, expand_ratio=3, activation=\"HS\", use_ltae=True),\n",
    "            InvertedResidual(40, 40, stride=1, expand_ratio=3, activation=\"HS\", use_ltae=True),\n",
    "            InvertedResidual(40, 40, stride=2, expand_ratio=3, activation=\"HS\", use_ltae=True),\n",
    "            InvertedResidual(40, 48, stride=1, expand_ratio=3, activation=\"HS\", use_ltae=True),\n",
    "            InvertedResidual(48, 48, stride=1, expand_ratio=3, activation=\"HS\", use_ltae=True),\n",
    "            InvertedResidual(48, 96, stride=1, expand_ratio=3, activation=\"HS\", use_ltae=True),\n",
    "            InvertedResidual(96, 96, stride=1, expand_ratio=3, activation=\"HS\", use_ltae=True),\n",
    "            InvertedResidual(96, 96, stride=2, expand_ratio=3, activation=\"HS\", use_ltae=True),\n",
    "        ])\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(96, 576, kernel_size=1)\n",
    "        self.bn2 = nn.BatchNorm2d(576)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc1 = nn.Linear(576, 1024)\n",
    "        self.fc2 = nn.Linear(1024, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.hs(self.bn1(self.conv1(x)))\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "        \n",
    "        # conv2 with LTAE\n",
    "        x = self.conv2(x)\n",
    "        x = self.hs(x)\n",
    "        # batch_size, channels, height, width = x.size()\n",
    "        # x = x.view(batch_size, channels, -1).permute(0, 2, 1)\n",
    "        # x = self.ltae(x)\n",
    "        # x = x.permute(0, 2, 1).view(batch_size, channels, height, width)\n",
    "        # x = self.hs(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.hs(self.fc1(x))\n",
    "        self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 112, 112]             448\n",
      "       BatchNorm2d-2         [-1, 16, 112, 112]              32\n",
      "       Hardsigmoid-3         [-1, 16, 112, 112]               0\n",
      "            Conv2d-4         [-1, 16, 112, 112]             272\n",
      "       BatchNorm2d-5         [-1, 16, 112, 112]              32\n",
      "              ReLU-6         [-1, 16, 112, 112]               0\n",
      "              ReLU-7         [-1, 16, 112, 112]               0\n",
      "            Conv2d-8         [-1, 16, 112, 112]             160\n",
      "       BatchNorm2d-9         [-1, 16, 112, 112]              32\n",
      "             ReLU-10         [-1, 16, 112, 112]               0\n",
      "             ReLU-11         [-1, 16, 112, 112]               0\n",
      "MultiheadAttention-12  [[-1, 12544, 16], [-1, 2, 2]]               0\n",
      "          Dropout-13            [-1, 12544, 16]               0\n",
      "        LayerNorm-14            [-1, 12544, 16]              32\n",
      "           Linear-15            [-1, 12544, 64]           1,088\n",
      "          Dropout-16            [-1, 12544, 64]               0\n",
      "           Linear-17            [-1, 12544, 16]           1,040\n",
      "        LayerNorm-18            [-1, 12544, 16]              32\n",
      "        LTAEBlock-19            [-1, 12544, 16]               0\n",
      "           Conv2d-20         [-1, 16, 112, 112]             272\n",
      "      BatchNorm2d-21         [-1, 16, 112, 112]              32\n",
      "             ReLU-22         [-1, 16, 112, 112]               0\n",
      "             ReLU-23         [-1, 16, 112, 112]               0\n",
      " InvertedResidual-24         [-1, 16, 112, 112]               0\n",
      "           Conv2d-25         [-1, 16, 112, 112]             272\n",
      "      BatchNorm2d-26         [-1, 16, 112, 112]              32\n",
      "             ReLU-27         [-1, 16, 112, 112]               0\n",
      "             ReLU-28         [-1, 16, 112, 112]               0\n",
      "           Conv2d-29           [-1, 16, 56, 56]             160\n",
      "      BatchNorm2d-30           [-1, 16, 56, 56]              32\n",
      "             ReLU-31           [-1, 16, 56, 56]               0\n",
      "             ReLU-32           [-1, 16, 56, 56]               0\n",
      "           Conv2d-33           [-1, 24, 56, 56]             408\n",
      "      BatchNorm2d-34           [-1, 24, 56, 56]              48\n",
      "             ReLU-35           [-1, 24, 56, 56]               0\n",
      "             ReLU-36           [-1, 24, 56, 56]               0\n",
      " InvertedResidual-37           [-1, 24, 56, 56]               0\n",
      "           Conv2d-38           [-1, 24, 56, 56]             600\n",
      "      BatchNorm2d-39           [-1, 24, 56, 56]              48\n",
      "             ReLU-40           [-1, 24, 56, 56]               0\n",
      "             ReLU-41           [-1, 24, 56, 56]               0\n",
      "           Conv2d-42           [-1, 24, 56, 56]             240\n",
      "      BatchNorm2d-43           [-1, 24, 56, 56]              48\n",
      "             ReLU-44           [-1, 24, 56, 56]               0\n",
      "             ReLU-45           [-1, 24, 56, 56]               0\n",
      "           Conv2d-46           [-1, 24, 56, 56]             600\n",
      "      BatchNorm2d-47           [-1, 24, 56, 56]              48\n",
      "             ReLU-48           [-1, 24, 56, 56]               0\n",
      "             ReLU-49           [-1, 24, 56, 56]               0\n",
      " InvertedResidual-50           [-1, 24, 56, 56]               0\n",
      "           Conv2d-51           [-1, 72, 56, 56]           1,800\n",
      "      BatchNorm2d-52           [-1, 72, 56, 56]             144\n",
      "        Hardswish-53           [-1, 72, 56, 56]               0\n",
      "        Hardswish-54           [-1, 72, 56, 56]               0\n",
      "           Conv2d-55           [-1, 72, 28, 28]             720\n",
      "      BatchNorm2d-56           [-1, 72, 28, 28]             144\n",
      "        Hardswish-57           [-1, 72, 28, 28]               0\n",
      "        Hardswish-58           [-1, 72, 28, 28]               0\n",
      "MultiheadAttention-59  [[-1, 784, 72], [-1, 2, 2]]               0\n",
      "          Dropout-60              [-1, 784, 72]               0\n",
      "        LayerNorm-61              [-1, 784, 72]             144\n",
      "           Linear-62             [-1, 784, 288]          21,024\n",
      "          Dropout-63             [-1, 784, 288]               0\n",
      "           Linear-64              [-1, 784, 72]          20,808\n",
      "        LayerNorm-65              [-1, 784, 72]             144\n",
      "        LTAEBlock-66              [-1, 784, 72]               0\n",
      "           Conv2d-67           [-1, 40, 28, 28]           2,920\n",
      "      BatchNorm2d-68           [-1, 40, 28, 28]              80\n",
      "        Hardswish-69           [-1, 40, 28, 28]               0\n",
      "        Hardswish-70           [-1, 40, 28, 28]               0\n",
      " InvertedResidual-71           [-1, 40, 28, 28]               0\n",
      "           Conv2d-72          [-1, 120, 28, 28]           4,920\n",
      "      BatchNorm2d-73          [-1, 120, 28, 28]             240\n",
      "        Hardswish-74          [-1, 120, 28, 28]               0\n",
      "        Hardswish-75          [-1, 120, 28, 28]               0\n",
      "           Conv2d-76          [-1, 120, 28, 28]           1,200\n",
      "      BatchNorm2d-77          [-1, 120, 28, 28]             240\n",
      "        Hardswish-78          [-1, 120, 28, 28]               0\n",
      "        Hardswish-79          [-1, 120, 28, 28]               0\n",
      "MultiheadAttention-80  [[-1, 784, 120], [-1, 2, 2]]               0\n",
      "          Dropout-81             [-1, 784, 120]               0\n",
      "        LayerNorm-82             [-1, 784, 120]             240\n",
      "           Linear-83             [-1, 784, 480]          58,080\n",
      "          Dropout-84             [-1, 784, 480]               0\n",
      "           Linear-85             [-1, 784, 120]          57,720\n",
      "        LayerNorm-86             [-1, 784, 120]             240\n",
      "        LTAEBlock-87             [-1, 784, 120]               0\n",
      "           Conv2d-88           [-1, 40, 28, 28]           4,840\n",
      "      BatchNorm2d-89           [-1, 40, 28, 28]              80\n",
      "        Hardswish-90           [-1, 40, 28, 28]               0\n",
      "        Hardswish-91           [-1, 40, 28, 28]               0\n",
      " InvertedResidual-92           [-1, 40, 28, 28]               0\n",
      "           Conv2d-93          [-1, 120, 28, 28]           4,920\n",
      "      BatchNorm2d-94          [-1, 120, 28, 28]             240\n",
      "        Hardswish-95          [-1, 120, 28, 28]               0\n",
      "        Hardswish-96          [-1, 120, 28, 28]               0\n",
      "           Conv2d-97          [-1, 120, 14, 14]           1,200\n",
      "      BatchNorm2d-98          [-1, 120, 14, 14]             240\n",
      "        Hardswish-99          [-1, 120, 14, 14]               0\n",
      "       Hardswish-100          [-1, 120, 14, 14]               0\n",
      "MultiheadAttention-101  [[-1, 196, 120], [-1, 2, 2]]               0\n",
      "         Dropout-102             [-1, 196, 120]               0\n",
      "       LayerNorm-103             [-1, 196, 120]             240\n",
      "          Linear-104             [-1, 196, 480]          58,080\n",
      "         Dropout-105             [-1, 196, 480]               0\n",
      "          Linear-106             [-1, 196, 120]          57,720\n",
      "       LayerNorm-107             [-1, 196, 120]             240\n",
      "       LTAEBlock-108             [-1, 196, 120]               0\n",
      "          Conv2d-109           [-1, 40, 14, 14]           4,840\n",
      "     BatchNorm2d-110           [-1, 40, 14, 14]              80\n",
      "       Hardswish-111           [-1, 40, 14, 14]               0\n",
      "       Hardswish-112           [-1, 40, 14, 14]               0\n",
      "InvertedResidual-113           [-1, 40, 14, 14]               0\n",
      "          Conv2d-114          [-1, 120, 14, 14]           4,920\n",
      "     BatchNorm2d-115          [-1, 120, 14, 14]             240\n",
      "       Hardswish-116          [-1, 120, 14, 14]               0\n",
      "       Hardswish-117          [-1, 120, 14, 14]               0\n",
      "          Conv2d-118          [-1, 120, 14, 14]           1,200\n",
      "     BatchNorm2d-119          [-1, 120, 14, 14]             240\n",
      "       Hardswish-120          [-1, 120, 14, 14]               0\n",
      "       Hardswish-121          [-1, 120, 14, 14]               0\n",
      "MultiheadAttention-122  [[-1, 196, 120], [-1, 2, 2]]               0\n",
      "         Dropout-123             [-1, 196, 120]               0\n",
      "       LayerNorm-124             [-1, 196, 120]             240\n",
      "          Linear-125             [-1, 196, 480]          58,080\n",
      "         Dropout-126             [-1, 196, 480]               0\n",
      "          Linear-127             [-1, 196, 120]          57,720\n",
      "       LayerNorm-128             [-1, 196, 120]             240\n",
      "       LTAEBlock-129             [-1, 196, 120]               0\n",
      "          Conv2d-130           [-1, 48, 14, 14]           5,808\n",
      "     BatchNorm2d-131           [-1, 48, 14, 14]              96\n",
      "       Hardswish-132           [-1, 48, 14, 14]               0\n",
      "       Hardswish-133           [-1, 48, 14, 14]               0\n",
      "InvertedResidual-134           [-1, 48, 14, 14]               0\n",
      "          Conv2d-135          [-1, 144, 14, 14]           7,056\n",
      "     BatchNorm2d-136          [-1, 144, 14, 14]             288\n",
      "       Hardswish-137          [-1, 144, 14, 14]               0\n",
      "       Hardswish-138          [-1, 144, 14, 14]               0\n",
      "          Conv2d-139          [-1, 144, 14, 14]           1,440\n",
      "     BatchNorm2d-140          [-1, 144, 14, 14]             288\n",
      "       Hardswish-141          [-1, 144, 14, 14]               0\n",
      "       Hardswish-142          [-1, 144, 14, 14]               0\n",
      "MultiheadAttention-143  [[-1, 196, 144], [-1, 2, 2]]               0\n",
      "         Dropout-144             [-1, 196, 144]               0\n",
      "       LayerNorm-145             [-1, 196, 144]             288\n",
      "          Linear-146             [-1, 196, 576]          83,520\n",
      "         Dropout-147             [-1, 196, 576]               0\n",
      "          Linear-148             [-1, 196, 144]          83,088\n",
      "       LayerNorm-149             [-1, 196, 144]             288\n",
      "       LTAEBlock-150             [-1, 196, 144]               0\n",
      "          Conv2d-151           [-1, 48, 14, 14]           6,960\n",
      "     BatchNorm2d-152           [-1, 48, 14, 14]              96\n",
      "       Hardswish-153           [-1, 48, 14, 14]               0\n",
      "       Hardswish-154           [-1, 48, 14, 14]               0\n",
      "InvertedResidual-155           [-1, 48, 14, 14]               0\n",
      "          Conv2d-156          [-1, 144, 14, 14]           7,056\n",
      "     BatchNorm2d-157          [-1, 144, 14, 14]             288\n",
      "       Hardswish-158          [-1, 144, 14, 14]               0\n",
      "       Hardswish-159          [-1, 144, 14, 14]               0\n",
      "          Conv2d-160          [-1, 144, 14, 14]           1,440\n",
      "     BatchNorm2d-161          [-1, 144, 14, 14]             288\n",
      "       Hardswish-162          [-1, 144, 14, 14]               0\n",
      "       Hardswish-163          [-1, 144, 14, 14]               0\n",
      "MultiheadAttention-164  [[-1, 196, 144], [-1, 2, 2]]               0\n",
      "         Dropout-165             [-1, 196, 144]               0\n",
      "       LayerNorm-166             [-1, 196, 144]             288\n",
      "          Linear-167             [-1, 196, 576]          83,520\n",
      "         Dropout-168             [-1, 196, 576]               0\n",
      "          Linear-169             [-1, 196, 144]          83,088\n",
      "       LayerNorm-170             [-1, 196, 144]             288\n",
      "       LTAEBlock-171             [-1, 196, 144]               0\n",
      "          Conv2d-172           [-1, 96, 14, 14]          13,920\n",
      "     BatchNorm2d-173           [-1, 96, 14, 14]             192\n",
      "       Hardswish-174           [-1, 96, 14, 14]               0\n",
      "       Hardswish-175           [-1, 96, 14, 14]               0\n",
      "InvertedResidual-176           [-1, 96, 14, 14]               0\n",
      "          Conv2d-177          [-1, 288, 14, 14]          27,936\n",
      "     BatchNorm2d-178          [-1, 288, 14, 14]             576\n",
      "       Hardswish-179          [-1, 288, 14, 14]               0\n",
      "       Hardswish-180          [-1, 288, 14, 14]               0\n",
      "          Conv2d-181          [-1, 288, 14, 14]           2,880\n",
      "     BatchNorm2d-182          [-1, 288, 14, 14]             576\n",
      "       Hardswish-183          [-1, 288, 14, 14]               0\n",
      "       Hardswish-184          [-1, 288, 14, 14]               0\n",
      "MultiheadAttention-185  [[-1, 196, 288], [-1, 2, 2]]               0\n",
      "         Dropout-186             [-1, 196, 288]               0\n",
      "       LayerNorm-187             [-1, 196, 288]             576\n",
      "          Linear-188            [-1, 196, 1152]         332,928\n",
      "         Dropout-189            [-1, 196, 1152]               0\n",
      "          Linear-190             [-1, 196, 288]         332,064\n",
      "       LayerNorm-191             [-1, 196, 288]             576\n",
      "       LTAEBlock-192             [-1, 196, 288]               0\n",
      "          Conv2d-193           [-1, 96, 14, 14]          27,744\n",
      "     BatchNorm2d-194           [-1, 96, 14, 14]             192\n",
      "       Hardswish-195           [-1, 96, 14, 14]               0\n",
      "       Hardswish-196           [-1, 96, 14, 14]               0\n",
      "InvertedResidual-197           [-1, 96, 14, 14]               0\n",
      "          Conv2d-198          [-1, 288, 14, 14]          27,936\n",
      "     BatchNorm2d-199          [-1, 288, 14, 14]             576\n",
      "       Hardswish-200          [-1, 288, 14, 14]               0\n",
      "       Hardswish-201          [-1, 288, 14, 14]               0\n",
      "          Conv2d-202            [-1, 288, 7, 7]           2,880\n",
      "     BatchNorm2d-203            [-1, 288, 7, 7]             576\n",
      "       Hardswish-204            [-1, 288, 7, 7]               0\n",
      "       Hardswish-205            [-1, 288, 7, 7]               0\n",
      "MultiheadAttention-206  [[-1, 49, 288], [-1, 2, 2]]               0\n",
      "         Dropout-207              [-1, 49, 288]               0\n",
      "       LayerNorm-208              [-1, 49, 288]             576\n",
      "          Linear-209             [-1, 49, 1152]         332,928\n",
      "         Dropout-210             [-1, 49, 1152]               0\n",
      "          Linear-211              [-1, 49, 288]         332,064\n",
      "       LayerNorm-212              [-1, 49, 288]             576\n",
      "       LTAEBlock-213              [-1, 49, 288]               0\n",
      "          Conv2d-214             [-1, 96, 7, 7]          27,744\n",
      "     BatchNorm2d-215             [-1, 96, 7, 7]             192\n",
      "       Hardswish-216             [-1, 96, 7, 7]               0\n",
      "       Hardswish-217             [-1, 96, 7, 7]               0\n",
      "InvertedResidual-218             [-1, 96, 7, 7]               0\n",
      "          Conv2d-219            [-1, 576, 7, 7]          55,872\n",
      "     Hardsigmoid-220            [-1, 576, 7, 7]               0\n",
      "AdaptiveAvgPool2d-221            [-1, 576, 1, 1]               0\n",
      "          Linear-222                 [-1, 1024]         590,848\n",
      "     Hardsigmoid-223                 [-1, 1024]               0\n",
      "         Dropout-224                 [-1, 1024]               0\n",
      "          Linear-225                   [-1, 31]          31,775\n",
      "================================================================\n",
      "Total params: 2,942,591\n",
      "Trainable params: 2,942,591\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 112.47\n",
      "Params size (MB): 11.23\n",
      "Estimated Total Size (MB): 124.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mbv3_small_LTAE = LTAEMobileNetV3Small(num_classes=NUM_CLASSES).to(device)\n",
    "summary(mbv3_small_LTAE, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = torch.optim.Adam(mbv3_small_LTAE.parameters(), lr=0.001)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# check_point_path = f'{HOME}/cp/mbv3_small_LTAE/'\n",
    "\n",
    "# train(mbv3_small_LTAE, optimizer, criterion, train_loader, test_loader, 10, checkpoint_path=check_point_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 8, 64, 64]             216\n",
      "       BatchNorm2d-2            [-1, 8, 64, 64]              16\n",
      "         Hardswish-3            [-1, 8, 64, 64]               0\n",
      "            Conv2d-4            [-1, 8, 32, 32]              72\n",
      "       BatchNorm2d-5            [-1, 8, 32, 32]              16\n",
      "              ReLU-6            [-1, 8, 32, 32]               0\n",
      " AdaptiveAvgPool2d-7              [-1, 8, 1, 1]               0\n",
      "            Conv2d-8              [-1, 8, 1, 1]              72\n",
      "              ReLU-9              [-1, 8, 1, 1]               0\n",
      "           Conv2d-10              [-1, 8, 1, 1]              72\n",
      "      Hardsigmoid-11              [-1, 8, 1, 1]               0\n",
      "SqueezeExcitation-12            [-1, 8, 32, 32]               0\n",
      "           Conv2d-13            [-1, 8, 32, 32]              64\n",
      "      BatchNorm2d-14            [-1, 8, 32, 32]              16\n",
      " InvertedResidual-15            [-1, 8, 32, 32]               0\n",
      "           Conv2d-16           [-1, 24, 32, 32]             192\n",
      "      BatchNorm2d-17           [-1, 24, 32, 32]              48\n",
      "             ReLU-18           [-1, 24, 32, 32]               0\n",
      "           Conv2d-19           [-1, 24, 16, 16]             216\n",
      "      BatchNorm2d-20           [-1, 24, 16, 16]              48\n",
      "             ReLU-21           [-1, 24, 16, 16]               0\n",
      "           Conv2d-22            [-1, 8, 16, 16]             192\n",
      "      BatchNorm2d-23            [-1, 8, 16, 16]              16\n",
      " InvertedResidual-24            [-1, 8, 16, 16]               0\n",
      "           Conv2d-25           [-1, 24, 16, 16]             192\n",
      "      BatchNorm2d-26           [-1, 24, 16, 16]              48\n",
      "             ReLU-27           [-1, 24, 16, 16]               0\n",
      "           Conv2d-28           [-1, 24, 16, 16]             216\n",
      "      BatchNorm2d-29           [-1, 24, 16, 16]              48\n",
      "             ReLU-30           [-1, 24, 16, 16]               0\n",
      "           Conv2d-31            [-1, 8, 16, 16]             192\n",
      "      BatchNorm2d-32            [-1, 8, 16, 16]              16\n",
      " InvertedResidual-33            [-1, 8, 16, 16]               0\n",
      "           Conv2d-34           [-1, 24, 16, 16]             192\n",
      "      BatchNorm2d-35           [-1, 24, 16, 16]              48\n",
      "        Hardswish-36           [-1, 24, 16, 16]               0\n",
      "           Conv2d-37             [-1, 24, 8, 8]             600\n",
      "      BatchNorm2d-38             [-1, 24, 8, 8]              48\n",
      "        Hardswish-39             [-1, 24, 8, 8]               0\n",
      "AdaptiveAvgPool2d-40             [-1, 24, 1, 1]               0\n",
      "           Conv2d-41              [-1, 8, 1, 1]             200\n",
      "             ReLU-42              [-1, 8, 1, 1]               0\n",
      "           Conv2d-43             [-1, 24, 1, 1]             216\n",
      "      Hardsigmoid-44             [-1, 24, 1, 1]               0\n",
      "SqueezeExcitation-45             [-1, 24, 8, 8]               0\n",
      "           Conv2d-46             [-1, 16, 8, 8]             384\n",
      "      BatchNorm2d-47             [-1, 16, 8, 8]              32\n",
      " InvertedResidual-48             [-1, 16, 8, 8]               0\n",
      "           Conv2d-49             [-1, 64, 8, 8]           1,024\n",
      "      BatchNorm2d-50             [-1, 64, 8, 8]             128\n",
      "        Hardswish-51             [-1, 64, 8, 8]               0\n",
      "           Conv2d-52             [-1, 64, 8, 8]           1,600\n",
      "      BatchNorm2d-53             [-1, 64, 8, 8]             128\n",
      "        Hardswish-54             [-1, 64, 8, 8]               0\n",
      "AdaptiveAvgPool2d-55             [-1, 64, 1, 1]               0\n",
      "           Conv2d-56             [-1, 16, 1, 1]           1,040\n",
      "             ReLU-57             [-1, 16, 1, 1]               0\n",
      "           Conv2d-58             [-1, 64, 1, 1]           1,088\n",
      "      Hardsigmoid-59             [-1, 64, 1, 1]               0\n",
      "SqueezeExcitation-60             [-1, 64, 8, 8]               0\n",
      "           Conv2d-61             [-1, 16, 8, 8]           1,024\n",
      "      BatchNorm2d-62             [-1, 16, 8, 8]              32\n",
      " InvertedResidual-63             [-1, 16, 8, 8]               0\n",
      "           Conv2d-64             [-1, 64, 8, 8]           1,024\n",
      "      BatchNorm2d-65             [-1, 64, 8, 8]             128\n",
      "        Hardswish-66             [-1, 64, 8, 8]               0\n",
      "           Conv2d-67             [-1, 64, 8, 8]           1,600\n",
      "      BatchNorm2d-68             [-1, 64, 8, 8]             128\n",
      "        Hardswish-69             [-1, 64, 8, 8]               0\n",
      "AdaptiveAvgPool2d-70             [-1, 64, 1, 1]               0\n",
      "           Conv2d-71             [-1, 16, 1, 1]           1,040\n",
      "             ReLU-72             [-1, 16, 1, 1]               0\n",
      "           Conv2d-73             [-1, 64, 1, 1]           1,088\n",
      "      Hardsigmoid-74             [-1, 64, 1, 1]               0\n",
      "SqueezeExcitation-75             [-1, 64, 8, 8]               0\n",
      "           Conv2d-76             [-1, 16, 8, 8]           1,024\n",
      "      BatchNorm2d-77             [-1, 16, 8, 8]              32\n",
      " InvertedResidual-78             [-1, 16, 8, 8]               0\n",
      "           Conv2d-79             [-1, 32, 8, 8]             512\n",
      "      BatchNorm2d-80             [-1, 32, 8, 8]              64\n",
      "        Hardswish-81             [-1, 32, 8, 8]               0\n",
      "           Conv2d-82             [-1, 32, 8, 8]             800\n",
      "      BatchNorm2d-83             [-1, 32, 8, 8]              64\n",
      "        Hardswish-84             [-1, 32, 8, 8]               0\n",
      "AdaptiveAvgPool2d-85             [-1, 32, 1, 1]               0\n",
      "           Conv2d-86              [-1, 8, 1, 1]             264\n",
      "             ReLU-87              [-1, 8, 1, 1]               0\n",
      "           Conv2d-88             [-1, 32, 1, 1]             288\n",
      "      Hardsigmoid-89             [-1, 32, 1, 1]               0\n",
      "SqueezeExcitation-90             [-1, 32, 8, 8]               0\n",
      "           Conv2d-91             [-1, 16, 8, 8]             512\n",
      "      BatchNorm2d-92             [-1, 16, 8, 8]              32\n",
      " InvertedResidual-93             [-1, 16, 8, 8]               0\n",
      "           Conv2d-94             [-1, 40, 8, 8]             640\n",
      "      BatchNorm2d-95             [-1, 40, 8, 8]              80\n",
      "        Hardswish-96             [-1, 40, 8, 8]               0\n",
      "           Conv2d-97             [-1, 40, 8, 8]           1,000\n",
      "      BatchNorm2d-98             [-1, 40, 8, 8]              80\n",
      "        Hardswish-99             [-1, 40, 8, 8]               0\n",
      "AdaptiveAvgPool2d-100             [-1, 40, 1, 1]               0\n",
      "          Conv2d-101             [-1, 16, 1, 1]             656\n",
      "            ReLU-102             [-1, 16, 1, 1]               0\n",
      "          Conv2d-103             [-1, 40, 1, 1]             680\n",
      "     Hardsigmoid-104             [-1, 40, 1, 1]               0\n",
      "SqueezeExcitation-105             [-1, 40, 8, 8]               0\n",
      "          Conv2d-106             [-1, 16, 8, 8]             640\n",
      "     BatchNorm2d-107             [-1, 16, 8, 8]              32\n",
      "InvertedResidual-108             [-1, 16, 8, 8]               0\n",
      "          Conv2d-109             [-1, 72, 8, 8]           1,152\n",
      "     BatchNorm2d-110             [-1, 72, 8, 8]             144\n",
      "       Hardswish-111             [-1, 72, 8, 8]               0\n",
      "          Conv2d-112             [-1, 72, 4, 4]           1,800\n",
      "     BatchNorm2d-113             [-1, 72, 4, 4]             144\n",
      "       Hardswish-114             [-1, 72, 4, 4]               0\n",
      "AdaptiveAvgPool2d-115             [-1, 72, 1, 1]               0\n",
      "          Conv2d-116             [-1, 24, 1, 1]           1,752\n",
      "            ReLU-117             [-1, 24, 1, 1]               0\n",
      "          Conv2d-118             [-1, 72, 1, 1]           1,800\n",
      "     Hardsigmoid-119             [-1, 72, 1, 1]               0\n",
      "SqueezeExcitation-120             [-1, 72, 4, 4]               0\n",
      "          Conv2d-121             [-1, 24, 4, 4]           1,728\n",
      "     BatchNorm2d-122             [-1, 24, 4, 4]              48\n",
      "InvertedResidual-123             [-1, 24, 4, 4]               0\n",
      "          Conv2d-124            [-1, 144, 4, 4]           3,456\n",
      "     BatchNorm2d-125            [-1, 144, 4, 4]             288\n",
      "       Hardswish-126            [-1, 144, 4, 4]               0\n",
      "          Conv2d-127            [-1, 144, 4, 4]           3,600\n",
      "     BatchNorm2d-128            [-1, 144, 4, 4]             288\n",
      "       Hardswish-129            [-1, 144, 4, 4]               0\n",
      "AdaptiveAvgPool2d-130            [-1, 144, 1, 1]               0\n",
      "          Conv2d-131             [-1, 40, 1, 1]           5,800\n",
      "            ReLU-132             [-1, 40, 1, 1]               0\n",
      "          Conv2d-133            [-1, 144, 1, 1]           5,904\n",
      "     Hardsigmoid-134            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-135            [-1, 144, 4, 4]               0\n",
      "          Conv2d-136             [-1, 24, 4, 4]           3,456\n",
      "     BatchNorm2d-137             [-1, 24, 4, 4]              48\n",
      "InvertedResidual-138             [-1, 24, 4, 4]               0\n",
      "          Conv2d-139            [-1, 144, 4, 4]           3,456\n",
      "     BatchNorm2d-140            [-1, 144, 4, 4]             288\n",
      "       Hardswish-141            [-1, 144, 4, 4]               0\n",
      "          Conv2d-142            [-1, 144, 4, 4]           3,600\n",
      "     BatchNorm2d-143            [-1, 144, 4, 4]             288\n",
      "       Hardswish-144            [-1, 144, 4, 4]               0\n",
      "AdaptiveAvgPool2d-145            [-1, 144, 1, 1]               0\n",
      "          Conv2d-146             [-1, 40, 1, 1]           5,800\n",
      "            ReLU-147             [-1, 40, 1, 1]               0\n",
      "          Conv2d-148            [-1, 144, 1, 1]           5,904\n",
      "     Hardsigmoid-149            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-150            [-1, 144, 4, 4]               0\n",
      "          Conv2d-151             [-1, 24, 4, 4]           3,456\n",
      "     BatchNorm2d-152             [-1, 24, 4, 4]              48\n",
      "InvertedResidual-153             [-1, 24, 4, 4]               0\n",
      "          Conv2d-154            [-1, 144, 4, 4]           3,456\n",
      "     BatchNorm2d-155            [-1, 144, 4, 4]             288\n",
      "       Hardswish-156            [-1, 144, 4, 4]               0\n",
      "AdaptiveAvgPool2d-157            [-1, 144, 1, 1]               0\n",
      "          Linear-158                  [-1, 256]          37,120\n",
      "       Hardswish-159                  [-1, 256]               0\n",
      "         Dropout-160                  [-1, 256]               0\n",
      "          Linear-161                   [-1, 31]           7,967\n",
      "================================================================\n",
      "Total params: 125,239\n",
      "Trainable params: 125,239\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 3.74\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 4.41\n",
      "----------------------------------------------------------------\n",
      "Number of FLOPs: 0.006198 GFLOPs (6.20 MFLOPs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(6198479.)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbv3_reduce = mobilenet_v3_small(weights=None, width_mult=0.25, num_classes=31)\n",
    "# mbv_3_small_ref.classifier[-1] = nn.Linear(mbv_3_small_ref.classifier[-1].in_features, NUM_CLASSES)\n",
    "mbv3_reduce = mbv3_reduce.to(device)\n",
    "summary(mbv3_reduce, (3, IMAGE_SIZE, IMAGE_SIZE))\n",
    "count_model_param_flops(model=mbv3_reduce.cpu().eval(), input_res=IMAGE_SIZE, multiply_adds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set, test_set = torch.utils.data.random_split(dslr_dataset, [0.8,0.2])\n",
    "train_loader = DataLoader(amazon_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(dslr_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(mbv3_reduce.parameters(), lr=0.001)\n",
    "\n",
    "check_point_path = f'{HOME}/newcp/pre2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖Training on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀Training Epoch [1/100]: 100%|██████████| 226/226 [00:16<00:00, 13.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTrain loss: 0.16299070115897346\n",
      "\tTrain acc: 0.27879291251384275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄Testing: 100%|██████████| 32/32 [00:05<00:00,  6.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest loss: 0.21019215504807162\n",
      "\tTest acc: 0.15060240963855423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀Training Epoch [2/100]: 100%|██████████| 226/226 [00:17<00:00, 13.13batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTrain loss: 0.13301405663770166\n",
      "\tTrain acc: 0.4003322259136213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄Testing: 100%|██████████| 32/32 [00:05<00:00,  5.99batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest loss: 0.21945139945271502\n",
      "\tTest acc: 0.142570281124498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀Training Epoch [3/100]: 100%|██████████| 226/226 [00:16<00:00, 13.41batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTrain loss: 0.11889225478848217\n",
      "\tTrain acc: 0.4601328903654485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄Testing: 100%|██████████| 32/32 [00:05<00:00,  6.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest loss: 0.2164306534102643\n",
      "\tTest acc: 0.20682730923694778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀Training Epoch [4/100]: 100%|██████████| 226/226 [00:16<00:00, 13.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTrain loss: 0.1051649580630221\n",
      "\tTrain acc: 0.5274086378737541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄Testing: 100%|██████████| 32/32 [00:05<00:00,  6.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest loss: 0.18789321734723316\n",
      "\tTest acc: 0.20883534136546184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀Training Epoch [5/100]: 100%|██████████| 226/226 [00:16<00:00, 13.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTrain loss: 0.09432869311318973\n",
      "\tTrain acc: 0.563953488372093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄Testing: 100%|██████████| 32/32 [00:05<00:00,  6.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest loss: 0.19792726276868797\n",
      "\tTest acc: 0.21485943775100402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀Training Epoch [6/100]: 100%|██████████| 226/226 [00:16<00:00, 13.49batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTrain loss: 0.08595663889962045\n",
      "\tTrain acc: 0.5985603543743079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄Testing: 100%|██████████| 32/32 [00:05<00:00,  6.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest loss: 0.19779770465261007\n",
      "\tTest acc: 0.2429718875502008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀Training Epoch [7/100]: 100%|██████████| 226/226 [00:16<00:00, 13.59batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tTrain loss: 0.07808307932064779\n",
      "\tTrain acc: 0.6273532668881506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄Testing: 100%|██████████| 32/32 [00:05<00:00,  6.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest loss: 0.22456915024293952\n",
      "\tTest acc: 0.21686746987951808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🚀Training Epoch [8/100]:  77%|███████▋  | 174/226 [00:12<00:03, 13.41batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train(mbv3_reduce, optimizer, criterion, train_loader, test_loader, \u001b[38;5;241m100\u001b[39m, checkpoint_path\u001b[38;5;241m=\u001b[39mcheck_point_path, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[21], line 32\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, opt, loss_fn, train_loader, test_loader, epochs, checkpoint_path, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     31\u001b[0m train_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m🚀Training Epoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, label \u001b[38;5;129;01min\u001b[39;00m train_bar:\n\u001b[1;32m     33\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     34\u001b[0m     label \u001b[38;5;241m=\u001b[39m label\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataset.py:350\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets[dataset_idx][sample_idx]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/datasets/folder.py:247\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/_presets.py:63\u001b[0m, in \u001b[0;36mImageClassification.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     61\u001b[0m     img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpil_to_tensor(img)\n\u001b[1;32m     62\u001b[0m img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconvert_image_dtype(img, torch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m---> 63\u001b[0m img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(img, mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstd)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/functional.py:350\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mnormalize(tensor, mean\u001b[38;5;241m=\u001b[39mmean, std\u001b[38;5;241m=\u001b[39mstd, inplace\u001b[38;5;241m=\u001b[39minplace)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/_functional_tensor.py:926\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m std\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    925\u001b[0m     std \u001b[38;5;241m=\u001b[39m std\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39msub_(mean)\u001b[38;5;241m.\u001b[39mdiv_(std)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(mbv3_reduce, optimizer, criterion, train_loader, test_loader, 100, checkpoint_path=check_point_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "\n",
    "# Gradient Reversal Layer for DANN\n",
    "class GradientReversal(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.alpha, None\n",
    "\n",
    "# Domain classifier for DANN\n",
    "class DomainClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DomainClassifier, self).__init__()\n",
    "        \n",
    "        # Classify domain based on features\n",
    "        self.domain_classifier = nn.Sequential(\n",
    "            nn.Linear(144, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 2)  # Binary output (0: source, 1: target)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features, alpha):\n",
    "        # Apply gradient reversal to the features\n",
    "        reversed_features = GradientReversal.apply(features, alpha)\n",
    "        \n",
    "        # Classify the domain\n",
    "        domain_output = self.domain_classifier(reversed_features)\n",
    "        return domain_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StudentModelMBV3SmallReduce(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentModelMBV3SmallReduce, self).__init__()\n",
    "        self.mbv3 = mobilenet_v3_small(weights=None, width_mult=0.25, num_classes=NUM_CLASSES)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.mbv3.features(x)\n",
    "        x = self.mbv3.avgpool(x)\n",
    "        features = x.view(x.size(0), -1)\n",
    "        x = self.mbv3.classifier(features)\n",
    "        return x, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dann(student_model, teacher_model, domain_classifier, source_loader, target_loader,\n",
    "               num_epochs,\n",
    "               optimizer, criterion_class, criterion_domain, alpha, temperature, checkpoint_path, device):\n",
    "    \n",
    "    training_logs = {\"train_loss\": [], \"train_src_acc\": [], \"train_tar_acc\": []}\n",
    "    epoch_number = 0\n",
    "    best_test_loss = float('inf')\n",
    "    \n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    domain_classifier.to(device)\n",
    "    \n",
    "    for param in teacher_model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    if checkpoint_path:\n",
    "      if os.path.exists(checkpoint_path + 'model.pth'):\n",
    "        student_model.load_state_dict(torch.load(checkpoint_path + 'model.pth', weights_only=True, map_location=device))\n",
    "\n",
    "      if os.path.exists(checkpoint_path + 'opt.pth'):\n",
    "        optimizer.load_state_dict(torch.load(checkpoint_path + 'opt.pth', weights_only=True, map_location=device))\n",
    "\n",
    "      if os.path.exists(checkpoint_path + 'training_logs.pth'):\n",
    "        training_logs = torch.load(checkpoint_path + 'training_logs.pth', weights_only=True)\n",
    "        epoch_number = len(training_logs['train_loss'])\n",
    "        best_test_loss = min(best_test_loss, min(training_logs['test_loss']))\n",
    "    \n",
    "    for i in range(epoch_number):\n",
    "        print(f\"Epochs {i+1}\".ljust(10), end='')\n",
    "        for k, v in training_logs.items():\n",
    "            print(f\"{k}: {v[i]:.5f}\", end=\" \")\n",
    "        print()\n",
    "        \n",
    "    for epoch in range(epoch_number,num_epochs):\n",
    "        student_model.train()\n",
    "        domain_classifier.train()\n",
    "        \n",
    "        p = epoch / num_epochs\n",
    "        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n",
    "\n",
    "        train_loss, train_src_correct, train_tar_correct = 0, 0, 0\n",
    "        for (source_data, source_labels), (target_data, target_labels) in zip(source_loader, target_loader):\n",
    "            source_data, source_labels = source_data.to(device), source_labels.to(device)\n",
    "            target_data, target_labels = target_data.to(device), target_labels.to(device)\n",
    "            \n",
    "            # Forward pass through student model for source domain\n",
    "            class_output, source_features = student_model(source_data)\n",
    "            loss_classification = criterion_class(class_output, source_labels)\n",
    "            \n",
    "            # Forward pass through student model for target domain (just features)\n",
    "            _, target_features = student_model(target_data)\n",
    "            \n",
    "            # Domain classifier loss (DANN)\n",
    "            domain_output_source = domain_classifier(source_features, alpha)\n",
    "            domain_output_target = domain_classifier(target_features, alpha)\n",
    "            \n",
    "            domain_labels_source = torch.zeros(source_data.size(0)).long().to(device)\n",
    "            domain_labels_target = torch.ones(target_data.size(0)).long().to(device)\n",
    "            \n",
    "            loss_domain_source = criterion_domain(domain_output_source, domain_labels_source)\n",
    "            loss_domain_target = criterion_domain(domain_output_target, domain_labels_target)\n",
    "            loss_domain = (loss_domain_source + loss_domain_target) / 2\n",
    "            \n",
    "            # Knowledge distillation loss\n",
    "            with torch.no_grad():\n",
    "                teacher_output = teacher_model(source_data)\n",
    "                \n",
    "            loss_distillation = F.kl_div(\n",
    "                F.log_softmax(class_output / temperature, dim=1),\n",
    "                F.softmax(teacher_output / temperature, dim=1),\n",
    "                reduction='batchmean'\n",
    "            ) * (temperature ** 2)\n",
    "\n",
    "            # Total loss\n",
    "            loss = loss_classification + loss_domain + loss_distillation\n",
    "            \n",
    "            loss = loss_classification + loss_domain\n",
    "\n",
    "            # Backprop and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "              class_prediction_s, _ = student_model(source_data)\n",
    "              class_prediction_t, _ = student_model(target_data)\n",
    "            \n",
    "            print(f'[{epoch}] '\n",
    "                  f'class loss: {loss_classification.item():.4f} '\n",
    "                  f'source_domain_loss: {loss_domain_source.item():.4f} '\n",
    "                  f'target_domain_loss: {loss_domain_target.item():.4f} '\n",
    "                  f'grl_lambda: {alpha:.3f}'\n",
    "                  )\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_src_correct += (class_prediction_s.argmax(1) == source_labels).float().sum().item()\n",
    "            train_tar_correct += (class_prediction_t.argmax(1) == target_labels).float().sum().item()\n",
    "\n",
    "\n",
    "        training_logs[\"train_src_acc\"].append(train_src_correct / len(source_loader.dataset))#.dataset))\n",
    "        training_logs[\"train_tar_acc\"].append(train_tar_correct / len(target_loader.dataset))#.dataset))\n",
    "        training_logs[\"train_loss\"].append(train_loss / len(source_loader))\n",
    "        \n",
    "        print(f'Epoch: {epoch} || \\\n",
    "        Train_src_acc: {train_src_correct / len(Dl_source.dataset)}, \\\n",
    "        Train_tar_acc: {train_tar_correct / len(Dl_target.dataset)}, \\\n",
    "        Train_loss: {train_loss / len(Dl_source)}'\n",
    "        )\n",
    "        \n",
    "        if checkpoint_path:\n",
    "            torch.save(student_model.state_dict(), checkpoint_path + \"model.pth\")\n",
    "            torch.save(optimizer.state_dict(), checkpoint_path + \"opt.pth\")\n",
    "            torch.save(training_logs, checkpoint_path + 'training_logs.pth')\n",
    "            if best_test_loss > train_tar_correct / len(target_loader.dataset):\n",
    "               torch.save(student_model.state_dict(), checkpoint_path + \"best_model.pth\")\n",
    "               best_test_loss = train_tar_correct / len(target_loader.dataset)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 8, 112, 112]             216\n",
      "       BatchNorm2d-2          [-1, 8, 112, 112]              16\n",
      "         Hardswish-3          [-1, 8, 112, 112]               0\n",
      "            Conv2d-4            [-1, 8, 56, 56]              72\n",
      "       BatchNorm2d-5            [-1, 8, 56, 56]              16\n",
      "              ReLU-6            [-1, 8, 56, 56]               0\n",
      " AdaptiveAvgPool2d-7              [-1, 8, 1, 1]               0\n",
      "            Conv2d-8              [-1, 8, 1, 1]              72\n",
      "              ReLU-9              [-1, 8, 1, 1]               0\n",
      "           Conv2d-10              [-1, 8, 1, 1]              72\n",
      "      Hardsigmoid-11              [-1, 8, 1, 1]               0\n",
      "SqueezeExcitation-12            [-1, 8, 56, 56]               0\n",
      "           Conv2d-13            [-1, 8, 56, 56]              64\n",
      "      BatchNorm2d-14            [-1, 8, 56, 56]              16\n",
      " InvertedResidual-15            [-1, 8, 56, 56]               0\n",
      "           Conv2d-16           [-1, 24, 56, 56]             192\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
      "             ReLU-18           [-1, 24, 56, 56]               0\n",
      "           Conv2d-19           [-1, 24, 28, 28]             216\n",
      "      BatchNorm2d-20           [-1, 24, 28, 28]              48\n",
      "             ReLU-21           [-1, 24, 28, 28]               0\n",
      "           Conv2d-22            [-1, 8, 28, 28]             192\n",
      "      BatchNorm2d-23            [-1, 8, 28, 28]              16\n",
      " InvertedResidual-24            [-1, 8, 28, 28]               0\n",
      "           Conv2d-25           [-1, 24, 28, 28]             192\n",
      "      BatchNorm2d-26           [-1, 24, 28, 28]              48\n",
      "             ReLU-27           [-1, 24, 28, 28]               0\n",
      "           Conv2d-28           [-1, 24, 28, 28]             216\n",
      "      BatchNorm2d-29           [-1, 24, 28, 28]              48\n",
      "             ReLU-30           [-1, 24, 28, 28]               0\n",
      "           Conv2d-31            [-1, 8, 28, 28]             192\n",
      "      BatchNorm2d-32            [-1, 8, 28, 28]              16\n",
      " InvertedResidual-33            [-1, 8, 28, 28]               0\n",
      "           Conv2d-34           [-1, 24, 28, 28]             192\n",
      "      BatchNorm2d-35           [-1, 24, 28, 28]              48\n",
      "        Hardswish-36           [-1, 24, 28, 28]               0\n",
      "           Conv2d-37           [-1, 24, 14, 14]             600\n",
      "      BatchNorm2d-38           [-1, 24, 14, 14]              48\n",
      "        Hardswish-39           [-1, 24, 14, 14]               0\n",
      "AdaptiveAvgPool2d-40             [-1, 24, 1, 1]               0\n",
      "           Conv2d-41              [-1, 8, 1, 1]             200\n",
      "             ReLU-42              [-1, 8, 1, 1]               0\n",
      "           Conv2d-43             [-1, 24, 1, 1]             216\n",
      "      Hardsigmoid-44             [-1, 24, 1, 1]               0\n",
      "SqueezeExcitation-45           [-1, 24, 14, 14]               0\n",
      "           Conv2d-46           [-1, 16, 14, 14]             384\n",
      "      BatchNorm2d-47           [-1, 16, 14, 14]              32\n",
      " InvertedResidual-48           [-1, 16, 14, 14]               0\n",
      "           Conv2d-49           [-1, 64, 14, 14]           1,024\n",
      "      BatchNorm2d-50           [-1, 64, 14, 14]             128\n",
      "        Hardswish-51           [-1, 64, 14, 14]               0\n",
      "           Conv2d-52           [-1, 64, 14, 14]           1,600\n",
      "      BatchNorm2d-53           [-1, 64, 14, 14]             128\n",
      "        Hardswish-54           [-1, 64, 14, 14]               0\n",
      "AdaptiveAvgPool2d-55             [-1, 64, 1, 1]               0\n",
      "           Conv2d-56             [-1, 16, 1, 1]           1,040\n",
      "             ReLU-57             [-1, 16, 1, 1]               0\n",
      "           Conv2d-58             [-1, 64, 1, 1]           1,088\n",
      "      Hardsigmoid-59             [-1, 64, 1, 1]               0\n",
      "SqueezeExcitation-60           [-1, 64, 14, 14]               0\n",
      "           Conv2d-61           [-1, 16, 14, 14]           1,024\n",
      "      BatchNorm2d-62           [-1, 16, 14, 14]              32\n",
      " InvertedResidual-63           [-1, 16, 14, 14]               0\n",
      "           Conv2d-64           [-1, 64, 14, 14]           1,024\n",
      "      BatchNorm2d-65           [-1, 64, 14, 14]             128\n",
      "        Hardswish-66           [-1, 64, 14, 14]               0\n",
      "           Conv2d-67           [-1, 64, 14, 14]           1,600\n",
      "      BatchNorm2d-68           [-1, 64, 14, 14]             128\n",
      "        Hardswish-69           [-1, 64, 14, 14]               0\n",
      "AdaptiveAvgPool2d-70             [-1, 64, 1, 1]               0\n",
      "           Conv2d-71             [-1, 16, 1, 1]           1,040\n",
      "             ReLU-72             [-1, 16, 1, 1]               0\n",
      "           Conv2d-73             [-1, 64, 1, 1]           1,088\n",
      "      Hardsigmoid-74             [-1, 64, 1, 1]               0\n",
      "SqueezeExcitation-75           [-1, 64, 14, 14]               0\n",
      "           Conv2d-76           [-1, 16, 14, 14]           1,024\n",
      "      BatchNorm2d-77           [-1, 16, 14, 14]              32\n",
      " InvertedResidual-78           [-1, 16, 14, 14]               0\n",
      "           Conv2d-79           [-1, 32, 14, 14]             512\n",
      "      BatchNorm2d-80           [-1, 32, 14, 14]              64\n",
      "        Hardswish-81           [-1, 32, 14, 14]               0\n",
      "           Conv2d-82           [-1, 32, 14, 14]             800\n",
      "      BatchNorm2d-83           [-1, 32, 14, 14]              64\n",
      "        Hardswish-84           [-1, 32, 14, 14]               0\n",
      "AdaptiveAvgPool2d-85             [-1, 32, 1, 1]               0\n",
      "           Conv2d-86              [-1, 8, 1, 1]             264\n",
      "             ReLU-87              [-1, 8, 1, 1]               0\n",
      "           Conv2d-88             [-1, 32, 1, 1]             288\n",
      "      Hardsigmoid-89             [-1, 32, 1, 1]               0\n",
      "SqueezeExcitation-90           [-1, 32, 14, 14]               0\n",
      "           Conv2d-91           [-1, 16, 14, 14]             512\n",
      "      BatchNorm2d-92           [-1, 16, 14, 14]              32\n",
      " InvertedResidual-93           [-1, 16, 14, 14]               0\n",
      "           Conv2d-94           [-1, 40, 14, 14]             640\n",
      "      BatchNorm2d-95           [-1, 40, 14, 14]              80\n",
      "        Hardswish-96           [-1, 40, 14, 14]               0\n",
      "           Conv2d-97           [-1, 40, 14, 14]           1,000\n",
      "      BatchNorm2d-98           [-1, 40, 14, 14]              80\n",
      "        Hardswish-99           [-1, 40, 14, 14]               0\n",
      "AdaptiveAvgPool2d-100             [-1, 40, 1, 1]               0\n",
      "          Conv2d-101             [-1, 16, 1, 1]             656\n",
      "            ReLU-102             [-1, 16, 1, 1]               0\n",
      "          Conv2d-103             [-1, 40, 1, 1]             680\n",
      "     Hardsigmoid-104             [-1, 40, 1, 1]               0\n",
      "SqueezeExcitation-105           [-1, 40, 14, 14]               0\n",
      "          Conv2d-106           [-1, 16, 14, 14]             640\n",
      "     BatchNorm2d-107           [-1, 16, 14, 14]              32\n",
      "InvertedResidual-108           [-1, 16, 14, 14]               0\n",
      "          Conv2d-109           [-1, 72, 14, 14]           1,152\n",
      "     BatchNorm2d-110           [-1, 72, 14, 14]             144\n",
      "       Hardswish-111           [-1, 72, 14, 14]               0\n",
      "          Conv2d-112             [-1, 72, 7, 7]           1,800\n",
      "     BatchNorm2d-113             [-1, 72, 7, 7]             144\n",
      "       Hardswish-114             [-1, 72, 7, 7]               0\n",
      "AdaptiveAvgPool2d-115             [-1, 72, 1, 1]               0\n",
      "          Conv2d-116             [-1, 24, 1, 1]           1,752\n",
      "            ReLU-117             [-1, 24, 1, 1]               0\n",
      "          Conv2d-118             [-1, 72, 1, 1]           1,800\n",
      "     Hardsigmoid-119             [-1, 72, 1, 1]               0\n",
      "SqueezeExcitation-120             [-1, 72, 7, 7]               0\n",
      "          Conv2d-121             [-1, 24, 7, 7]           1,728\n",
      "     BatchNorm2d-122             [-1, 24, 7, 7]              48\n",
      "InvertedResidual-123             [-1, 24, 7, 7]               0\n",
      "          Conv2d-124            [-1, 144, 7, 7]           3,456\n",
      "     BatchNorm2d-125            [-1, 144, 7, 7]             288\n",
      "       Hardswish-126            [-1, 144, 7, 7]               0\n",
      "          Conv2d-127            [-1, 144, 7, 7]           3,600\n",
      "     BatchNorm2d-128            [-1, 144, 7, 7]             288\n",
      "       Hardswish-129            [-1, 144, 7, 7]               0\n",
      "AdaptiveAvgPool2d-130            [-1, 144, 1, 1]               0\n",
      "          Conv2d-131             [-1, 40, 1, 1]           5,800\n",
      "            ReLU-132             [-1, 40, 1, 1]               0\n",
      "          Conv2d-133            [-1, 144, 1, 1]           5,904\n",
      "     Hardsigmoid-134            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-135            [-1, 144, 7, 7]               0\n",
      "          Conv2d-136             [-1, 24, 7, 7]           3,456\n",
      "     BatchNorm2d-137             [-1, 24, 7, 7]              48\n",
      "InvertedResidual-138             [-1, 24, 7, 7]               0\n",
      "          Conv2d-139            [-1, 144, 7, 7]           3,456\n",
      "     BatchNorm2d-140            [-1, 144, 7, 7]             288\n",
      "       Hardswish-141            [-1, 144, 7, 7]               0\n",
      "          Conv2d-142            [-1, 144, 7, 7]           3,600\n",
      "     BatchNorm2d-143            [-1, 144, 7, 7]             288\n",
      "       Hardswish-144            [-1, 144, 7, 7]               0\n",
      "AdaptiveAvgPool2d-145            [-1, 144, 1, 1]               0\n",
      "          Conv2d-146             [-1, 40, 1, 1]           5,800\n",
      "            ReLU-147             [-1, 40, 1, 1]               0\n",
      "          Conv2d-148            [-1, 144, 1, 1]           5,904\n",
      "     Hardsigmoid-149            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-150            [-1, 144, 7, 7]               0\n",
      "          Conv2d-151             [-1, 24, 7, 7]           3,456\n",
      "     BatchNorm2d-152             [-1, 24, 7, 7]              48\n",
      "InvertedResidual-153             [-1, 24, 7, 7]               0\n",
      "          Conv2d-154            [-1, 144, 7, 7]           3,456\n",
      "     BatchNorm2d-155            [-1, 144, 7, 7]             288\n",
      "       Hardswish-156            [-1, 144, 7, 7]               0\n",
      "AdaptiveAvgPool2d-157            [-1, 144, 1, 1]               0\n",
      "          Linear-158                  [-1, 256]          37,120\n",
      "       Hardswish-159                  [-1, 256]               0\n",
      "         Dropout-160                  [-1, 256]               0\n",
      "          Linear-161                   [-1, 31]           7,967\n",
      "================================================================\n",
      "Total params: 125,239\n",
      "Trainable params: 125,239\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 11.42\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 12.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "teacher_model = mobilenet_v3_large(num_classes=NUM_CLASSES).to(device)\n",
    "teacher_model.load_state_dict(torch.load(f'{HOME}/cp/mbv3_large_ref/best_model.pth', weights_only=True))\n",
    "# summary(teacher_model, (3, 224, 224))\n",
    "# student_model = mobilenet_v3_small(weights=None, width_mult=0.25, num_classes=NUM_CLASSES).to(device)\n",
    "# print(student_model.features)\n",
    "# print(student_model.avgpool)\n",
    "student_model = StudentModelMBV3SmallReduce().to(device)\n",
    "student_model.mbv3.load_state_dict(torch.load(f'{HOME}/cp/mbv3_small_reduce/best_model.pth', weights_only=True))\n",
    "summary(student_model, (3, 224, 224))\n",
    "domain_classifier = DomainClassifier()\n",
    "optim = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "source_loader = DataLoader(amazon_dataset, batch_size=32, shuffle=True)\n",
    "target_loader = DataLoader(dslr_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "criterion_class = nn.CrossEntropyLoss()  # For classification task\n",
    "criterion_domain = nn.CrossEntropyLoss()  # For domain classification task\n",
    "criterion_distillation = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "checkpoint_path = f'{HOME}/cp/DANN_A2D/'\n",
    "\n",
    "alpha = 0.1  # You may want to increase this gradually during training\n",
    "temperature = 3.0  # For softening the teacher's logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] class loss: 4.0537 source_domain_loss: 0.7631 target_domain_loss: 0.6261 grl_lambda: 0.000\n",
      "[0] class loss: 2.4414 source_domain_loss: 0.7607 target_domain_loss: 0.6294 grl_lambda: 0.000\n",
      "[0] class loss: 3.5196 source_domain_loss: 0.7590 target_domain_loss: 0.6288 grl_lambda: 0.000\n",
      "[0] class loss: 1.9956 source_domain_loss: 0.7588 target_domain_loss: 0.6332 grl_lambda: 0.000\n",
      "[0] class loss: 2.1725 source_domain_loss: 0.7588 target_domain_loss: 0.6293 grl_lambda: 0.000\n",
      "[0] class loss: 2.4339 source_domain_loss: 0.7597 target_domain_loss: 0.6310 grl_lambda: 0.000\n",
      "[0] class loss: 2.3472 source_domain_loss: 0.7636 target_domain_loss: 0.6288 grl_lambda: 0.000\n",
      "[0] class loss: 2.7420 source_domain_loss: 0.7625 target_domain_loss: 0.6275 grl_lambda: 0.000\n",
      "[0] class loss: 2.9229 source_domain_loss: 0.7631 target_domain_loss: 0.6297 grl_lambda: 0.000\n",
      "[0] class loss: 2.0477 source_domain_loss: 0.7647 target_domain_loss: 0.6292 grl_lambda: 0.000\n",
      "[0] class loss: 2.1571 source_domain_loss: 0.7624 target_domain_loss: 0.6268 grl_lambda: 0.000\n",
      "[0] class loss: 2.4339 source_domain_loss: 0.7631 target_domain_loss: 0.6309 grl_lambda: 0.000\n",
      "[0] class loss: 2.3832 source_domain_loss: 0.7630 target_domain_loss: 0.6268 grl_lambda: 0.000\n",
      "[0] class loss: 1.6773 source_domain_loss: 0.7630 target_domain_loss: 0.6320 grl_lambda: 0.000\n",
      "[0] class loss: 2.2366 source_domain_loss: 0.7622 target_domain_loss: 0.6299 grl_lambda: 0.000\n",
      "[0] class loss: 2.9895 source_domain_loss: 0.7638 target_domain_loss: 0.6283 grl_lambda: 0.000\n",
      "Epoch: 0 ||         Train_src_acc: 0.16108108108108107,         Train_tar_acc: 0.1308108108108108,         Train_loss: 0.4455490667244484\n",
      "[1] class loss: 2.7641 source_domain_loss: 0.7606 target_domain_loss: 0.6283 grl_lambda: 0.050\n",
      "[1] class loss: 2.1129 source_domain_loss: 0.7599 target_domain_loss: 0.6276 grl_lambda: 0.050\n",
      "[1] class loss: 1.7900 source_domain_loss: 0.7622 target_domain_loss: 0.6297 grl_lambda: 0.050\n",
      "[1] class loss: 1.0884 source_domain_loss: 0.7621 target_domain_loss: 0.6297 grl_lambda: 0.050\n",
      "[1] class loss: 2.1624 source_domain_loss: 0.7612 target_domain_loss: 0.6297 grl_lambda: 0.050\n",
      "[1] class loss: 0.6149 source_domain_loss: 0.7619 target_domain_loss: 0.6306 grl_lambda: 0.050\n",
      "[1] class loss: 2.4838 source_domain_loss: 0.7596 target_domain_loss: 0.6303 grl_lambda: 0.050\n",
      "[1] class loss: 2.0498 source_domain_loss: 0.7608 target_domain_loss: 0.6287 grl_lambda: 0.050\n",
      "[1] class loss: 1.6981 source_domain_loss: 0.7642 target_domain_loss: 0.6293 grl_lambda: 0.050\n",
      "[1] class loss: 2.1550 source_domain_loss: 0.7600 target_domain_loss: 0.6266 grl_lambda: 0.050\n",
      "[1] class loss: 2.0745 source_domain_loss: 0.7606 target_domain_loss: 0.6287 grl_lambda: 0.050\n",
      "[1] class loss: 2.3148 source_domain_loss: 0.7646 target_domain_loss: 0.6318 grl_lambda: 0.050\n",
      "[1] class loss: 1.3481 source_domain_loss: 0.7595 target_domain_loss: 0.6303 grl_lambda: 0.050\n",
      "[1] class loss: 1.4810 source_domain_loss: 0.7644 target_domain_loss: 0.6266 grl_lambda: 0.050\n",
      "[1] class loss: 1.8207 source_domain_loss: 0.7594 target_domain_loss: 0.6284 grl_lambda: 0.050\n",
      "[1] class loss: 2.4388 source_domain_loss: 0.7615 target_domain_loss: 0.6306 grl_lambda: 0.050\n",
      "Epoch: 1 ||         Train_src_acc: 0.16918918918918918,         Train_tar_acc: 0.13405405405405404,         Train_loss: 0.35794988685640794\n",
      "[2] class loss: 1.2051 source_domain_loss: 0.7607 target_domain_loss: 0.6303 grl_lambda: 0.100\n",
      "[2] class loss: 2.0987 source_domain_loss: 0.7602 target_domain_loss: 0.6301 grl_lambda: 0.100\n",
      "[2] class loss: 1.8448 source_domain_loss: 0.7633 target_domain_loss: 0.6279 grl_lambda: 0.100\n",
      "[2] class loss: 2.9851 source_domain_loss: 0.7603 target_domain_loss: 0.6306 grl_lambda: 0.100\n",
      "[2] class loss: 2.1698 source_domain_loss: 0.7617 target_domain_loss: 0.6288 grl_lambda: 0.100\n",
      "[2] class loss: 1.6730 source_domain_loss: 0.7609 target_domain_loss: 0.6293 grl_lambda: 0.100\n",
      "[2] class loss: 0.7454 source_domain_loss: 0.7656 target_domain_loss: 0.6297 grl_lambda: 0.100\n",
      "[2] class loss: 1.5006 source_domain_loss: 0.7589 target_domain_loss: 0.6275 grl_lambda: 0.100\n",
      "[2] class loss: 1.6927 source_domain_loss: 0.7601 target_domain_loss: 0.6285 grl_lambda: 0.100\n",
      "[2] class loss: 1.7616 source_domain_loss: 0.7624 target_domain_loss: 0.6316 grl_lambda: 0.100\n",
      "[2] class loss: 1.5191 source_domain_loss: 0.7613 target_domain_loss: 0.6297 grl_lambda: 0.100\n",
      "[2] class loss: 1.7403 source_domain_loss: 0.7630 target_domain_loss: 0.6270 grl_lambda: 0.100\n",
      "[2] class loss: 1.0013 source_domain_loss: 0.7589 target_domain_loss: 0.6275 grl_lambda: 0.100\n",
      "[2] class loss: 1.1320 source_domain_loss: 0.7620 target_domain_loss: 0.6300 grl_lambda: 0.100\n",
      "[2] class loss: 1.5473 source_domain_loss: 0.7596 target_domain_loss: 0.6285 grl_lambda: 0.100\n",
      "[2] class loss: 1.9266 source_domain_loss: 0.7606 target_domain_loss: 0.6292 grl_lambda: 0.100\n",
      "Epoch: 2 ||         Train_src_acc: 0.1810810810810811,         Train_tar_acc: 0.14054054054054055,         Train_loss: 0.32471011835953284\n",
      "[3] class loss: 1.7469 source_domain_loss: 0.7631 target_domain_loss: 0.6301 grl_lambda: 0.149\n",
      "[3] class loss: 0.9889 source_domain_loss: 0.7622 target_domain_loss: 0.6287 grl_lambda: 0.149\n",
      "[3] class loss: 1.0641 source_domain_loss: 0.7630 target_domain_loss: 0.6284 grl_lambda: 0.149\n",
      "[3] class loss: 1.1647 source_domain_loss: 0.7623 target_domain_loss: 0.6260 grl_lambda: 0.149\n",
      "[3] class loss: 1.4156 source_domain_loss: 0.7633 target_domain_loss: 0.6273 grl_lambda: 0.149\n",
      "[3] class loss: 1.9757 source_domain_loss: 0.7625 target_domain_loss: 0.6284 grl_lambda: 0.149\n",
      "[3] class loss: 0.8888 source_domain_loss: 0.7648 target_domain_loss: 0.6283 grl_lambda: 0.149\n",
      "[3] class loss: 1.8718 source_domain_loss: 0.7588 target_domain_loss: 0.6285 grl_lambda: 0.149\n",
      "[3] class loss: 0.7140 source_domain_loss: 0.7591 target_domain_loss: 0.6269 grl_lambda: 0.149\n",
      "[3] class loss: 1.8723 source_domain_loss: 0.7604 target_domain_loss: 0.6286 grl_lambda: 0.149\n",
      "[3] class loss: 0.7155 source_domain_loss: 0.7581 target_domain_loss: 0.6271 grl_lambda: 0.149\n",
      "[3] class loss: 1.4004 source_domain_loss: 0.7630 target_domain_loss: 0.6284 grl_lambda: 0.149\n",
      "[3] class loss: 1.5172 source_domain_loss: 0.7647 target_domain_loss: 0.6271 grl_lambda: 0.149\n",
      "[3] class loss: 1.8292 source_domain_loss: 0.7627 target_domain_loss: 0.6287 grl_lambda: 0.149\n",
      "[3] class loss: 1.7819 source_domain_loss: 0.7604 target_domain_loss: 0.6293 grl_lambda: 0.149\n",
      "[3] class loss: 1.3793 source_domain_loss: 0.7622 target_domain_loss: 0.6251 grl_lambda: 0.149\n",
      "Epoch: 3 ||         Train_src_acc: 0.18972972972972973,         Train_tar_acc: 0.13891891891891892,         Train_loss: 0.2883192383009812\n",
      "[4] class loss: 1.7841 source_domain_loss: 0.7595 target_domain_loss: 0.6279 grl_lambda: 0.197\n",
      "[4] class loss: 1.2545 source_domain_loss: 0.7596 target_domain_loss: 0.6279 grl_lambda: 0.197\n",
      "[4] class loss: 1.2724 source_domain_loss: 0.7610 target_domain_loss: 0.6249 grl_lambda: 0.197\n",
      "[4] class loss: 2.1242 source_domain_loss: 0.7612 target_domain_loss: 0.6287 grl_lambda: 0.197\n",
      "[4] class loss: 0.5741 source_domain_loss: 0.7661 target_domain_loss: 0.6277 grl_lambda: 0.197\n",
      "[4] class loss: 1.1302 source_domain_loss: 0.7633 target_domain_loss: 0.6275 grl_lambda: 0.197\n",
      "[4] class loss: 1.0963 source_domain_loss: 0.7606 target_domain_loss: 0.6284 grl_lambda: 0.197\n",
      "[4] class loss: 1.1153 source_domain_loss: 0.7626 target_domain_loss: 0.6301 grl_lambda: 0.197\n",
      "[4] class loss: 1.0861 source_domain_loss: 0.7642 target_domain_loss: 0.6253 grl_lambda: 0.197\n",
      "[4] class loss: 1.4181 source_domain_loss: 0.7659 target_domain_loss: 0.6297 grl_lambda: 0.197\n",
      "[4] class loss: 1.4545 source_domain_loss: 0.7617 target_domain_loss: 0.6280 grl_lambda: 0.197\n",
      "[4] class loss: 1.3867 source_domain_loss: 0.7636 target_domain_loss: 0.6264 grl_lambda: 0.197\n",
      "[4] class loss: 1.3829 source_domain_loss: 0.7638 target_domain_loss: 0.6272 grl_lambda: 0.197\n",
      "[4] class loss: 1.2255 source_domain_loss: 0.7647 target_domain_loss: 0.6287 grl_lambda: 0.197\n",
      "[4] class loss: 1.2519 source_domain_loss: 0.7637 target_domain_loss: 0.6266 grl_lambda: 0.197\n",
      "[4] class loss: 1.2625 source_domain_loss: 0.7632 target_domain_loss: 0.6270 grl_lambda: 0.197\n",
      "Epoch: 4 ||         Train_src_acc: 0.1881081081081081,         Train_tar_acc: 0.14270270270270272,         Train_loss: 0.2753695167344192\n",
      "[5] class loss: 0.4980 source_domain_loss: 0.7616 target_domain_loss: 0.6256 grl_lambda: 0.245\n",
      "[5] class loss: 1.2486 source_domain_loss: 0.7628 target_domain_loss: 0.6263 grl_lambda: 0.245\n",
      "[5] class loss: 1.1493 source_domain_loss: 0.7616 target_domain_loss: 0.6299 grl_lambda: 0.245\n",
      "[5] class loss: 1.3884 source_domain_loss: 0.7616 target_domain_loss: 0.6274 grl_lambda: 0.245\n",
      "[5] class loss: 0.9679 source_domain_loss: 0.7637 target_domain_loss: 0.6280 grl_lambda: 0.245\n",
      "[5] class loss: 0.8123 source_domain_loss: 0.7597 target_domain_loss: 0.6285 grl_lambda: 0.245\n",
      "[5] class loss: 1.4604 source_domain_loss: 0.7626 target_domain_loss: 0.6268 grl_lambda: 0.245\n",
      "[5] class loss: 0.6211 source_domain_loss: 0.7623 target_domain_loss: 0.6332 grl_lambda: 0.245\n",
      "[5] class loss: 1.4176 source_domain_loss: 0.7618 target_domain_loss: 0.6300 grl_lambda: 0.245\n",
      "[5] class loss: 1.0572 source_domain_loss: 0.7596 target_domain_loss: 0.6299 grl_lambda: 0.245\n",
      "[5] class loss: 0.8272 source_domain_loss: 0.7609 target_domain_loss: 0.6271 grl_lambda: 0.245\n",
      "[5] class loss: 0.7726 source_domain_loss: 0.7614 target_domain_loss: 0.6285 grl_lambda: 0.245\n",
      "[5] class loss: 0.8152 source_domain_loss: 0.7612 target_domain_loss: 0.6277 grl_lambda: 0.245\n",
      "[5] class loss: 1.3535 source_domain_loss: 0.7603 target_domain_loss: 0.6285 grl_lambda: 0.245\n",
      "[5] class loss: 1.1566 source_domain_loss: 0.7572 target_domain_loss: 0.6287 grl_lambda: 0.245\n",
      "[5] class loss: 0.7924 source_domain_loss: 0.7628 target_domain_loss: 0.6262 grl_lambda: 0.245\n",
      "Epoch: 5 ||         Train_src_acc: 0.21243243243243243,         Train_tar_acc: 0.13945945945945945,         Train_loss: 0.236682358486899\n",
      "[6] class loss: 0.6819 source_domain_loss: 0.7609 target_domain_loss: 0.6293 grl_lambda: 0.291\n",
      "[6] class loss: 1.1887 source_domain_loss: 0.7633 target_domain_loss: 0.6272 grl_lambda: 0.291\n",
      "[6] class loss: 1.0969 source_domain_loss: 0.7603 target_domain_loss: 0.6303 grl_lambda: 0.291\n",
      "[6] class loss: 1.3291 source_domain_loss: 0.7595 target_domain_loss: 0.6293 grl_lambda: 0.291\n",
      "[6] class loss: 0.8816 source_domain_loss: 0.7601 target_domain_loss: 0.6274 grl_lambda: 0.291\n",
      "[6] class loss: 0.7860 source_domain_loss: 0.7604 target_domain_loss: 0.6304 grl_lambda: 0.291\n",
      "[6] class loss: 0.6851 source_domain_loss: 0.7640 target_domain_loss: 0.6286 grl_lambda: 0.291\n",
      "[6] class loss: 1.5479 source_domain_loss: 0.7639 target_domain_loss: 0.6266 grl_lambda: 0.291\n",
      "[6] class loss: 1.2179 source_domain_loss: 0.7605 target_domain_loss: 0.6265 grl_lambda: 0.291\n",
      "[6] class loss: 1.0106 source_domain_loss: 0.7597 target_domain_loss: 0.6299 grl_lambda: 0.291\n",
      "[6] class loss: 0.6195 source_domain_loss: 0.7618 target_domain_loss: 0.6294 grl_lambda: 0.291\n",
      "[6] class loss: 0.7307 source_domain_loss: 0.7630 target_domain_loss: 0.6286 grl_lambda: 0.291\n",
      "[6] class loss: 1.3410 source_domain_loss: 0.7650 target_domain_loss: 0.6294 grl_lambda: 0.291\n",
      "[6] class loss: 0.7388 source_domain_loss: 0.7582 target_domain_loss: 0.6275 grl_lambda: 0.291\n",
      "[6] class loss: 0.9390 source_domain_loss: 0.7606 target_domain_loss: 0.6305 grl_lambda: 0.291\n",
      "[6] class loss: 0.9513 source_domain_loss: 0.7603 target_domain_loss: 0.6239 grl_lambda: 0.291\n",
      "Epoch: 6 ||         Train_src_acc: 0.2091891891891892,         Train_tar_acc: 0.1491891891891892,         Train_loss: 0.23158800704725857\n",
      "[7] class loss: 1.1980 source_domain_loss: 0.7624 target_domain_loss: 0.6282 grl_lambda: 0.336\n",
      "[7] class loss: 0.8257 source_domain_loss: 0.7661 target_domain_loss: 0.6296 grl_lambda: 0.336\n",
      "[7] class loss: 0.6864 source_domain_loss: 0.7624 target_domain_loss: 0.6306 grl_lambda: 0.336\n",
      "[7] class loss: 0.5772 source_domain_loss: 0.7633 target_domain_loss: 0.6284 grl_lambda: 0.336\n",
      "[7] class loss: 1.0566 source_domain_loss: 0.7589 target_domain_loss: 0.6262 grl_lambda: 0.336\n",
      "[7] class loss: 0.7303 source_domain_loss: 0.7630 target_domain_loss: 0.6285 grl_lambda: 0.336\n",
      "[7] class loss: 0.3549 source_domain_loss: 0.7645 target_domain_loss: 0.6300 grl_lambda: 0.336\n",
      "[7] class loss: 0.4662 source_domain_loss: 0.7634 target_domain_loss: 0.6284 grl_lambda: 0.336\n",
      "[7] class loss: 0.7599 source_domain_loss: 0.7595 target_domain_loss: 0.6278 grl_lambda: 0.336\n",
      "[7] class loss: 0.7980 source_domain_loss: 0.7588 target_domain_loss: 0.6288 grl_lambda: 0.336\n",
      "[7] class loss: 1.0972 source_domain_loss: 0.7626 target_domain_loss: 0.6268 grl_lambda: 0.336\n",
      "[7] class loss: 0.9005 source_domain_loss: 0.7610 target_domain_loss: 0.6278 grl_lambda: 0.336\n",
      "[7] class loss: 1.1105 source_domain_loss: 0.7580 target_domain_loss: 0.6306 grl_lambda: 0.336\n",
      "[7] class loss: 1.5918 source_domain_loss: 0.7615 target_domain_loss: 0.6273 grl_lambda: 0.336\n",
      "[7] class loss: 0.3096 source_domain_loss: 0.7622 target_domain_loss: 0.6286 grl_lambda: 0.336\n",
      "[7] class loss: 1.1901 source_domain_loss: 0.7628 target_domain_loss: 0.6285 grl_lambda: 0.336\n",
      "Epoch: 7 ||         Train_src_acc: 0.21135135135135136,         Train_tar_acc: 0.13891891891891892,         Train_loss: 0.21358716898951038\n",
      "[8] class loss: 0.8503 source_domain_loss: 0.7612 target_domain_loss: 0.6287 grl_lambda: 0.380\n",
      "[8] class loss: 0.6668 source_domain_loss: 0.7654 target_domain_loss: 0.6270 grl_lambda: 0.380\n",
      "[8] class loss: 0.9047 source_domain_loss: 0.7601 target_domain_loss: 0.6291 grl_lambda: 0.380\n",
      "[8] class loss: 0.9576 source_domain_loss: 0.7608 target_domain_loss: 0.6273 grl_lambda: 0.380\n",
      "[8] class loss: 0.4966 source_domain_loss: 0.7642 target_domain_loss: 0.6280 grl_lambda: 0.380\n",
      "[8] class loss: 0.5084 source_domain_loss: 0.7634 target_domain_loss: 0.6303 grl_lambda: 0.380\n",
      "[8] class loss: 0.9887 source_domain_loss: 0.7591 target_domain_loss: 0.6298 grl_lambda: 0.380\n",
      "[8] class loss: 1.8959 source_domain_loss: 0.7644 target_domain_loss: 0.6289 grl_lambda: 0.380\n",
      "[8] class loss: 0.7295 source_domain_loss: 0.7635 target_domain_loss: 0.6283 grl_lambda: 0.380\n",
      "[8] class loss: 0.6968 source_domain_loss: 0.7621 target_domain_loss: 0.6302 grl_lambda: 0.380\n",
      "[8] class loss: 0.8675 source_domain_loss: 0.7598 target_domain_loss: 0.6270 grl_lambda: 0.380\n",
      "[8] class loss: 1.1194 source_domain_loss: 0.7619 target_domain_loss: 0.6294 grl_lambda: 0.380\n",
      "[8] class loss: 0.8963 source_domain_loss: 0.7633 target_domain_loss: 0.6266 grl_lambda: 0.380\n",
      "[8] class loss: 0.6983 source_domain_loss: 0.7638 target_domain_loss: 0.6296 grl_lambda: 0.380\n",
      "[8] class loss: 0.6584 source_domain_loss: 0.7608 target_domain_loss: 0.6298 grl_lambda: 0.380\n",
      "[8] class loss: 0.8613 source_domain_loss: 0.7642 target_domain_loss: 0.6250 grl_lambda: 0.380\n",
      "Epoch: 8 ||         Train_src_acc: 0.21621621621621623,         Train_tar_acc: 0.14702702702702702,         Train_loss: 0.21485432160311732\n",
      "[9] class loss: 0.6501 source_domain_loss: 0.7621 target_domain_loss: 0.6287 grl_lambda: 0.422\n",
      "[9] class loss: 1.3793 source_domain_loss: 0.7615 target_domain_loss: 0.6293 grl_lambda: 0.422\n",
      "[9] class loss: 0.7629 source_domain_loss: 0.7587 target_domain_loss: 0.6280 grl_lambda: 0.422\n",
      "[9] class loss: 0.5732 source_domain_loss: 0.7607 target_domain_loss: 0.6259 grl_lambda: 0.422\n",
      "[9] class loss: 0.8248 source_domain_loss: 0.7614 target_domain_loss: 0.6277 grl_lambda: 0.422\n",
      "[9] class loss: 0.8058 source_domain_loss: 0.7620 target_domain_loss: 0.6321 grl_lambda: 0.422\n",
      "[9] class loss: 0.5753 source_domain_loss: 0.7631 target_domain_loss: 0.6275 grl_lambda: 0.422\n",
      "[9] class loss: 0.8203 source_domain_loss: 0.7614 target_domain_loss: 0.6291 grl_lambda: 0.422\n",
      "[9] class loss: 0.7586 source_domain_loss: 0.7634 target_domain_loss: 0.6263 grl_lambda: 0.422\n",
      "[9] class loss: 0.6494 source_domain_loss: 0.7621 target_domain_loss: 0.6281 grl_lambda: 0.422\n",
      "[9] class loss: 0.8280 source_domain_loss: 0.7644 target_domain_loss: 0.6298 grl_lambda: 0.422\n",
      "[9] class loss: 0.5555 source_domain_loss: 0.7637 target_domain_loss: 0.6303 grl_lambda: 0.422\n",
      "[9] class loss: 0.8903 source_domain_loss: 0.7629 target_domain_loss: 0.6257 grl_lambda: 0.422\n",
      "[9] class loss: 0.6717 source_domain_loss: 0.7630 target_domain_loss: 0.6310 grl_lambda: 0.422\n",
      "[9] class loss: 1.1185 source_domain_loss: 0.7628 target_domain_loss: 0.6271 grl_lambda: 0.422\n",
      "[9] class loss: 0.3901 source_domain_loss: 0.7601 target_domain_loss: 0.6281 grl_lambda: 0.422\n",
      "Epoch: 9 ||         Train_src_acc: 0.22108108108108107,         Train_tar_acc: 0.13783783783783785,         Train_loss: 0.20153443361150808\n",
      "[10] class loss: 0.7505 source_domain_loss: 0.7638 target_domain_loss: 0.6281 grl_lambda: 0.462\n",
      "[10] class loss: 1.0150 source_domain_loss: 0.7606 target_domain_loss: 0.6279 grl_lambda: 0.462\n",
      "[10] class loss: 0.7032 source_domain_loss: 0.7596 target_domain_loss: 0.6278 grl_lambda: 0.462\n",
      "[10] class loss: 0.9833 source_domain_loss: 0.7604 target_domain_loss: 0.6287 grl_lambda: 0.462\n",
      "[10] class loss: 0.4768 source_domain_loss: 0.7632 target_domain_loss: 0.6278 grl_lambda: 0.462\n",
      "[10] class loss: 0.4931 source_domain_loss: 0.7613 target_domain_loss: 0.6265 grl_lambda: 0.462\n",
      "[10] class loss: 0.5844 source_domain_loss: 0.7647 target_domain_loss: 0.6286 grl_lambda: 0.462\n",
      "[10] class loss: 1.1731 source_domain_loss: 0.7638 target_domain_loss: 0.6276 grl_lambda: 0.462\n",
      "[10] class loss: 0.4789 source_domain_loss: 0.7632 target_domain_loss: 0.6278 grl_lambda: 0.462\n",
      "[10] class loss: 0.8563 source_domain_loss: 0.7607 target_domain_loss: 0.6271 grl_lambda: 0.462\n",
      "[10] class loss: 0.5000 source_domain_loss: 0.7622 target_domain_loss: 0.6285 grl_lambda: 0.462\n",
      "[10] class loss: 0.7317 source_domain_loss: 0.7641 target_domain_loss: 0.6289 grl_lambda: 0.462\n",
      "[10] class loss: 0.7600 source_domain_loss: 0.7612 target_domain_loss: 0.6292 grl_lambda: 0.462\n",
      "[10] class loss: 0.8417 source_domain_loss: 0.7639 target_domain_loss: 0.6317 grl_lambda: 0.462\n",
      "[10] class loss: 0.8112 source_domain_loss: 0.7630 target_domain_loss: 0.6284 grl_lambda: 0.462\n",
      "[10] class loss: 0.9312 source_domain_loss: 0.7625 target_domain_loss: 0.6281 grl_lambda: 0.462\n",
      "Epoch: 10 ||         Train_src_acc: 0.22324324324324324,         Train_tar_acc: 0.1362162162162162,         Train_loss: 0.2001367581301722\n",
      "[11] class loss: 0.6549 source_domain_loss: 0.7647 target_domain_loss: 0.6272 grl_lambda: 0.501\n",
      "[11] class loss: 0.7341 source_domain_loss: 0.7618 target_domain_loss: 0.6281 grl_lambda: 0.501\n",
      "[11] class loss: 1.0895 source_domain_loss: 0.7610 target_domain_loss: 0.6265 grl_lambda: 0.501\n",
      "[11] class loss: 0.7301 source_domain_loss: 0.7625 target_domain_loss: 0.6261 grl_lambda: 0.501\n",
      "[11] class loss: 0.6703 source_domain_loss: 0.7654 target_domain_loss: 0.6295 grl_lambda: 0.501\n",
      "[11] class loss: 1.0735 source_domain_loss: 0.7637 target_domain_loss: 0.6274 grl_lambda: 0.501\n",
      "[11] class loss: 0.6610 source_domain_loss: 0.7620 target_domain_loss: 0.6280 grl_lambda: 0.501\n",
      "[11] class loss: 1.0775 source_domain_loss: 0.7649 target_domain_loss: 0.6288 grl_lambda: 0.501\n",
      "[11] class loss: 0.7078 source_domain_loss: 0.7613 target_domain_loss: 0.6301 grl_lambda: 0.501\n",
      "[11] class loss: 0.6552 source_domain_loss: 0.7622 target_domain_loss: 0.6301 grl_lambda: 0.501\n",
      "[11] class loss: 0.6965 source_domain_loss: 0.7611 target_domain_loss: 0.6286 grl_lambda: 0.501\n",
      "[11] class loss: 0.3859 source_domain_loss: 0.7611 target_domain_loss: 0.6299 grl_lambda: 0.501\n",
      "[11] class loss: 0.8089 source_domain_loss: 0.7631 target_domain_loss: 0.6284 grl_lambda: 0.501\n",
      "[11] class loss: 0.5542 source_domain_loss: 0.7609 target_domain_loss: 0.6331 grl_lambda: 0.501\n",
      "[11] class loss: 1.0872 source_domain_loss: 0.7609 target_domain_loss: 0.6268 grl_lambda: 0.501\n",
      "[11] class loss: 0.4875 source_domain_loss: 0.7609 target_domain_loss: 0.6273 grl_lambda: 0.501\n",
      "Epoch: 11 ||         Train_src_acc: 0.22486486486486487,         Train_tar_acc: 0.1464864864864865,         Train_loss: 0.20000636063773056\n",
      "[12] class loss: 0.5890 source_domain_loss: 0.7608 target_domain_loss: 0.6274 grl_lambda: 0.537\n",
      "[12] class loss: 0.4420 source_domain_loss: 0.7586 target_domain_loss: 0.6291 grl_lambda: 0.537\n",
      "[12] class loss: 0.9356 source_domain_loss: 0.7593 target_domain_loss: 0.6287 grl_lambda: 0.537\n",
      "[12] class loss: 0.6383 source_domain_loss: 0.7636 target_domain_loss: 0.6254 grl_lambda: 0.537\n",
      "[12] class loss: 0.9078 source_domain_loss: 0.7644 target_domain_loss: 0.6278 grl_lambda: 0.537\n",
      "[12] class loss: 1.0301 source_domain_loss: 0.7610 target_domain_loss: 0.6298 grl_lambda: 0.537\n",
      "[12] class loss: 0.8028 source_domain_loss: 0.7620 target_domain_loss: 0.6283 grl_lambda: 0.537\n",
      "[12] class loss: 0.6541 source_domain_loss: 0.7580 target_domain_loss: 0.6318 grl_lambda: 0.537\n",
      "[12] class loss: 0.6097 source_domain_loss: 0.7602 target_domain_loss: 0.6298 grl_lambda: 0.537\n",
      "[12] class loss: 0.4841 source_domain_loss: 0.7614 target_domain_loss: 0.6280 grl_lambda: 0.537\n",
      "[12] class loss: 0.6582 source_domain_loss: 0.7604 target_domain_loss: 0.6298 grl_lambda: 0.537\n",
      "[12] class loss: 0.4138 source_domain_loss: 0.7614 target_domain_loss: 0.6288 grl_lambda: 0.537\n",
      "[12] class loss: 0.6934 source_domain_loss: 0.7650 target_domain_loss: 0.6290 grl_lambda: 0.537\n",
      "[12] class loss: 0.7062 source_domain_loss: 0.7610 target_domain_loss: 0.6275 grl_lambda: 0.537\n",
      "[12] class loss: 0.4434 source_domain_loss: 0.7616 target_domain_loss: 0.6314 grl_lambda: 0.537\n",
      "[12] class loss: 0.5946 source_domain_loss: 0.7645 target_domain_loss: 0.6276 grl_lambda: 0.537\n",
      "Epoch: 12 ||         Train_src_acc: 0.23189189189189188,         Train_tar_acc: 0.14270270270270272,         Train_loss: 0.18728083680415974\n",
      "[13] class loss: 0.7730 source_domain_loss: 0.7673 target_domain_loss: 0.6299 grl_lambda: 0.572\n",
      "[13] class loss: 0.6365 source_domain_loss: 0.7601 target_domain_loss: 0.6278 grl_lambda: 0.572\n",
      "[13] class loss: 1.0137 source_domain_loss: 0.7635 target_domain_loss: 0.6280 grl_lambda: 0.572\n",
      "[13] class loss: 0.8045 source_domain_loss: 0.7629 target_domain_loss: 0.6318 grl_lambda: 0.572\n",
      "[13] class loss: 0.3473 source_domain_loss: 0.7591 target_domain_loss: 0.6262 grl_lambda: 0.572\n",
      "[13] class loss: 0.3615 source_domain_loss: 0.7611 target_domain_loss: 0.6282 grl_lambda: 0.572\n",
      "[13] class loss: 0.2914 source_domain_loss: 0.7611 target_domain_loss: 0.6286 grl_lambda: 0.572\n",
      "[13] class loss: 0.6743 source_domain_loss: 0.7603 target_domain_loss: 0.6305 grl_lambda: 0.572\n",
      "[13] class loss: 0.5748 source_domain_loss: 0.7651 target_domain_loss: 0.6270 grl_lambda: 0.572\n",
      "[13] class loss: 0.6609 source_domain_loss: 0.7603 target_domain_loss: 0.6277 grl_lambda: 0.572\n",
      "[13] class loss: 0.5251 source_domain_loss: 0.7616 target_domain_loss: 0.6261 grl_lambda: 0.572\n",
      "[13] class loss: 0.3936 source_domain_loss: 0.7595 target_domain_loss: 0.6295 grl_lambda: 0.572\n",
      "[13] class loss: 0.6290 source_domain_loss: 0.7590 target_domain_loss: 0.6285 grl_lambda: 0.572\n",
      "[13] class loss: 0.7539 source_domain_loss: 0.7612 target_domain_loss: 0.6316 grl_lambda: 0.572\n",
      "[13] class loss: 0.4309 source_domain_loss: 0.7640 target_domain_loss: 0.6305 grl_lambda: 0.572\n",
      "[13] class loss: 0.5518 source_domain_loss: 0.7627 target_domain_loss: 0.6281 grl_lambda: 0.572\n",
      "Epoch: 13 ||         Train_src_acc: 0.23513513513513515,         Train_tar_acc: 0.1437837837837838,         Train_loss: 0.1771256990473846\n",
      "[14] class loss: 0.6691 source_domain_loss: 0.7608 target_domain_loss: 0.6294 grl_lambda: 0.604\n",
      "[14] class loss: 0.3820 source_domain_loss: 0.7602 target_domain_loss: 0.6306 grl_lambda: 0.604\n",
      "[14] class loss: 0.6036 source_domain_loss: 0.7650 target_domain_loss: 0.6268 grl_lambda: 0.604\n",
      "[14] class loss: 0.8064 source_domain_loss: 0.7600 target_domain_loss: 0.6308 grl_lambda: 0.604\n",
      "[14] class loss: 0.9650 source_domain_loss: 0.7630 target_domain_loss: 0.6278 grl_lambda: 0.604\n",
      "[14] class loss: 0.3428 source_domain_loss: 0.7585 target_domain_loss: 0.6279 grl_lambda: 0.604\n",
      "[14] class loss: 0.5372 source_domain_loss: 0.7609 target_domain_loss: 0.6290 grl_lambda: 0.604\n",
      "[14] class loss: 1.0580 source_domain_loss: 0.7628 target_domain_loss: 0.6281 grl_lambda: 0.604\n",
      "[14] class loss: 0.3481 source_domain_loss: 0.7586 target_domain_loss: 0.6290 grl_lambda: 0.604\n",
      "[14] class loss: 0.6964 source_domain_loss: 0.7595 target_domain_loss: 0.6270 grl_lambda: 0.604\n",
      "[14] class loss: 0.7487 source_domain_loss: 0.7578 target_domain_loss: 0.6299 grl_lambda: 0.604\n",
      "[14] class loss: 0.4210 source_domain_loss: 0.7634 target_domain_loss: 0.6292 grl_lambda: 0.604\n",
      "[14] class loss: 0.7304 source_domain_loss: 0.7639 target_domain_loss: 0.6293 grl_lambda: 0.604\n",
      "[14] class loss: 0.9122 source_domain_loss: 0.7623 target_domain_loss: 0.6292 grl_lambda: 0.604\n",
      "[14] class loss: 0.5007 source_domain_loss: 0.7632 target_domain_loss: 0.6292 grl_lambda: 0.604\n",
      "[14] class loss: 0.7190 source_domain_loss: 0.7621 target_domain_loss: 0.6320 grl_lambda: 0.604\n",
      "Epoch: 14 ||         Train_src_acc: 0.2308108108108108,         Train_tar_acc: 0.14054054054054055,         Train_loss: 0.18589882501240435\n",
      "[15] class loss: 0.3908 source_domain_loss: 0.7597 target_domain_loss: 0.6282 grl_lambda: 0.635\n",
      "[15] class loss: 0.5352 source_domain_loss: 0.7630 target_domain_loss: 0.6289 grl_lambda: 0.635\n",
      "[15] class loss: 0.7106 source_domain_loss: 0.7623 target_domain_loss: 0.6293 grl_lambda: 0.635\n",
      "[15] class loss: 0.3787 source_domain_loss: 0.7628 target_domain_loss: 0.6293 grl_lambda: 0.635\n",
      "[15] class loss: 0.4086 source_domain_loss: 0.7613 target_domain_loss: 0.6290 grl_lambda: 0.635\n",
      "[15] class loss: 0.2602 source_domain_loss: 0.7640 target_domain_loss: 0.6286 grl_lambda: 0.635\n",
      "[15] class loss: 0.7181 source_domain_loss: 0.7609 target_domain_loss: 0.6285 grl_lambda: 0.635\n",
      "[15] class loss: 0.3970 source_domain_loss: 0.7579 target_domain_loss: 0.6279 grl_lambda: 0.635\n",
      "[15] class loss: 0.4449 source_domain_loss: 0.7621 target_domain_loss: 0.6290 grl_lambda: 0.635\n",
      "[15] class loss: 0.3696 source_domain_loss: 0.7609 target_domain_loss: 0.6296 grl_lambda: 0.635\n",
      "[15] class loss: 0.5912 source_domain_loss: 0.7598 target_domain_loss: 0.6316 grl_lambda: 0.635\n",
      "[15] class loss: 0.3198 source_domain_loss: 0.7634 target_domain_loss: 0.6279 grl_lambda: 0.635\n",
      "[15] class loss: 0.5069 source_domain_loss: 0.7626 target_domain_loss: 0.6271 grl_lambda: 0.635\n",
      "[15] class loss: 0.4070 source_domain_loss: 0.7593 target_domain_loss: 0.6277 grl_lambda: 0.635\n",
      "[15] class loss: 0.1570 source_domain_loss: 0.7604 target_domain_loss: 0.6292 grl_lambda: 0.635\n",
      "[15] class loss: 0.7027 source_domain_loss: 0.7601 target_domain_loss: 0.6259 grl_lambda: 0.635\n",
      "Epoch: 15 ||         Train_src_acc: 0.2491891891891892,         Train_tar_acc: 0.1345945945945946,         Train_loss: 0.15877168651284843\n",
      "[16] class loss: 0.8645 source_domain_loss: 0.7640 target_domain_loss: 0.6305 grl_lambda: 0.664\n",
      "[16] class loss: 1.1061 source_domain_loss: 0.7598 target_domain_loss: 0.6288 grl_lambda: 0.664\n",
      "[16] class loss: 0.2498 source_domain_loss: 0.7596 target_domain_loss: 0.6285 grl_lambda: 0.664\n",
      "[16] class loss: 0.6055 source_domain_loss: 0.7619 target_domain_loss: 0.6279 grl_lambda: 0.664\n",
      "[16] class loss: 0.3305 source_domain_loss: 0.7591 target_domain_loss: 0.6273 grl_lambda: 0.664\n",
      "[16] class loss: 0.5679 source_domain_loss: 0.7593 target_domain_loss: 0.6258 grl_lambda: 0.664\n",
      "[16] class loss: 0.4080 source_domain_loss: 0.7629 target_domain_loss: 0.6310 grl_lambda: 0.664\n",
      "[16] class loss: 0.4756 source_domain_loss: 0.7630 target_domain_loss: 0.6274 grl_lambda: 0.664\n",
      "[16] class loss: 0.6515 source_domain_loss: 0.7642 target_domain_loss: 0.6285 grl_lambda: 0.664\n",
      "[16] class loss: 0.7584 source_domain_loss: 0.7623 target_domain_loss: 0.6270 grl_lambda: 0.664\n",
      "[16] class loss: 0.5123 source_domain_loss: 0.7598 target_domain_loss: 0.6304 grl_lambda: 0.664\n",
      "[16] class loss: 0.3587 source_domain_loss: 0.7605 target_domain_loss: 0.6297 grl_lambda: 0.664\n",
      "[16] class loss: 0.5447 source_domain_loss: 0.7605 target_domain_loss: 0.6300 grl_lambda: 0.664\n",
      "[16] class loss: 0.4007 source_domain_loss: 0.7626 target_domain_loss: 0.6269 grl_lambda: 0.664\n",
      "[16] class loss: 0.4701 source_domain_loss: 0.7576 target_domain_loss: 0.6280 grl_lambda: 0.664\n",
      "[16] class loss: 0.6224 source_domain_loss: 0.7600 target_domain_loss: 0.6267 grl_lambda: 0.664\n",
      "Epoch: 16 ||         Train_src_acc: 0.23891891891891892,         Train_tar_acc: 0.1345945945945946,         Train_loss: 0.17278055898074446\n",
      "[17] class loss: 0.3941 source_domain_loss: 0.7593 target_domain_loss: 0.6282 grl_lambda: 0.691\n",
      "[17] class loss: 0.3680 source_domain_loss: 0.7617 target_domain_loss: 0.6288 grl_lambda: 0.691\n",
      "[17] class loss: 0.3950 source_domain_loss: 0.7600 target_domain_loss: 0.6287 grl_lambda: 0.691\n",
      "[17] class loss: 0.6049 source_domain_loss: 0.7595 target_domain_loss: 0.6307 grl_lambda: 0.691\n",
      "[17] class loss: 0.5334 source_domain_loss: 0.7623 target_domain_loss: 0.6291 grl_lambda: 0.691\n",
      "[17] class loss: 0.6371 source_domain_loss: 0.7649 target_domain_loss: 0.6256 grl_lambda: 0.691\n",
      "[17] class loss: 0.7474 source_domain_loss: 0.7615 target_domain_loss: 0.6272 grl_lambda: 0.691\n",
      "[17] class loss: 0.6825 source_domain_loss: 0.7611 target_domain_loss: 0.6286 grl_lambda: 0.691\n",
      "[17] class loss: 0.5397 source_domain_loss: 0.7625 target_domain_loss: 0.6326 grl_lambda: 0.691\n",
      "[17] class loss: 0.3292 source_domain_loss: 0.7621 target_domain_loss: 0.6277 grl_lambda: 0.691\n",
      "[17] class loss: 0.4404 source_domain_loss: 0.7635 target_domain_loss: 0.6261 grl_lambda: 0.691\n",
      "[17] class loss: 0.8745 source_domain_loss: 0.7619 target_domain_loss: 0.6267 grl_lambda: 0.691\n",
      "[17] class loss: 0.6363 source_domain_loss: 0.7637 target_domain_loss: 0.6294 grl_lambda: 0.691\n",
      "[17] class loss: 0.5166 source_domain_loss: 0.7633 target_domain_loss: 0.6311 grl_lambda: 0.691\n",
      "[17] class loss: 0.4846 source_domain_loss: 0.7602 target_domain_loss: 0.6279 grl_lambda: 0.691\n",
      "[17] class loss: 0.2040 source_domain_loss: 0.7623 target_domain_loss: 0.6231 grl_lambda: 0.691\n",
      "Epoch: 17 ||         Train_src_acc: 0.2427027027027027,         Train_tar_acc: 0.14540540540540542,         Train_loss: 0.1681755354692196\n",
      "[18] class loss: 0.6128 source_domain_loss: 0.7616 target_domain_loss: 0.6286 grl_lambda: 0.716\n",
      "[18] class loss: 1.0696 source_domain_loss: 0.7617 target_domain_loss: 0.6247 grl_lambda: 0.716\n",
      "[18] class loss: 0.5229 source_domain_loss: 0.7607 target_domain_loss: 0.6296 grl_lambda: 0.716\n",
      "[18] class loss: 0.4335 source_domain_loss: 0.7624 target_domain_loss: 0.6281 grl_lambda: 0.716\n",
      "[18] class loss: 0.4662 source_domain_loss: 0.7629 target_domain_loss: 0.6291 grl_lambda: 0.716\n",
      "[18] class loss: 0.4841 source_domain_loss: 0.7618 target_domain_loss: 0.6258 grl_lambda: 0.716\n",
      "[18] class loss: 0.3351 source_domain_loss: 0.7616 target_domain_loss: 0.6316 grl_lambda: 0.716\n",
      "[18] class loss: 0.5981 source_domain_loss: 0.7618 target_domain_loss: 0.6264 grl_lambda: 0.716\n",
      "[18] class loss: 0.3036 source_domain_loss: 0.7636 target_domain_loss: 0.6280 grl_lambda: 0.716\n",
      "[18] class loss: 0.3916 source_domain_loss: 0.7592 target_domain_loss: 0.6296 grl_lambda: 0.716\n",
      "[18] class loss: 0.7701 source_domain_loss: 0.7599 target_domain_loss: 0.6281 grl_lambda: 0.716\n",
      "[18] class loss: 0.7841 source_domain_loss: 0.7618 target_domain_loss: 0.6301 grl_lambda: 0.716\n",
      "[18] class loss: 0.4966 source_domain_loss: 0.7621 target_domain_loss: 0.6295 grl_lambda: 0.716\n",
      "[18] class loss: 0.4402 source_domain_loss: 0.7626 target_domain_loss: 0.6273 grl_lambda: 0.716\n",
      "[18] class loss: 0.6733 source_domain_loss: 0.7626 target_domain_loss: 0.6299 grl_lambda: 0.716\n",
      "[18] class loss: 0.4360 source_domain_loss: 0.7633 target_domain_loss: 0.6289 grl_lambda: 0.716\n",
      "Epoch: 18 ||         Train_src_acc: 0.23783783783783785,         Train_tar_acc: 0.13945945945945945,         Train_loss: 0.1718977021759954\n",
      "[19] class loss: 0.3503 source_domain_loss: 0.7633 target_domain_loss: 0.6268 grl_lambda: 0.740\n",
      "[19] class loss: 0.4493 source_domain_loss: 0.7623 target_domain_loss: 0.6278 grl_lambda: 0.740\n",
      "[19] class loss: 0.7635 source_domain_loss: 0.7644 target_domain_loss: 0.6292 grl_lambda: 0.740\n",
      "[19] class loss: 0.3022 source_domain_loss: 0.7638 target_domain_loss: 0.6297 grl_lambda: 0.740\n",
      "[19] class loss: 0.5233 source_domain_loss: 0.7643 target_domain_loss: 0.6283 grl_lambda: 0.740\n",
      "[19] class loss: 0.4666 source_domain_loss: 0.7621 target_domain_loss: 0.6272 grl_lambda: 0.740\n",
      "[19] class loss: 0.2628 source_domain_loss: 0.7634 target_domain_loss: 0.6302 grl_lambda: 0.740\n",
      "[19] class loss: 0.3288 source_domain_loss: 0.7622 target_domain_loss: 0.6295 grl_lambda: 0.740\n",
      "[19] class loss: 0.2681 source_domain_loss: 0.7626 target_domain_loss: 0.6296 grl_lambda: 0.740\n",
      "[19] class loss: 0.3167 source_domain_loss: 0.7618 target_domain_loss: 0.6279 grl_lambda: 0.740\n",
      "[19] class loss: 0.6210 source_domain_loss: 0.7625 target_domain_loss: 0.6276 grl_lambda: 0.740\n",
      "[19] class loss: 0.5619 source_domain_loss: 0.7604 target_domain_loss: 0.6299 grl_lambda: 0.740\n",
      "[19] class loss: 0.3534 source_domain_loss: 0.7634 target_domain_loss: 0.6274 grl_lambda: 0.740\n",
      "[19] class loss: 0.5705 source_domain_loss: 0.7620 target_domain_loss: 0.6285 grl_lambda: 0.740\n",
      "[19] class loss: 0.4446 source_domain_loss: 0.7641 target_domain_loss: 0.6296 grl_lambda: 0.740\n",
      "[19] class loss: 0.3372 source_domain_loss: 0.7617 target_domain_loss: 0.6267 grl_lambda: 0.740\n",
      "Epoch: 19 ||         Train_src_acc: 0.2427027027027027,         Train_tar_acc: 0.12486486486486487,         Train_loss: 0.15560661975679727\n",
      "[20] class loss: 0.4601 source_domain_loss: 0.7634 target_domain_loss: 0.6286 grl_lambda: 0.762\n",
      "[20] class loss: 0.5312 source_domain_loss: 0.7623 target_domain_loss: 0.6291 grl_lambda: 0.762\n",
      "[20] class loss: 0.3106 source_domain_loss: 0.7637 target_domain_loss: 0.6273 grl_lambda: 0.762\n",
      "[20] class loss: 0.1154 source_domain_loss: 0.7621 target_domain_loss: 0.6246 grl_lambda: 0.762\n",
      "[20] class loss: 0.4893 source_domain_loss: 0.7623 target_domain_loss: 0.6277 grl_lambda: 0.762\n",
      "[20] class loss: 0.6507 source_domain_loss: 0.7630 target_domain_loss: 0.6271 grl_lambda: 0.762\n",
      "[20] class loss: 0.8304 source_domain_loss: 0.7658 target_domain_loss: 0.6308 grl_lambda: 0.762\n",
      "[20] class loss: 0.3928 source_domain_loss: 0.7631 target_domain_loss: 0.6290 grl_lambda: 0.762\n",
      "[20] class loss: 0.4640 source_domain_loss: 0.7635 target_domain_loss: 0.6273 grl_lambda: 0.762\n",
      "[20] class loss: 0.2305 source_domain_loss: 0.7613 target_domain_loss: 0.6278 grl_lambda: 0.762\n",
      "[20] class loss: 0.2107 source_domain_loss: 0.7639 target_domain_loss: 0.6271 grl_lambda: 0.762\n",
      "[20] class loss: 0.3288 source_domain_loss: 0.7632 target_domain_loss: 0.6287 grl_lambda: 0.762\n",
      "[20] class loss: 0.5253 source_domain_loss: 0.7598 target_domain_loss: 0.6274 grl_lambda: 0.762\n",
      "[20] class loss: 0.4142 source_domain_loss: 0.7585 target_domain_loss: 0.6288 grl_lambda: 0.762\n",
      "[20] class loss: 0.6120 source_domain_loss: 0.7629 target_domain_loss: 0.6277 grl_lambda: 0.762\n",
      "[20] class loss: 0.5066 source_domain_loss: 0.7633 target_domain_loss: 0.6276 grl_lambda: 0.762\n",
      "Epoch: 20 ||         Train_src_acc: 0.24432432432432433,         Train_tar_acc: 0.13513513513513514,         Train_loss: 0.15686948134981352\n",
      "[21] class loss: 0.1297 source_domain_loss: 0.7631 target_domain_loss: 0.6289 grl_lambda: 0.782\n",
      "[21] class loss: 0.4790 source_domain_loss: 0.7621 target_domain_loss: 0.6280 grl_lambda: 0.782\n",
      "[21] class loss: 0.3242 source_domain_loss: 0.7619 target_domain_loss: 0.6256 grl_lambda: 0.782\n",
      "[21] class loss: 0.6178 source_domain_loss: 0.7660 target_domain_loss: 0.6300 grl_lambda: 0.782\n",
      "[21] class loss: 0.4051 source_domain_loss: 0.7615 target_domain_loss: 0.6287 grl_lambda: 0.782\n",
      "[21] class loss: 0.2797 source_domain_loss: 0.7622 target_domain_loss: 0.6290 grl_lambda: 0.782\n",
      "[21] class loss: 0.4647 source_domain_loss: 0.7628 target_domain_loss: 0.6303 grl_lambda: 0.782\n",
      "[21] class loss: 0.3697 source_domain_loss: 0.7626 target_domain_loss: 0.6258 grl_lambda: 0.782\n",
      "[21] class loss: 0.8426 source_domain_loss: 0.7622 target_domain_loss: 0.6273 grl_lambda: 0.782\n",
      "[21] class loss: 0.2281 source_domain_loss: 0.7626 target_domain_loss: 0.6274 grl_lambda: 0.782\n",
      "[21] class loss: 0.6221 source_domain_loss: 0.7633 target_domain_loss: 0.6260 grl_lambda: 0.782\n",
      "[21] class loss: 0.3900 source_domain_loss: 0.7662 target_domain_loss: 0.6291 grl_lambda: 0.782\n",
      "[21] class loss: 0.5126 source_domain_loss: 0.7651 target_domain_loss: 0.6275 grl_lambda: 0.782\n",
      "[21] class loss: 0.6385 source_domain_loss: 0.7650 target_domain_loss: 0.6269 grl_lambda: 0.782\n",
      "[21] class loss: 0.4461 source_domain_loss: 0.7613 target_domain_loss: 0.6286 grl_lambda: 0.782\n",
      "[21] class loss: 0.4724 source_domain_loss: 0.7669 target_domain_loss: 0.6294 grl_lambda: 0.782\n",
      "Epoch: 21 ||         Train_src_acc: 0.24162162162162162,         Train_tar_acc: 0.1318918918918919,         Train_loss: 0.15822297951270795\n",
      "[22] class loss: 0.2034 source_domain_loss: 0.7656 target_domain_loss: 0.6251 grl_lambda: 0.800\n",
      "[22] class loss: 0.2586 source_domain_loss: 0.7602 target_domain_loss: 0.6284 grl_lambda: 0.800\n",
      "[22] class loss: 0.1873 source_domain_loss: 0.7628 target_domain_loss: 0.6250 grl_lambda: 0.800\n",
      "[22] class loss: 0.5655 source_domain_loss: 0.7648 target_domain_loss: 0.6286 grl_lambda: 0.800\n",
      "[22] class loss: 0.4258 source_domain_loss: 0.7604 target_domain_loss: 0.6275 grl_lambda: 0.800\n",
      "[22] class loss: 0.4225 source_domain_loss: 0.7619 target_domain_loss: 0.6287 grl_lambda: 0.800\n",
      "[22] class loss: 0.5569 source_domain_loss: 0.7633 target_domain_loss: 0.6275 grl_lambda: 0.800\n",
      "[22] class loss: 0.4990 source_domain_loss: 0.7648 target_domain_loss: 0.6255 grl_lambda: 0.800\n",
      "[22] class loss: 0.3037 source_domain_loss: 0.7638 target_domain_loss: 0.6292 grl_lambda: 0.800\n",
      "[22] class loss: 0.3274 source_domain_loss: 0.7621 target_domain_loss: 0.6269 grl_lambda: 0.800\n",
      "[22] class loss: 0.2200 source_domain_loss: 0.7648 target_domain_loss: 0.6263 grl_lambda: 0.800\n",
      "[22] class loss: 0.7482 source_domain_loss: 0.7642 target_domain_loss: 0.6261 grl_lambda: 0.800\n",
      "[22] class loss: 0.3777 source_domain_loss: 0.7639 target_domain_loss: 0.6295 grl_lambda: 0.800\n",
      "[22] class loss: 0.4824 source_domain_loss: 0.7640 target_domain_loss: 0.6304 grl_lambda: 0.800\n",
      "[22] class loss: 0.4224 source_domain_loss: 0.7635 target_domain_loss: 0.6266 grl_lambda: 0.800\n",
      "[22] class loss: 0.4048 source_domain_loss: 0.7664 target_domain_loss: 0.6251 grl_lambda: 0.800\n",
      "Epoch: 22 ||         Train_src_acc: 0.252972972972973,         Train_tar_acc: 0.13243243243243244,         Train_loss: 0.15113922080089306\n",
      "[23] class loss: 0.1414 source_domain_loss: 0.7633 target_domain_loss: 0.6271 grl_lambda: 0.818\n",
      "[23] class loss: 0.2400 source_domain_loss: 0.7631 target_domain_loss: 0.6269 grl_lambda: 0.818\n",
      "[23] class loss: 0.4441 source_domain_loss: 0.7641 target_domain_loss: 0.6257 grl_lambda: 0.818\n",
      "[23] class loss: 0.1503 source_domain_loss: 0.7647 target_domain_loss: 0.6278 grl_lambda: 0.818\n",
      "[23] class loss: 0.3147 source_domain_loss: 0.7650 target_domain_loss: 0.6262 grl_lambda: 0.818\n",
      "[23] class loss: 0.5796 source_domain_loss: 0.7648 target_domain_loss: 0.6296 grl_lambda: 0.818\n",
      "[23] class loss: 0.2003 source_domain_loss: 0.7633 target_domain_loss: 0.6272 grl_lambda: 0.818\n",
      "[23] class loss: 0.2133 source_domain_loss: 0.7642 target_domain_loss: 0.6303 grl_lambda: 0.818\n",
      "[23] class loss: 0.9081 source_domain_loss: 0.7640 target_domain_loss: 0.6260 grl_lambda: 0.818\n",
      "[23] class loss: 0.5283 source_domain_loss: 0.7648 target_domain_loss: 0.6267 grl_lambda: 0.818\n",
      "[23] class loss: 0.2571 source_domain_loss: 0.7642 target_domain_loss: 0.6280 grl_lambda: 0.818\n",
      "[23] class loss: 0.1607 source_domain_loss: 0.7618 target_domain_loss: 0.6276 grl_lambda: 0.818\n",
      "[23] class loss: 0.2348 source_domain_loss: 0.7632 target_domain_loss: 0.6271 grl_lambda: 0.818\n",
      "[23] class loss: 0.2312 source_domain_loss: 0.7624 target_domain_loss: 0.6274 grl_lambda: 0.818\n",
      "[23] class loss: 0.5087 source_domain_loss: 0.7644 target_domain_loss: 0.6297 grl_lambda: 0.818\n",
      "[23] class loss: 0.5368 source_domain_loss: 0.7616 target_domain_loss: 0.6259 grl_lambda: 0.818\n",
      "Epoch: 23 ||         Train_src_acc: 0.25513513513513514,         Train_tar_acc: 0.12972972972972974,         Train_loss: 0.1446435297357625\n",
      "[24] class loss: 0.5875 source_domain_loss: 0.7635 target_domain_loss: 0.6284 grl_lambda: 0.834\n",
      "[24] class loss: 0.4056 source_domain_loss: 0.7659 target_domain_loss: 0.6284 grl_lambda: 0.834\n",
      "[24] class loss: 0.1221 source_domain_loss: 0.7656 target_domain_loss: 0.6251 grl_lambda: 0.834\n",
      "[24] class loss: 0.3321 source_domain_loss: 0.7656 target_domain_loss: 0.6289 grl_lambda: 0.834\n",
      "[24] class loss: 0.3312 source_domain_loss: 0.7644 target_domain_loss: 0.6245 grl_lambda: 0.834\n",
      "[24] class loss: 0.1980 source_domain_loss: 0.7615 target_domain_loss: 0.6303 grl_lambda: 0.834\n",
      "[24] class loss: 0.3351 source_domain_loss: 0.7655 target_domain_loss: 0.6282 grl_lambda: 0.834\n",
      "[24] class loss: 0.4969 source_domain_loss: 0.7629 target_domain_loss: 0.6268 grl_lambda: 0.834\n",
      "[24] class loss: 0.3464 source_domain_loss: 0.7643 target_domain_loss: 0.6288 grl_lambda: 0.834\n",
      "[24] class loss: 0.7816 source_domain_loss: 0.7653 target_domain_loss: 0.6261 grl_lambda: 0.834\n",
      "[24] class loss: 0.3024 source_domain_loss: 0.7627 target_domain_loss: 0.6291 grl_lambda: 0.834\n",
      "[24] class loss: 0.1092 source_domain_loss: 0.7622 target_domain_loss: 0.6283 grl_lambda: 0.834\n",
      "[24] class loss: 0.3227 source_domain_loss: 0.7618 target_domain_loss: 0.6285 grl_lambda: 0.834\n",
      "[24] class loss: 0.2542 source_domain_loss: 0.7659 target_domain_loss: 0.6302 grl_lambda: 0.834\n",
      "[24] class loss: 0.2604 source_domain_loss: 0.7631 target_domain_loss: 0.6250 grl_lambda: 0.834\n",
      "[24] class loss: 0.2493 source_domain_loss: 0.7610 target_domain_loss: 0.6251 grl_lambda: 0.834\n",
      "Epoch: 24 ||         Train_src_acc: 0.25891891891891894,         Train_tar_acc: 0.1318918918918919,         Train_loss: 0.1428124000286234\n",
      "[25] class loss: 0.5348 source_domain_loss: 0.7650 target_domain_loss: 0.6282 grl_lambda: 0.848\n",
      "[25] class loss: 0.3808 source_domain_loss: 0.7634 target_domain_loss: 0.6270 grl_lambda: 0.848\n",
      "[25] class loss: 0.4346 source_domain_loss: 0.7642 target_domain_loss: 0.6271 grl_lambda: 0.848\n",
      "[25] class loss: 0.5998 source_domain_loss: 0.7632 target_domain_loss: 0.6270 grl_lambda: 0.848\n",
      "[25] class loss: 0.4160 source_domain_loss: 0.7624 target_domain_loss: 0.6273 grl_lambda: 0.848\n",
      "[25] class loss: 0.6218 source_domain_loss: 0.7631 target_domain_loss: 0.6310 grl_lambda: 0.848\n",
      "[25] class loss: 0.2979 source_domain_loss: 0.7634 target_domain_loss: 0.6278 grl_lambda: 0.848\n",
      "[25] class loss: 0.0484 source_domain_loss: 0.7608 target_domain_loss: 0.6267 grl_lambda: 0.848\n",
      "[25] class loss: 0.0837 source_domain_loss: 0.7654 target_domain_loss: 0.6250 grl_lambda: 0.848\n",
      "[25] class loss: 0.3012 source_domain_loss: 0.7643 target_domain_loss: 0.6256 grl_lambda: 0.848\n",
      "[25] class loss: 0.3464 source_domain_loss: 0.7652 target_domain_loss: 0.6267 grl_lambda: 0.848\n",
      "[25] class loss: 0.1926 source_domain_loss: 0.7623 target_domain_loss: 0.6257 grl_lambda: 0.848\n",
      "[25] class loss: 0.1973 source_domain_loss: 0.7616 target_domain_loss: 0.6274 grl_lambda: 0.848\n",
      "[25] class loss: 0.3345 source_domain_loss: 0.7672 target_domain_loss: 0.6264 grl_lambda: 0.848\n",
      "[25] class loss: 0.1729 source_domain_loss: 0.7640 target_domain_loss: 0.6252 grl_lambda: 0.848\n",
      "[25] class loss: 0.2421 source_domain_loss: 0.7669 target_domain_loss: 0.6294 grl_lambda: 0.848\n",
      "Epoch: 25 ||         Train_src_acc: 0.2562162162162162,         Train_tar_acc: 0.13675675675675675,         Train_loss: 0.14080019192448978\n",
      "[26] class loss: 0.5390 source_domain_loss: 0.7621 target_domain_loss: 0.6293 grl_lambda: 0.862\n",
      "[26] class loss: 0.1899 source_domain_loss: 0.7606 target_domain_loss: 0.6264 grl_lambda: 0.862\n",
      "[26] class loss: 0.3034 source_domain_loss: 0.7653 target_domain_loss: 0.6298 grl_lambda: 0.862\n",
      "[26] class loss: 0.2677 source_domain_loss: 0.7642 target_domain_loss: 0.6235 grl_lambda: 0.862\n",
      "[26] class loss: 0.1969 source_domain_loss: 0.7654 target_domain_loss: 0.6241 grl_lambda: 0.862\n",
      "[26] class loss: 0.4345 source_domain_loss: 0.7680 target_domain_loss: 0.6290 grl_lambda: 0.862\n",
      "[26] class loss: 0.4227 source_domain_loss: 0.7636 target_domain_loss: 0.6270 grl_lambda: 0.862\n",
      "[26] class loss: 0.1915 source_domain_loss: 0.7638 target_domain_loss: 0.6272 grl_lambda: 0.862\n",
      "[26] class loss: 0.4370 source_domain_loss: 0.7647 target_domain_loss: 0.6257 grl_lambda: 0.862\n",
      "[26] class loss: 0.4214 source_domain_loss: 0.7620 target_domain_loss: 0.6269 grl_lambda: 0.862\n",
      "[26] class loss: 0.4652 source_domain_loss: 0.7657 target_domain_loss: 0.6268 grl_lambda: 0.862\n",
      "[26] class loss: 1.0391 source_domain_loss: 0.7640 target_domain_loss: 0.6272 grl_lambda: 0.862\n",
      "[26] class loss: 0.3602 source_domain_loss: 0.7641 target_domain_loss: 0.6247 grl_lambda: 0.862\n",
      "[26] class loss: 0.2889 source_domain_loss: 0.7648 target_domain_loss: 0.6257 grl_lambda: 0.862\n",
      "[26] class loss: 0.1680 source_domain_loss: 0.7657 target_domain_loss: 0.6273 grl_lambda: 0.862\n",
      "[26] class loss: 0.1690 source_domain_loss: 0.7642 target_domain_loss: 0.6219 grl_lambda: 0.862\n",
      "Epoch: 26 ||         Train_src_acc: 0.25027027027027027,         Train_tar_acc: 0.13297297297297297,         Train_loss: 0.146721544450727\n",
      "[27] class loss: 0.2621 source_domain_loss: 0.7665 target_domain_loss: 0.6264 grl_lambda: 0.874\n",
      "[27] class loss: 0.1641 source_domain_loss: 0.7619 target_domain_loss: 0.6252 grl_lambda: 0.874\n",
      "[27] class loss: 0.3371 source_domain_loss: 0.7653 target_domain_loss: 0.6301 grl_lambda: 0.874\n",
      "[27] class loss: 0.3004 source_domain_loss: 0.7674 target_domain_loss: 0.6283 grl_lambda: 0.874\n",
      "[27] class loss: 0.4903 source_domain_loss: 0.7640 target_domain_loss: 0.6241 grl_lambda: 0.874\n",
      "[27] class loss: 0.1808 source_domain_loss: 0.7622 target_domain_loss: 0.6280 grl_lambda: 0.874\n",
      "[27] class loss: 0.4610 source_domain_loss: 0.7631 target_domain_loss: 0.6260 grl_lambda: 0.874\n",
      "[27] class loss: 0.3591 source_domain_loss: 0.7644 target_domain_loss: 0.6266 grl_lambda: 0.874\n",
      "[27] class loss: 0.1697 source_domain_loss: 0.7657 target_domain_loss: 0.6279 grl_lambda: 0.874\n",
      "[27] class loss: 0.3949 source_domain_loss: 0.7646 target_domain_loss: 0.6282 grl_lambda: 0.874\n",
      "[27] class loss: 0.5213 source_domain_loss: 0.7660 target_domain_loss: 0.6272 grl_lambda: 0.874\n",
      "[27] class loss: 0.1003 source_domain_loss: 0.7646 target_domain_loss: 0.6260 grl_lambda: 0.874\n",
      "[27] class loss: 0.1133 source_domain_loss: 0.7651 target_domain_loss: 0.6255 grl_lambda: 0.874\n",
      "[27] class loss: 0.2274 source_domain_loss: 0.7630 target_domain_loss: 0.6260 grl_lambda: 0.874\n",
      "[27] class loss: 0.4543 source_domain_loss: 0.7642 target_domain_loss: 0.6286 grl_lambda: 0.874\n",
      "[27] class loss: 0.4097 source_domain_loss: 0.7620 target_domain_loss: 0.6258 grl_lambda: 0.874\n",
      "Epoch: 27 ||         Train_src_acc: 0.2545945945945946,         Train_tar_acc: 0.13135135135135134,         Train_loss: 0.13858273471223898\n",
      "[28] class loss: 0.3650 source_domain_loss: 0.7646 target_domain_loss: 0.6250 grl_lambda: 0.885\n",
      "[28] class loss: 0.2126 source_domain_loss: 0.7642 target_domain_loss: 0.6269 grl_lambda: 0.885\n",
      "[28] class loss: 0.0516 source_domain_loss: 0.7633 target_domain_loss: 0.6255 grl_lambda: 0.885\n",
      "[28] class loss: 0.0906 source_domain_loss: 0.7627 target_domain_loss: 0.6289 grl_lambda: 0.885\n",
      "[28] class loss: 0.6198 source_domain_loss: 0.7655 target_domain_loss: 0.6261 grl_lambda: 0.885\n",
      "[28] class loss: 0.2301 source_domain_loss: 0.7645 target_domain_loss: 0.6272 grl_lambda: 0.885\n",
      "[28] class loss: 0.1355 source_domain_loss: 0.7673 target_domain_loss: 0.6286 grl_lambda: 0.885\n",
      "[28] class loss: 0.5896 source_domain_loss: 0.7672 target_domain_loss: 0.6273 grl_lambda: 0.885\n",
      "[28] class loss: 0.5278 source_domain_loss: 0.7643 target_domain_loss: 0.6282 grl_lambda: 0.885\n",
      "[28] class loss: 0.2037 source_domain_loss: 0.7637 target_domain_loss: 0.6288 grl_lambda: 0.885\n",
      "[28] class loss: 0.1807 source_domain_loss: 0.7656 target_domain_loss: 0.6315 grl_lambda: 0.885\n",
      "[28] class loss: 0.2837 source_domain_loss: 0.7623 target_domain_loss: 0.6237 grl_lambda: 0.885\n",
      "[28] class loss: 0.0982 source_domain_loss: 0.7654 target_domain_loss: 0.6254 grl_lambda: 0.885\n",
      "[28] class loss: 0.1833 source_domain_loss: 0.7602 target_domain_loss: 0.6284 grl_lambda: 0.885\n",
      "[28] class loss: 0.1425 source_domain_loss: 0.7639 target_domain_loss: 0.6290 grl_lambda: 0.885\n",
      "[28] class loss: 0.3965 source_domain_loss: 0.7644 target_domain_loss: 0.6252 grl_lambda: 0.885\n",
      "Epoch: 28 ||         Train_src_acc: 0.2664864864864865,         Train_tar_acc: 0.1362162162162162,         Train_loss: 0.13313240069767523\n",
      "[29] class loss: 0.4775 source_domain_loss: 0.7651 target_domain_loss: 0.6253 grl_lambda: 0.896\n",
      "[29] class loss: 0.3536 source_domain_loss: 0.7638 target_domain_loss: 0.6302 grl_lambda: 0.896\n",
      "[29] class loss: 0.3733 source_domain_loss: 0.7636 target_domain_loss: 0.6261 grl_lambda: 0.896\n",
      "[29] class loss: 0.0590 source_domain_loss: 0.7607 target_domain_loss: 0.6292 grl_lambda: 0.896\n",
      "[29] class loss: 0.2443 source_domain_loss: 0.7676 target_domain_loss: 0.6256 grl_lambda: 0.896\n",
      "[29] class loss: 0.1641 source_domain_loss: 0.7639 target_domain_loss: 0.6275 grl_lambda: 0.896\n",
      "[29] class loss: 0.1843 source_domain_loss: 0.7640 target_domain_loss: 0.6293 grl_lambda: 0.896\n",
      "[29] class loss: 0.2245 source_domain_loss: 0.7650 target_domain_loss: 0.6288 grl_lambda: 0.896\n",
      "[29] class loss: 0.1967 source_domain_loss: 0.7636 target_domain_loss: 0.6277 grl_lambda: 0.896\n",
      "[29] class loss: 0.4241 source_domain_loss: 0.7668 target_domain_loss: 0.6278 grl_lambda: 0.896\n",
      "[29] class loss: 0.2115 source_domain_loss: 0.7615 target_domain_loss: 0.6246 grl_lambda: 0.896\n",
      "[29] class loss: 0.3315 source_domain_loss: 0.7641 target_domain_loss: 0.6275 grl_lambda: 0.896\n",
      "[29] class loss: 0.1913 source_domain_loss: 0.7630 target_domain_loss: 0.6239 grl_lambda: 0.896\n",
      "[29] class loss: 0.6216 source_domain_loss: 0.7622 target_domain_loss: 0.6276 grl_lambda: 0.896\n",
      "[29] class loss: 0.3678 source_domain_loss: 0.7664 target_domain_loss: 0.6247 grl_lambda: 0.896\n",
      "[29] class loss: 0.2429 source_domain_loss: 0.7639 target_domain_loss: 0.6311 grl_lambda: 0.896\n",
      "Epoch: 29 ||         Train_src_acc: 0.26054054054054054,         Train_tar_acc: 0.12108108108108108,         Train_loss: 0.13619987255540386\n",
      "[30] class loss: 0.1223 source_domain_loss: 0.7668 target_domain_loss: 0.6255 grl_lambda: 0.905\n",
      "[30] class loss: 0.2670 source_domain_loss: 0.7638 target_domain_loss: 0.6258 grl_lambda: 0.905\n",
      "[30] class loss: 0.0558 source_domain_loss: 0.7616 target_domain_loss: 0.6253 grl_lambda: 0.905\n",
      "[30] class loss: 0.2705 source_domain_loss: 0.7658 target_domain_loss: 0.6232 grl_lambda: 0.905\n",
      "[30] class loss: 0.4111 source_domain_loss: 0.7671 target_domain_loss: 0.6288 grl_lambda: 0.905\n",
      "[30] class loss: 0.2934 source_domain_loss: 0.7618 target_domain_loss: 0.6284 grl_lambda: 0.905\n",
      "[30] class loss: 0.6136 source_domain_loss: 0.7667 target_domain_loss: 0.6288 grl_lambda: 0.905\n",
      "[30] class loss: 0.0904 source_domain_loss: 0.7648 target_domain_loss: 0.6268 grl_lambda: 0.905\n",
      "[30] class loss: 0.2664 source_domain_loss: 0.7636 target_domain_loss: 0.6306 grl_lambda: 0.905\n",
      "[30] class loss: 0.2158 source_domain_loss: 0.7660 target_domain_loss: 0.6274 grl_lambda: 0.905\n",
      "[30] class loss: 0.2943 source_domain_loss: 0.7647 target_domain_loss: 0.6300 grl_lambda: 0.905\n",
      "[30] class loss: 0.0470 source_domain_loss: 0.7640 target_domain_loss: 0.6247 grl_lambda: 0.905\n",
      "[30] class loss: 0.5419 source_domain_loss: 0.7622 target_domain_loss: 0.6286 grl_lambda: 0.905\n",
      "[30] class loss: 0.6031 source_domain_loss: 0.7668 target_domain_loss: 0.6274 grl_lambda: 0.905\n",
      "[30] class loss: 0.2077 source_domain_loss: 0.7657 target_domain_loss: 0.6261 grl_lambda: 0.905\n",
      "[30] class loss: 0.3337 source_domain_loss: 0.7658 target_domain_loss: 0.6248 grl_lambda: 0.905\n",
      "Epoch: 30 ||         Train_src_acc: 0.2632432432432432,         Train_tar_acc: 0.13297297297297297,         Train_loss: 0.13593673243604856\n",
      "[31] class loss: 0.2308 source_domain_loss: 0.7656 target_domain_loss: 0.6280 grl_lambda: 0.914\n",
      "[31] class loss: 0.2797 source_domain_loss: 0.7612 target_domain_loss: 0.6297 grl_lambda: 0.914\n",
      "[31] class loss: 0.0830 source_domain_loss: 0.7651 target_domain_loss: 0.6280 grl_lambda: 0.914\n",
      "[31] class loss: 0.2213 source_domain_loss: 0.7643 target_domain_loss: 0.6289 grl_lambda: 0.914\n",
      "[31] class loss: 0.2030 source_domain_loss: 0.7607 target_domain_loss: 0.6290 grl_lambda: 0.914\n",
      "[31] class loss: 0.2141 source_domain_loss: 0.7651 target_domain_loss: 0.6266 grl_lambda: 0.914\n",
      "[31] class loss: 0.2207 source_domain_loss: 0.7654 target_domain_loss: 0.6261 grl_lambda: 0.914\n",
      "[31] class loss: 0.4885 source_domain_loss: 0.7660 target_domain_loss: 0.6268 grl_lambda: 0.914\n",
      "[31] class loss: 0.1628 source_domain_loss: 0.7633 target_domain_loss: 0.6244 grl_lambda: 0.914\n",
      "[31] class loss: 0.1870 source_domain_loss: 0.7608 target_domain_loss: 0.6278 grl_lambda: 0.914\n",
      "[31] class loss: 0.3331 source_domain_loss: 0.7645 target_domain_loss: 0.6273 grl_lambda: 0.914\n",
      "[31] class loss: 0.1608 source_domain_loss: 0.7657 target_domain_loss: 0.6245 grl_lambda: 0.914\n",
      "[31] class loss: 0.3575 source_domain_loss: 0.7638 target_domain_loss: 0.6259 grl_lambda: 0.914\n",
      "[31] class loss: 0.3782 source_domain_loss: 0.7665 target_domain_loss: 0.6241 grl_lambda: 0.914\n",
      "[31] class loss: 0.4767 source_domain_loss: 0.7672 target_domain_loss: 0.6269 grl_lambda: 0.914\n",
      "[31] class loss: 0.3449 source_domain_loss: 0.7650 target_domain_loss: 0.6289 grl_lambda: 0.914\n",
      "Epoch: 31 ||         Train_src_acc: 0.2594594594594595,         Train_tar_acc: 0.1308108108108108,         Train_loss: 0.13339505730004148\n",
      "[32] class loss: 0.0466 source_domain_loss: 0.7640 target_domain_loss: 0.6278 grl_lambda: 0.922\n",
      "[32] class loss: 0.1734 source_domain_loss: 0.7664 target_domain_loss: 0.6279 grl_lambda: 0.922\n",
      "[32] class loss: 0.3512 source_domain_loss: 0.7656 target_domain_loss: 0.6267 grl_lambda: 0.922\n",
      "[32] class loss: 0.3381 source_domain_loss: 0.7658 target_domain_loss: 0.6245 grl_lambda: 0.922\n",
      "[32] class loss: 0.2311 source_domain_loss: 0.7659 target_domain_loss: 0.6258 grl_lambda: 0.922\n",
      "[32] class loss: 0.2517 source_domain_loss: 0.7629 target_domain_loss: 0.6298 grl_lambda: 0.922\n",
      "[32] class loss: 0.2316 source_domain_loss: 0.7635 target_domain_loss: 0.6239 grl_lambda: 0.922\n",
      "[32] class loss: 0.1779 source_domain_loss: 0.7666 target_domain_loss: 0.6258 grl_lambda: 0.922\n",
      "[32] class loss: 0.2055 source_domain_loss: 0.7642 target_domain_loss: 0.6248 grl_lambda: 0.922\n",
      "[32] class loss: 0.4872 source_domain_loss: 0.7645 target_domain_loss: 0.6239 grl_lambda: 0.922\n",
      "[32] class loss: 0.2271 source_domain_loss: 0.7644 target_domain_loss: 0.6239 grl_lambda: 0.922\n",
      "[32] class loss: 0.2586 source_domain_loss: 0.7662 target_domain_loss: 0.6240 grl_lambda: 0.922\n",
      "[32] class loss: 0.2460 source_domain_loss: 0.7644 target_domain_loss: 0.6277 grl_lambda: 0.922\n",
      "[32] class loss: 0.3463 source_domain_loss: 0.7636 target_domain_loss: 0.6257 grl_lambda: 0.922\n",
      "[32] class loss: 0.2836 source_domain_loss: 0.7689 target_domain_loss: 0.6242 grl_lambda: 0.922\n",
      "[32] class loss: 0.2744 source_domain_loss: 0.7672 target_domain_loss: 0.6283 grl_lambda: 0.922\n",
      "Epoch: 32 ||         Train_src_acc: 0.2610810810810811,         Train_tar_acc: 0.13243243243243244,         Train_loss: 0.13154889591808977\n",
      "[33] class loss: 0.2001 source_domain_loss: 0.7663 target_domain_loss: 0.6260 grl_lambda: 0.929\n",
      "[33] class loss: 0.1399 source_domain_loss: 0.7646 target_domain_loss: 0.6254 grl_lambda: 0.929\n",
      "[33] class loss: 0.2346 source_domain_loss: 0.7654 target_domain_loss: 0.6262 grl_lambda: 0.929\n",
      "[33] class loss: 0.2740 source_domain_loss: 0.7613 target_domain_loss: 0.6245 grl_lambda: 0.929\n",
      "[33] class loss: 0.1195 source_domain_loss: 0.7663 target_domain_loss: 0.6263 grl_lambda: 0.929\n",
      "[33] class loss: 0.1422 source_domain_loss: 0.7649 target_domain_loss: 0.6253 grl_lambda: 0.929\n",
      "[33] class loss: 0.1875 source_domain_loss: 0.7646 target_domain_loss: 0.6251 grl_lambda: 0.929\n",
      "[33] class loss: 0.1181 source_domain_loss: 0.7653 target_domain_loss: 0.6266 grl_lambda: 0.929\n",
      "[33] class loss: 0.2106 source_domain_loss: 0.7656 target_domain_loss: 0.6263 grl_lambda: 0.929\n",
      "[33] class loss: 0.3363 source_domain_loss: 0.7638 target_domain_loss: 0.6232 grl_lambda: 0.929\n",
      "[33] class loss: 0.0515 source_domain_loss: 0.7660 target_domain_loss: 0.6287 grl_lambda: 0.929\n",
      "[33] class loss: 0.3059 source_domain_loss: 0.7674 target_domain_loss: 0.6285 grl_lambda: 0.929\n",
      "[33] class loss: 0.5058 source_domain_loss: 0.7669 target_domain_loss: 0.6267 grl_lambda: 0.929\n",
      "[33] class loss: 0.1044 source_domain_loss: 0.7627 target_domain_loss: 0.6268 grl_lambda: 0.929\n",
      "[33] class loss: 0.2199 source_domain_loss: 0.7671 target_domain_loss: 0.6281 grl_lambda: 0.929\n",
      "[33] class loss: 0.0736 source_domain_loss: 0.7640 target_domain_loss: 0.6248 grl_lambda: 0.929\n",
      "Epoch: 33 ||         Train_src_acc: 0.26594594594594595,         Train_tar_acc: 0.1345945945945946,         Train_loss: 0.12374355001696224\n",
      "[34] class loss: 0.5795 source_domain_loss: 0.7652 target_domain_loss: 0.6255 grl_lambda: 0.935\n",
      "[34] class loss: 0.1697 source_domain_loss: 0.7639 target_domain_loss: 0.6267 grl_lambda: 0.935\n",
      "[34] class loss: 0.2259 source_domain_loss: 0.7651 target_domain_loss: 0.6256 grl_lambda: 0.935\n",
      "[34] class loss: 0.1205 source_domain_loss: 0.7669 target_domain_loss: 0.6243 grl_lambda: 0.935\n",
      "[34] class loss: 0.0745 source_domain_loss: 0.7654 target_domain_loss: 0.6258 grl_lambda: 0.935\n",
      "[34] class loss: 0.1736 source_domain_loss: 0.7669 target_domain_loss: 0.6289 grl_lambda: 0.935\n",
      "[34] class loss: 0.0936 source_domain_loss: 0.7664 target_domain_loss: 0.6260 grl_lambda: 0.935\n",
      "[34] class loss: 0.0735 source_domain_loss: 0.7657 target_domain_loss: 0.6250 grl_lambda: 0.935\n",
      "[34] class loss: 0.1397 source_domain_loss: 0.7644 target_domain_loss: 0.6255 grl_lambda: 0.935\n",
      "[34] class loss: 0.1590 source_domain_loss: 0.7679 target_domain_loss: 0.6275 grl_lambda: 0.935\n",
      "[34] class loss: 0.3840 source_domain_loss: 0.7636 target_domain_loss: 0.6261 grl_lambda: 0.935\n",
      "[34] class loss: 0.3261 source_domain_loss: 0.7679 target_domain_loss: 0.6228 grl_lambda: 0.935\n",
      "[34] class loss: 0.2656 source_domain_loss: 0.7651 target_domain_loss: 0.6256 grl_lambda: 0.935\n",
      "[34] class loss: 0.2078 source_domain_loss: 0.7653 target_domain_loss: 0.6241 grl_lambda: 0.935\n",
      "[34] class loss: 0.4477 source_domain_loss: 0.7656 target_domain_loss: 0.6290 grl_lambda: 0.935\n",
      "[34] class loss: 0.0830 source_domain_loss: 0.7697 target_domain_loss: 0.6252 grl_lambda: 0.935\n",
      "Epoch: 34 ||         Train_src_acc: 0.267027027027027,         Train_tar_acc: 0.1254054054054054,         Train_loss: 0.12636251182391725\n",
      "[35] class loss: 0.1373 source_domain_loss: 0.7666 target_domain_loss: 0.6261 grl_lambda: 0.941\n",
      "[35] class loss: 0.3862 source_domain_loss: 0.7639 target_domain_loss: 0.6275 grl_lambda: 0.941\n",
      "[35] class loss: 0.1316 source_domain_loss: 0.7664 target_domain_loss: 0.6287 grl_lambda: 0.941\n",
      "[35] class loss: 0.1580 source_domain_loss: 0.7673 target_domain_loss: 0.6242 grl_lambda: 0.941\n",
      "[35] class loss: 0.0771 source_domain_loss: 0.7635 target_domain_loss: 0.6252 grl_lambda: 0.941\n",
      "[35] class loss: 0.1937 source_domain_loss: 0.7664 target_domain_loss: 0.6256 grl_lambda: 0.941\n",
      "[35] class loss: 0.2095 source_domain_loss: 0.7676 target_domain_loss: 0.6252 grl_lambda: 0.941\n",
      "[35] class loss: 0.2888 source_domain_loss: 0.7673 target_domain_loss: 0.6239 grl_lambda: 0.941\n",
      "[35] class loss: 0.1153 source_domain_loss: 0.7630 target_domain_loss: 0.6248 grl_lambda: 0.941\n",
      "[35] class loss: 0.1272 source_domain_loss: 0.7636 target_domain_loss: 0.6244 grl_lambda: 0.941\n",
      "[35] class loss: 0.1665 source_domain_loss: 0.7659 target_domain_loss: 0.6256 grl_lambda: 0.941\n",
      "[35] class loss: 0.1806 source_domain_loss: 0.7669 target_domain_loss: 0.6243 grl_lambda: 0.941\n",
      "[35] class loss: 0.1276 source_domain_loss: 0.7669 target_domain_loss: 0.6249 grl_lambda: 0.941\n",
      "[35] class loss: 0.3573 source_domain_loss: 0.7661 target_domain_loss: 0.6258 grl_lambda: 0.941\n",
      "[35] class loss: 0.1713 source_domain_loss: 0.7658 target_domain_loss: 0.6232 grl_lambda: 0.941\n",
      "[35] class loss: 0.2014 source_domain_loss: 0.7684 target_domain_loss: 0.6296 grl_lambda: 0.941\n",
      "Epoch: 35 ||         Train_src_acc: 0.2681081081081081,         Train_tar_acc: 0.12162162162162163,         Train_loss: 0.1220848503811606\n",
      "[36] class loss: 0.6169 source_domain_loss: 0.7670 target_domain_loss: 0.6243 grl_lambda: 0.947\n",
      "[36] class loss: 0.3259 source_domain_loss: 0.7678 target_domain_loss: 0.6266 grl_lambda: 0.947\n",
      "[36] class loss: 0.0398 source_domain_loss: 0.7670 target_domain_loss: 0.6255 grl_lambda: 0.947\n",
      "[36] class loss: 0.2343 source_domain_loss: 0.7667 target_domain_loss: 0.6249 grl_lambda: 0.947\n",
      "[36] class loss: 0.1015 source_domain_loss: 0.7663 target_domain_loss: 0.6253 grl_lambda: 0.947\n",
      "[36] class loss: 0.1816 source_domain_loss: 0.7696 target_domain_loss: 0.6267 grl_lambda: 0.947\n",
      "[36] class loss: 0.2750 source_domain_loss: 0.7667 target_domain_loss: 0.6227 grl_lambda: 0.947\n",
      "[36] class loss: 0.3222 source_domain_loss: 0.7657 target_domain_loss: 0.6242 grl_lambda: 0.947\n",
      "[36] class loss: 0.3790 source_domain_loss: 0.7684 target_domain_loss: 0.6241 grl_lambda: 0.947\n",
      "[36] class loss: 0.2352 source_domain_loss: 0.7671 target_domain_loss: 0.6223 grl_lambda: 0.947\n",
      "[36] class loss: 0.2766 source_domain_loss: 0.7681 target_domain_loss: 0.6254 grl_lambda: 0.947\n",
      "[36] class loss: 0.1344 source_domain_loss: 0.7688 target_domain_loss: 0.6269 grl_lambda: 0.947\n",
      "[36] class loss: 0.2402 source_domain_loss: 0.7667 target_domain_loss: 0.6229 grl_lambda: 0.947\n",
      "[36] class loss: 0.0879 source_domain_loss: 0.7649 target_domain_loss: 0.6244 grl_lambda: 0.947\n",
      "[36] class loss: 0.1894 source_domain_loss: 0.7662 target_domain_loss: 0.6259 grl_lambda: 0.947\n",
      "[36] class loss: 0.1699 source_domain_loss: 0.7653 target_domain_loss: 0.6220 grl_lambda: 0.947\n",
      "Epoch: 36 ||         Train_src_acc: 0.2648648648648649,         Train_tar_acc: 0.1227027027027027,         Train_loss: 0.12881913883932705\n",
      "[37] class loss: 0.1274 source_domain_loss: 0.7665 target_domain_loss: 0.6279 grl_lambda: 0.952\n",
      "[37] class loss: 0.3891 source_domain_loss: 0.7697 target_domain_loss: 0.6254 grl_lambda: 0.952\n",
      "[37] class loss: 0.1073 source_domain_loss: 0.7671 target_domain_loss: 0.6260 grl_lambda: 0.952\n",
      "[37] class loss: 0.1279 source_domain_loss: 0.7673 target_domain_loss: 0.6232 grl_lambda: 0.952\n",
      "[37] class loss: 0.2358 source_domain_loss: 0.7659 target_domain_loss: 0.6254 grl_lambda: 0.952\n",
      "[37] class loss: 0.2752 source_domain_loss: 0.7695 target_domain_loss: 0.6271 grl_lambda: 0.952\n",
      "[37] class loss: 0.2078 source_domain_loss: 0.7666 target_domain_loss: 0.6255 grl_lambda: 0.952\n",
      "[37] class loss: 0.2884 source_domain_loss: 0.7672 target_domain_loss: 0.6260 grl_lambda: 0.952\n",
      "[37] class loss: 0.1647 source_domain_loss: 0.7685 target_domain_loss: 0.6231 grl_lambda: 0.952\n",
      "[37] class loss: 0.0929 source_domain_loss: 0.7686 target_domain_loss: 0.6257 grl_lambda: 0.952\n",
      "[37] class loss: 0.1548 source_domain_loss: 0.7694 target_domain_loss: 0.6201 grl_lambda: 0.952\n",
      "[37] class loss: 0.1237 source_domain_loss: 0.7680 target_domain_loss: 0.6233 grl_lambda: 0.952\n",
      "[37] class loss: 0.1778 source_domain_loss: 0.7660 target_domain_loss: 0.6256 grl_lambda: 0.952\n",
      "[37] class loss: 0.0984 source_domain_loss: 0.7637 target_domain_loss: 0.6227 grl_lambda: 0.952\n",
      "[37] class loss: 0.1558 source_domain_loss: 0.7663 target_domain_loss: 0.6241 grl_lambda: 0.952\n",
      "[37] class loss: 0.3374 source_domain_loss: 0.7685 target_domain_loss: 0.6246 grl_lambda: 0.952\n",
      "Epoch: 37 ||         Train_src_acc: 0.2681081081081081,         Train_tar_acc: 0.12702702702702703,         Train_loss: 0.1224260926246643\n",
      "[38] class loss: 0.1653 source_domain_loss: 0.7680 target_domain_loss: 0.6250 grl_lambda: 0.956\n",
      "[38] class loss: 0.1089 source_domain_loss: 0.7717 target_domain_loss: 0.6272 grl_lambda: 0.956\n",
      "[38] class loss: 0.1335 source_domain_loss: 0.7679 target_domain_loss: 0.6229 grl_lambda: 0.956\n",
      "[38] class loss: 0.0860 source_domain_loss: 0.7682 target_domain_loss: 0.6260 grl_lambda: 0.956\n",
      "[38] class loss: 0.1298 source_domain_loss: 0.7662 target_domain_loss: 0.6243 grl_lambda: 0.956\n",
      "[38] class loss: 0.1045 source_domain_loss: 0.7678 target_domain_loss: 0.6251 grl_lambda: 0.956\n",
      "[38] class loss: 0.0868 source_domain_loss: 0.7672 target_domain_loss: 0.6242 grl_lambda: 0.956\n",
      "[38] class loss: 0.2628 source_domain_loss: 0.7660 target_domain_loss: 0.6258 grl_lambda: 0.956\n",
      "[38] class loss: 0.2504 source_domain_loss: 0.7662 target_domain_loss: 0.6215 grl_lambda: 0.956\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[258], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_dann(student_model, teacher_model, domain_classifier, source_loader, target_loader, \u001b[38;5;241m100\u001b[39m, optim, criterion, criterion, alpha, temperature, checkpoint_path, device)\n",
      "Cell \u001b[0;32mIn[256], line 42\u001b[0m, in \u001b[0;36mtrain_dann\u001b[0;34m(student_model, teacher_model, domain_classifier, source_loader, target_loader, num_epochs, optimizer, criterion_class, criterion_domain, alpha, temperature, checkpoint_path, device)\u001b[0m\n\u001b[1;32m     39\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2.\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1.\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m p)) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     41\u001b[0m train_loss, train_src_correct, train_tar_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (source_data, source_labels), (target_data, target_labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(source_loader, target_loader):\n\u001b[1;32m     43\u001b[0m     source_data, source_labels \u001b[38;5;241m=\u001b[39m source_data\u001b[38;5;241m.\u001b[39mto(device), source_labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     44\u001b[0m     target_data, target_labels \u001b[38;5;241m=\u001b[39m target_data\u001b[38;5;241m.\u001b[39mto(device), target_labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/datasets/folder.py:247\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m t(img)\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/transforms.py:354\u001b[0m, in \u001b[0;36mResize.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m    347\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mresize(img, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minterpolation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mantialias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/functional.py:477\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    475\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    476\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[0;32m--> 477\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F_pil\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39mpil_interpolation)\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/transforms/_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mresize(\u001b[38;5;28mtuple\u001b[39m(size[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]), interpolation)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/Image.py:2328\u001b[0m, in \u001b[0;36mImage.resize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   2316\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2317\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2318\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce)\n\u001b[1;32m   2319\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[1;32m   2320\u001b[0m         )\n\u001b[1;32m   2321\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2322\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2323\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2324\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[1;32m   2325\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[1;32m   2326\u001b[0m         )\n\u001b[0;32m-> 2328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39mresize(size, resample, box))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dann(student_model, teacher_model, domain_classifier, source_loader, target_loader, 100, optim, criterion, criterion, alpha, temperature, checkpoint_path, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_mix(source, target, alpha=0.8):\n",
    "    \"\"\"Mixes patches from source and target images with a bias towards the source.\"\"\"\n",
    "    batch_size, _, height, width = target.size()\n",
    "    patch_size = height // 2  # Assuming we split into 2x2 patches\n",
    "\n",
    "    # Create a random mask\n",
    "    rand_mask = torch.rand(batch_size, 1, 1, 1).to(source.device)\n",
    "\n",
    "    # Use the mask to blend the images, favoring the source\n",
    "    mixed_images = (rand_mask < alpha) * source + (rand_mask >= alpha) * target\n",
    "    return mixed_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_patchmix(student_model, teacher_model, opt, loss_fn, source_loader, target_loader, epochs=10, checkpoint_path=None, device='cpu'):\n",
    "    training_logs = {\"train_loss\": [], \"train_tar_acc\": [], \"train_src_acc\": []}\n",
    "    epoch_number = 0\n",
    "    best_test_loss = float('inf')\n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    \n",
    "    for param in teacher_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if checkpoint_path:\n",
    "      if os.path.exists(checkpoint_path + 'model.pth'):\n",
    "        student_model.load_state_dict(torch.load(checkpoint_path + 'model.pth', weights_only=True, map_location=device))\n",
    "\n",
    "      if os.path.exists(checkpoint_path + 'opt.pth'):\n",
    "        opt.load_state_dict(torch.load(checkpoint_path + 'opt.pth', weights_only=True, map_location=device))\n",
    "\n",
    "      if os.path.exists(checkpoint_path + 'training_logs.pth'):\n",
    "        training_logs = torch.load(checkpoint_path + 'training_logs.pth', weights_only=True)\n",
    "        epoch_number = len(training_logs['train_loss'])\n",
    "        best_test_loss = min(best_test_loss, min(training_logs['validate_loss']))\n",
    "\n",
    "    for i in range(epoch_number):\n",
    "        print(f\"Epochs {i+1}\".ljust(10), end='')\n",
    "        for k, v in training_logs.items():\n",
    "            print(f\"{k}: {v[i]:.5f}\", end=\" \")\n",
    "        print()\n",
    "\n",
    "    print(\"🤖Training on\", device)\n",
    "    for epoch in range(epoch_number, epochs):\n",
    "\n",
    "        student_model.train()\n",
    "        train_loss, train_src_correct, train_tar_correct = 0, 0, 0\n",
    "        for (source_images, source_labels), (target_images, target_labels) in zip(source_loader, target_loader):\n",
    "            source_labels = source_labels.to(device)\n",
    "            source_images = source_images.to(device)\n",
    "            target_labels = target_labels.to(device)\n",
    "            target_images = target_images.to(device)\n",
    "            mixed_images = patch_mix(source_images, target_images).to(device)\n",
    "            opt.zero_grad()\n",
    "            outputs = student_model(mixed_images)\n",
    "            loss_classification = loss_fn(outputs, source_labels)\n",
    "            loss_classification.backward()\n",
    "            opt.step()\n",
    "            train_src_correct += (outputs.argmax(1) == source_labels).float().sum().item()\n",
    "            \n",
    "            outputs = student_model(target_images)\n",
    "            train_tar_correct += (outputs.argmax(1) == target_labels).float().sum().item()\n",
    "            \n",
    "            # # Knowledge distillation loss\n",
    "            # with torch.no_grad():\n",
    "            #     teacher_output = teacher_model(source_images)\n",
    "                \n",
    "            # loss_distillation = F.kl_div(\n",
    "            #     F.log_softmax(outputs / temperature, dim=1),\n",
    "            #     F.softmax(teacher_output / temperature, dim=1),\n",
    "            #     reduction='batchmean'\n",
    "            # ) * (temperature ** 2)\n",
    "\n",
    "            # # Total loss\n",
    "            # loss = loss_classification + loss_distillation\n",
    "            loss = loss_classification\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = train_loss / len(target_loader.dataset)\n",
    "        avg_train_src_acc = train_src_correct / len(source_loader.dataset)\n",
    "        avg_train_tar_acc = train_tar_correct / len(target_loader.dataset)\n",
    "        print(f'Epoch: {epoch+1} || \\\n",
    "        Train_src_acc: {avg_train_src_acc}, \\\n",
    "        Train_tar_acc: {avg_train_tar_acc}, \\\n",
    "        Train_loss: {avg_train_loss}'\n",
    "        )\n",
    "        training_logs[\"train_loss\"].append(avg_train_loss)\n",
    "        training_logs['train_src_acc'].append(avg_train_src_acc)\n",
    "        training_logs['train_tar_acc'].append(avg_train_tar_acc)\n",
    "        # training_logs[\"train_acc\"].append(avg_train_acc)\n",
    "\n",
    "        # test_loss, test_correct = 0, 0\n",
    "        # student_model.eval()\n",
    "        # test_bar = tqdm(test_loader,desc='📄Testing',unit='batch')\n",
    "        # with torch.no_grad():\n",
    "        #   for images, label in test_bar:\n",
    "        #     images = images.to(device)\n",
    "        #     label = label.to(device)\n",
    "        #     outputs = student_model(images)\n",
    "        #     loss = loss_fn(outputs, label)\n",
    "\n",
    "        #     test_loss += loss.item()\n",
    "        #     test_correct += (outputs.argmax(1) == label).float().sum().item()\n",
    "            \n",
    "        # avg_test_loss = test_loss / len(test_loader.dataset)\n",
    "        # avg_test_acc = test_correct / len(test_loader.dataset)\n",
    "        # print(f'\\tTest loss: {avg_test_loss}')\n",
    "        # print(f'\\tTest acc: {avg_test_acc}')\n",
    "        # training_logs[\"validate_loss\"].append(avg_test_loss)\n",
    "        # training_logs[\"validate_acc\"].append(avg_test_acc)\n",
    "\n",
    "        if checkpoint_path:\n",
    "            torch.save(student_model.state_dict(), checkpoint_path + \"model.pth\")\n",
    "            torch.save(opt.state_dict(), checkpoint_path + \"opt.pth\")\n",
    "            torch.save(training_logs, checkpoint_path + 'training_logs.pth')\n",
    "            if best_test_loss > avg_train_tar_acc:\n",
    "               torch.save(student_model.state_dict(), checkpoint_path + \"best_model.pth\")\n",
    "               best_test_loss = avg_train_tar_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 8, 112, 112]             216\n",
      "       BatchNorm2d-2          [-1, 8, 112, 112]              16\n",
      "         Hardswish-3          [-1, 8, 112, 112]               0\n",
      "            Conv2d-4            [-1, 8, 56, 56]              72\n",
      "       BatchNorm2d-5            [-1, 8, 56, 56]              16\n",
      "              ReLU-6            [-1, 8, 56, 56]               0\n",
      " AdaptiveAvgPool2d-7              [-1, 8, 1, 1]               0\n",
      "            Conv2d-8              [-1, 8, 1, 1]              72\n",
      "              ReLU-9              [-1, 8, 1, 1]               0\n",
      "           Conv2d-10              [-1, 8, 1, 1]              72\n",
      "      Hardsigmoid-11              [-1, 8, 1, 1]               0\n",
      "SqueezeExcitation-12            [-1, 8, 56, 56]               0\n",
      "           Conv2d-13            [-1, 8, 56, 56]              64\n",
      "      BatchNorm2d-14            [-1, 8, 56, 56]              16\n",
      " InvertedResidual-15            [-1, 8, 56, 56]               0\n",
      "           Conv2d-16           [-1, 24, 56, 56]             192\n",
      "      BatchNorm2d-17           [-1, 24, 56, 56]              48\n",
      "             ReLU-18           [-1, 24, 56, 56]               0\n",
      "           Conv2d-19           [-1, 24, 28, 28]             216\n",
      "      BatchNorm2d-20           [-1, 24, 28, 28]              48\n",
      "             ReLU-21           [-1, 24, 28, 28]               0\n",
      "           Conv2d-22            [-1, 8, 28, 28]             192\n",
      "      BatchNorm2d-23            [-1, 8, 28, 28]              16\n",
      " InvertedResidual-24            [-1, 8, 28, 28]               0\n",
      "           Conv2d-25           [-1, 24, 28, 28]             192\n",
      "      BatchNorm2d-26           [-1, 24, 28, 28]              48\n",
      "             ReLU-27           [-1, 24, 28, 28]               0\n",
      "           Conv2d-28           [-1, 24, 28, 28]             216\n",
      "      BatchNorm2d-29           [-1, 24, 28, 28]              48\n",
      "             ReLU-30           [-1, 24, 28, 28]               0\n",
      "           Conv2d-31            [-1, 8, 28, 28]             192\n",
      "      BatchNorm2d-32            [-1, 8, 28, 28]              16\n",
      " InvertedResidual-33            [-1, 8, 28, 28]               0\n",
      "           Conv2d-34           [-1, 24, 28, 28]             192\n",
      "      BatchNorm2d-35           [-1, 24, 28, 28]              48\n",
      "        Hardswish-36           [-1, 24, 28, 28]               0\n",
      "           Conv2d-37           [-1, 24, 14, 14]             600\n",
      "      BatchNorm2d-38           [-1, 24, 14, 14]              48\n",
      "        Hardswish-39           [-1, 24, 14, 14]               0\n",
      "AdaptiveAvgPool2d-40             [-1, 24, 1, 1]               0\n",
      "           Conv2d-41              [-1, 8, 1, 1]             200\n",
      "             ReLU-42              [-1, 8, 1, 1]               0\n",
      "           Conv2d-43             [-1, 24, 1, 1]             216\n",
      "      Hardsigmoid-44             [-1, 24, 1, 1]               0\n",
      "SqueezeExcitation-45           [-1, 24, 14, 14]               0\n",
      "           Conv2d-46           [-1, 16, 14, 14]             384\n",
      "      BatchNorm2d-47           [-1, 16, 14, 14]              32\n",
      " InvertedResidual-48           [-1, 16, 14, 14]               0\n",
      "           Conv2d-49           [-1, 64, 14, 14]           1,024\n",
      "      BatchNorm2d-50           [-1, 64, 14, 14]             128\n",
      "        Hardswish-51           [-1, 64, 14, 14]               0\n",
      "           Conv2d-52           [-1, 64, 14, 14]           1,600\n",
      "      BatchNorm2d-53           [-1, 64, 14, 14]             128\n",
      "        Hardswish-54           [-1, 64, 14, 14]               0\n",
      "AdaptiveAvgPool2d-55             [-1, 64, 1, 1]               0\n",
      "           Conv2d-56             [-1, 16, 1, 1]           1,040\n",
      "             ReLU-57             [-1, 16, 1, 1]               0\n",
      "           Conv2d-58             [-1, 64, 1, 1]           1,088\n",
      "      Hardsigmoid-59             [-1, 64, 1, 1]               0\n",
      "SqueezeExcitation-60           [-1, 64, 14, 14]               0\n",
      "           Conv2d-61           [-1, 16, 14, 14]           1,024\n",
      "      BatchNorm2d-62           [-1, 16, 14, 14]              32\n",
      " InvertedResidual-63           [-1, 16, 14, 14]               0\n",
      "           Conv2d-64           [-1, 64, 14, 14]           1,024\n",
      "      BatchNorm2d-65           [-1, 64, 14, 14]             128\n",
      "        Hardswish-66           [-1, 64, 14, 14]               0\n",
      "           Conv2d-67           [-1, 64, 14, 14]           1,600\n",
      "      BatchNorm2d-68           [-1, 64, 14, 14]             128\n",
      "        Hardswish-69           [-1, 64, 14, 14]               0\n",
      "AdaptiveAvgPool2d-70             [-1, 64, 1, 1]               0\n",
      "           Conv2d-71             [-1, 16, 1, 1]           1,040\n",
      "             ReLU-72             [-1, 16, 1, 1]               0\n",
      "           Conv2d-73             [-1, 64, 1, 1]           1,088\n",
      "      Hardsigmoid-74             [-1, 64, 1, 1]               0\n",
      "SqueezeExcitation-75           [-1, 64, 14, 14]               0\n",
      "           Conv2d-76           [-1, 16, 14, 14]           1,024\n",
      "      BatchNorm2d-77           [-1, 16, 14, 14]              32\n",
      " InvertedResidual-78           [-1, 16, 14, 14]               0\n",
      "           Conv2d-79           [-1, 32, 14, 14]             512\n",
      "      BatchNorm2d-80           [-1, 32, 14, 14]              64\n",
      "        Hardswish-81           [-1, 32, 14, 14]               0\n",
      "           Conv2d-82           [-1, 32, 14, 14]             800\n",
      "      BatchNorm2d-83           [-1, 32, 14, 14]              64\n",
      "        Hardswish-84           [-1, 32, 14, 14]               0\n",
      "AdaptiveAvgPool2d-85             [-1, 32, 1, 1]               0\n",
      "           Conv2d-86              [-1, 8, 1, 1]             264\n",
      "             ReLU-87              [-1, 8, 1, 1]               0\n",
      "           Conv2d-88             [-1, 32, 1, 1]             288\n",
      "      Hardsigmoid-89             [-1, 32, 1, 1]               0\n",
      "SqueezeExcitation-90           [-1, 32, 14, 14]               0\n",
      "           Conv2d-91           [-1, 16, 14, 14]             512\n",
      "      BatchNorm2d-92           [-1, 16, 14, 14]              32\n",
      " InvertedResidual-93           [-1, 16, 14, 14]               0\n",
      "           Conv2d-94           [-1, 40, 14, 14]             640\n",
      "      BatchNorm2d-95           [-1, 40, 14, 14]              80\n",
      "        Hardswish-96           [-1, 40, 14, 14]               0\n",
      "           Conv2d-97           [-1, 40, 14, 14]           1,000\n",
      "      BatchNorm2d-98           [-1, 40, 14, 14]              80\n",
      "        Hardswish-99           [-1, 40, 14, 14]               0\n",
      "AdaptiveAvgPool2d-100             [-1, 40, 1, 1]               0\n",
      "          Conv2d-101             [-1, 16, 1, 1]             656\n",
      "            ReLU-102             [-1, 16, 1, 1]               0\n",
      "          Conv2d-103             [-1, 40, 1, 1]             680\n",
      "     Hardsigmoid-104             [-1, 40, 1, 1]               0\n",
      "SqueezeExcitation-105           [-1, 40, 14, 14]               0\n",
      "          Conv2d-106           [-1, 16, 14, 14]             640\n",
      "     BatchNorm2d-107           [-1, 16, 14, 14]              32\n",
      "InvertedResidual-108           [-1, 16, 14, 14]               0\n",
      "          Conv2d-109           [-1, 72, 14, 14]           1,152\n",
      "     BatchNorm2d-110           [-1, 72, 14, 14]             144\n",
      "       Hardswish-111           [-1, 72, 14, 14]               0\n",
      "          Conv2d-112             [-1, 72, 7, 7]           1,800\n",
      "     BatchNorm2d-113             [-1, 72, 7, 7]             144\n",
      "       Hardswish-114             [-1, 72, 7, 7]               0\n",
      "AdaptiveAvgPool2d-115             [-1, 72, 1, 1]               0\n",
      "          Conv2d-116             [-1, 24, 1, 1]           1,752\n",
      "            ReLU-117             [-1, 24, 1, 1]               0\n",
      "          Conv2d-118             [-1, 72, 1, 1]           1,800\n",
      "     Hardsigmoid-119             [-1, 72, 1, 1]               0\n",
      "SqueezeExcitation-120             [-1, 72, 7, 7]               0\n",
      "          Conv2d-121             [-1, 24, 7, 7]           1,728\n",
      "     BatchNorm2d-122             [-1, 24, 7, 7]              48\n",
      "InvertedResidual-123             [-1, 24, 7, 7]               0\n",
      "          Conv2d-124            [-1, 144, 7, 7]           3,456\n",
      "     BatchNorm2d-125            [-1, 144, 7, 7]             288\n",
      "       Hardswish-126            [-1, 144, 7, 7]               0\n",
      "          Conv2d-127            [-1, 144, 7, 7]           3,600\n",
      "     BatchNorm2d-128            [-1, 144, 7, 7]             288\n",
      "       Hardswish-129            [-1, 144, 7, 7]               0\n",
      "AdaptiveAvgPool2d-130            [-1, 144, 1, 1]               0\n",
      "          Conv2d-131             [-1, 40, 1, 1]           5,800\n",
      "            ReLU-132             [-1, 40, 1, 1]               0\n",
      "          Conv2d-133            [-1, 144, 1, 1]           5,904\n",
      "     Hardsigmoid-134            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-135            [-1, 144, 7, 7]               0\n",
      "          Conv2d-136             [-1, 24, 7, 7]           3,456\n",
      "     BatchNorm2d-137             [-1, 24, 7, 7]              48\n",
      "InvertedResidual-138             [-1, 24, 7, 7]               0\n",
      "          Conv2d-139            [-1, 144, 7, 7]           3,456\n",
      "     BatchNorm2d-140            [-1, 144, 7, 7]             288\n",
      "       Hardswish-141            [-1, 144, 7, 7]               0\n",
      "          Conv2d-142            [-1, 144, 7, 7]           3,600\n",
      "     BatchNorm2d-143            [-1, 144, 7, 7]             288\n",
      "       Hardswish-144            [-1, 144, 7, 7]               0\n",
      "AdaptiveAvgPool2d-145            [-1, 144, 1, 1]               0\n",
      "          Conv2d-146             [-1, 40, 1, 1]           5,800\n",
      "            ReLU-147             [-1, 40, 1, 1]               0\n",
      "          Conv2d-148            [-1, 144, 1, 1]           5,904\n",
      "     Hardsigmoid-149            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-150            [-1, 144, 7, 7]               0\n",
      "          Conv2d-151             [-1, 24, 7, 7]           3,456\n",
      "     BatchNorm2d-152             [-1, 24, 7, 7]              48\n",
      "InvertedResidual-153             [-1, 24, 7, 7]               0\n",
      "          Conv2d-154            [-1, 144, 7, 7]           3,456\n",
      "     BatchNorm2d-155            [-1, 144, 7, 7]             288\n",
      "       Hardswish-156            [-1, 144, 7, 7]               0\n",
      "AdaptiveAvgPool2d-157            [-1, 144, 1, 1]               0\n",
      "          Linear-158                  [-1, 256]          37,120\n",
      "       Hardswish-159                  [-1, 256]               0\n",
      "         Dropout-160                  [-1, 256]               0\n",
      "          Linear-161                   [-1, 31]           7,967\n",
      "================================================================\n",
      "Total params: 125,239\n",
      "Trainable params: 125,239\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 11.42\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 12.47\n",
      "----------------------------------------------------------------\n",
      "2817 498\n"
     ]
    }
   ],
   "source": [
    "teacher_model = mobilenet_v3_large(num_classes=NUM_CLASSES).to(device)\n",
    "teacher_model.load_state_dict(torch.load(f'{HOME}/cp/mbv3_large_ref/best_model.pth', weights_only=True))\n",
    "# summary(teacher_model, (3, 224, 224))\n",
    "student_model = mobilenet_v3_small(weights=None, width_mult=0.25, num_classes=NUM_CLASSES).to(device)\n",
    "student_model.load_state_dict(torch.load(f'{HOME}/cp/mbv3_small_reduce/best_model.pth', weights_only=True))\n",
    "# print(student_model.features)\n",
    "# print(student_model.avgpool)\n",
    "# student_model = StudentModelMBV3SmallReduce().to(device)\n",
    "summary(student_model, (3, 224, 224))\n",
    "domain_classifier = DomainClassifier()\n",
    "optim = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "print(len(amazon_dataset), len(dslr_dataset))\n",
    "\n",
    "class ExpandDataset(Dataset):\n",
    "    def __init__(self, original_dataset, required_size):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.required_size = required_size\n",
    "        self.original_size = len(original_dataset)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.required_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Select a random index from the original dataset to duplicate\n",
    "        original_idx = idx % self.original_size  # Loop around if idx exceeds original size\n",
    "        return self.original_dataset[original_idx]\n",
    "\n",
    "expanded_dataset = ExpandDataset(dslr_dataset, 2817)\n",
    "\n",
    "source_loader = DataLoader(amazon_dataset, batch_size=32, shuffle=True)\n",
    "target_loader = DataLoader(expanded_dataset, batch_size=32, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "criterion_class = nn.CrossEntropyLoss()\n",
    "criterion_distillation = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "# checkpoint_path = f'{HOME}/cp/student_patchmix/'\n",
    "# checkpoint_path = f'{HOME}/cp/patchmix/'\n",
    "checkpoint_path = f'{HOME}/cp/patchmix_pretrainedA2D/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖Training on cuda\n",
      "Epoch: 1 ||         Train_src_acc: 0.43485977990770325,         Train_tar_acc: 0.40717074902378414,         Train_loss: 0.09740737528084947\n",
      "Epoch: 2 ||         Train_src_acc: 0.5303514376996805,         Train_tar_acc: 0.40610578629747957,         Train_loss: 0.05941654368838309\n",
      "Epoch: 3 ||         Train_src_acc: 0.5818246361377352,         Train_tar_acc: 0.38161164359247424,         Train_loss: 0.04929924072591303\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[275], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train_patchmix(student_model, teacher_model, opt, loss_fn, source_loader, target_loader, test_loader, epochs=10, checkpoint_path=None, device='cpu')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_patchmix(student_model, teacher_model, optim, criterion_class, source_loader, target_loader, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, checkpoint_path\u001b[38;5;241m=\u001b[39mcheckpoint_path, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[273], line 34\u001b[0m, in \u001b[0;36mtrain_patchmix\u001b[0;34m(student_model, teacher_model, opt, loss_fn, source_loader, target_loader, epochs, checkpoint_path, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m student_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     33\u001b[0m train_loss, train_src_correct, train_tar_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (source_images, source_labels), (target_images, target_labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(source_loader, target_loader):\n\u001b[1;32m     35\u001b[0m     source_labels \u001b[38;5;241m=\u001b[39m source_labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     36\u001b[0m     source_images \u001b[38;5;241m=\u001b[39m source_images\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[274], line 27\u001b[0m, in \u001b[0;36mExpandDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Select a random index from the original dataset to duplicate\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     original_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_size  \u001b[38;5;66;03m# Loop around if idx exceeds original size\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_dataset[original_idx]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/datasets/folder.py:245\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[0;32m--> 245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/datasets/folder.py:284\u001b[0m, in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pil_loader(path)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/datasets/folder.py:264\u001b[0m, in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    263\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/Image.py:1007\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mor\u001b[39;00m (mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m matrix):\n\u001b[0;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m matrix:\n\u001b[1;32m   1010\u001b[0m     \u001b[38;5;66;03m# matrix conversion\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/Image.py:1274\u001b[0m, in \u001b[0;36mImage.copy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;124;03mCopies this image. Use this method if you wish to paste things\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;124;03minto an image, but still retain the original.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1271\u001b[0m \u001b[38;5;124;03m:returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n\u001b[0;32m-> 1274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim\u001b[38;5;241m.\u001b[39mcopy())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_patchmix(student_model, teacher_model, opt, loss_fn, source_loader, target_loader, test_loader, epochs=10, checkpoint_path=None, device='cpu')\n",
    "train_patchmix(student_model, teacher_model, optim, criterion_class, source_loader, target_loader, epochs=100, checkpoint_path=checkpoint_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.exposure import match_histograms\n",
    "\n",
    "def histogram_matching(source, target):\n",
    "    # Convert PyTorch tensors to NumPy arrays\n",
    "    source_np = source.cpu().detach().numpy()\n",
    "    target_np = target.cpu().detach().numpy()\n",
    "\n",
    "    # Initialize a list to hold matched images\n",
    "    matched_images = []\n",
    "\n",
    "    # Process each image in the batch\n",
    "    for i in range(target_np.shape[0]):\n",
    "        image = np.array(source[i].cpu()*255).astype(np.uint8).transpose(1, 2, 0)\n",
    "        ref = np.array(target[i].cpu()*255).astype(np.uint8).transpose(1, 2, 0)\n",
    "        \n",
    "        matched = torch.tensor(match_histograms(image, ref, channel_axis=-1)).permute(2, 0, 1)\n",
    "        matched_images.append(matched.unsqueeze(0))\n",
    "\n",
    "\n",
    "    # Stack matched images into a tensor\n",
    "    matched_images = torch.cat(matched_images, dim=0).to(source.device)  # Shape (B, H, W)\n",
    "\n",
    "    return matched_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 256, 256])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example for standard PyTorch images with value ranges of [0-1]\n",
    "source_loader = DataLoader(source_dataset, batch_size=16, shuffle=True)\n",
    "batch1 = next(iter(source_loader))\n",
    "batch2 = next(iter(source_loader))\n",
    "\n",
    "matched = histogram_matching(batch1[0], batch2[0])\n",
    "\n",
    "print(matched.shape)\n",
    "\n",
    "plt.imshow(matched[0].permute(1, 2, 0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchedDataset(Dataset):\n",
    "    def __init__(self, source_dataset, target_dataset, transform=None):\n",
    "        self.source_dataset = source_dataset\n",
    "        self.target_dataset = target_dataset\n",
    "        self.matched_images = []\n",
    "        self.transform =  transform\n",
    "\n",
    "        # Apply histogram matching and create matched images\n",
    "        for source_image, _ in DataLoader(source_dataset, batch_size=1):\n",
    "            for target_image, _ in DataLoader(target_dataset, batch_size=1):\n",
    "                matched_image = histogram_matching(source_image, target_image)\n",
    "                \n",
    "                if self.transform:\n",
    "                    matched_image = self.transform(matched_image)\n",
    "                    \n",
    "                self.matched_images.append(matched_image)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.matched_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.matched_images[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[239], line 22\u001b[0m\n\u001b[1;32m     18\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m DataLoader(labeled_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m source_dataset, target_dataset, test_dataset \u001b[38;5;241m=\u001b[39m random_split(labeled_dataset, [\u001b[38;5;241m1850\u001b[39m, \u001b[38;5;241m1850\u001b[39m, \u001b[38;5;241m410\u001b[39m])\n\u001b[0;32m---> 22\u001b[0m new_source_dataset \u001b[38;5;241m=\u001b[39m MatchedDataset(source_dataset, target_dataset, transform\u001b[38;5;241m=\u001b[39mtransform)\n\u001b[1;32m     23\u001b[0m new_source_loader \u001b[38;5;241m=\u001b[39m DataLoader(new_source_dataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(source_dataset), \u001b[38;5;28mlen\u001b[39m(target_dataset), \u001b[38;5;28mlen\u001b[39m(test_dataset))\n",
      "Cell \u001b[0;32mIn[238], line 11\u001b[0m, in \u001b[0;36mMatchedDataset.__init__\u001b[0;34m(self, source_dataset, target_dataset, transform)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m source_image, _ \u001b[38;5;129;01min\u001b[39;00m DataLoader(source_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m target_image, _ \u001b[38;5;129;01min\u001b[39;00m DataLoader(target_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m         matched_image \u001b[38;5;241m=\u001b[39m histogram_matching(source_image, target_image)\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     14\u001b[0m             matched_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(matched_image)\n",
      "Cell \u001b[0;32mIn[234], line 18\u001b[0m, in \u001b[0;36mhistogram_matching\u001b[0;34m(source, target)\u001b[0m\n\u001b[1;32m     15\u001b[0m     image \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(source[i]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     16\u001b[0m     ref \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(target[i]\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m255\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m     matched \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(match_histograms(image, ref, channel_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m     matched_images\u001b[38;5;241m.\u001b[39mappend(matched\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Stack matched images into a tensor\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    torchvision.models.MobileNet_V3_Small_Weights.IMAGENET1K_V1.transforms()\n",
    "])\n",
    "\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "amazon_dataset = ImageFolder(root=f'{DATASET_DIR}/amazon', transform=transform2)\n",
    "dslr_dataset = ImageFolder(root=f'{DATASET_DIR}/dslr', transform=transform2)\n",
    "webcam_dataset = ImageFolder(root=f'{DATASET_DIR}/webcam', transform=transform2)\n",
    "\n",
    "classes = webcam_dataset.classes\n",
    "\n",
    "\n",
    "new_source_dataset = MatchedDataset(amazon_dataset, dslr_dataset, transform=transform)\n",
    "new_source_loader = DataLoader(new_source_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_histogram_matching(student_model, teacher_model, opt, loss_fn, source_loader, target_loader, test_loader, epochs=10, checkpoint_path=None, device='cpu'):\n",
    "    training_logs = {\"train_loss\": [], \"validate_loss\": [], \"train_acc\": [], \"validate_acc\": []}\n",
    "    epoch_number = 0\n",
    "    best_test_loss = float('inf')\n",
    "    student_model.to(device)\n",
    "    teacher_model.to(device)\n",
    "    \n",
    "    for param in teacher_model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    if checkpoint_path:\n",
    "      if os.path.exists(checkpoint_path + 'model.pth'):\n",
    "        student_model.load_state_dict(torch.load(checkpoint_path + 'model.pth', weights_only=True, map_location=device))\n",
    "\n",
    "      if os.path.exists(checkpoint_path + 'opt.pth'):\n",
    "        opt.load_state_dict(torch.load(checkpoint_path + 'opt.pth', weights_only=True, map_location=device))\n",
    "\n",
    "      if os.path.exists(checkpoint_path + 'training_logs.pth'):\n",
    "        training_logs = torch.load(checkpoint_path + 'training_logs.pth', weights_only=True)\n",
    "        epoch_number = len(training_logs['train_loss'])\n",
    "        best_test_loss = min(best_test_loss, min(training_logs['validate_loss']))\n",
    "\n",
    "    for i in range(epoch_number):\n",
    "        print(f\"Epochs {i+1}\".ljust(10), end='')\n",
    "        for k, v in training_logs.items():\n",
    "            print(f\"{k}: {v[i]:.5f}\", end=\" \")\n",
    "        print()\n",
    "\n",
    "    print(\"🤖Training on\", device)\n",
    "    for epoch in range(epoch_number, epochs):\n",
    "\n",
    "        train_loss, train_correct = 0, 0\n",
    "        student_model.train()\n",
    "        for (source_images, source_labels), (target_images, _) in zip(source_loader, target_loader):\n",
    "            source_labels = source_labels.to(device)\n",
    "            source_images = source_images.to(device)\n",
    "            target_images = target_images.to(device)\n",
    "            opt.zero_grad()\n",
    "            outputs = student_model(source_images)\n",
    "            loss_classification = loss_fn(outputs, source_labels)\n",
    "            loss_classification.backward()\n",
    "            opt.step()\n",
    "            train_correct += (outputs.argmax(1) == source_labels).float().sum().item()\n",
    "            \n",
    "            # # Knowledge distillation loss\n",
    "            # with torch.no_grad():\n",
    "            #     teacher_output = teacher_model(source_images)\n",
    "                \n",
    "            # loss_distillation = F.kl_div(\n",
    "            #     F.log_softmax(outputs / temperature, dim=1),\n",
    "            #     F.softmax(teacher_output / temperature, dim=1),\n",
    "            #     reduction='batchmean'\n",
    "            # ) * (temperature ** 2)\n",
    "\n",
    "            # # Total loss\n",
    "            # loss = loss_classification + loss_distillation\n",
    "            loss = loss_classification\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        avg_train_acc = train_correct / len(train_loader.dataset)\n",
    "        print(f'\\n\\tTrain loss: {avg_train_loss}')\n",
    "        print(f'\\tTrain acc: {avg_train_acc}')\n",
    "        training_logs[\"train_loss\"].append(avg_train_loss)\n",
    "        training_logs[\"train_acc\"].append(avg_train_acc)\n",
    "\n",
    "        test_loss, test_correct = 0, 0\n",
    "        student_model.eval()\n",
    "        test_bar = tqdm(test_loader,desc='📄Testing',unit='batch')\n",
    "        with torch.no_grad():\n",
    "          for images, label in test_bar:\n",
    "            images = images.to(device)\n",
    "            label = label.to(device)\n",
    "            outputs = student_model(images)\n",
    "            loss = loss_fn(outputs, label)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            test_correct += (outputs.argmax(1) == label).float().sum().item()\n",
    "            \n",
    "        avg_test_loss = test_loss / len(test_loader.dataset)\n",
    "        avg_test_acc = test_correct / len(test_loader.dataset)\n",
    "        print(f'\\tTest loss: {avg_test_loss}')\n",
    "        print(f'\\tTest acc: {avg_test_acc}')\n",
    "        training_logs[\"validate_loss\"].append(avg_test_loss)\n",
    "        training_logs[\"validate_acc\"].append(avg_test_acc)\n",
    "\n",
    "        if checkpoint_path:\n",
    "            torch.save(student_model.state_dict(), checkpoint_path + \"model.pth\")\n",
    "            torch.save(opt.state_dict(), checkpoint_path + \"opt.pth\")\n",
    "            torch.save(training_logs, checkpoint_path + 'training_logs.pth')\n",
    "            if best_test_loss > avg_test_loss:\n",
    "               torch.save(student_model.state_dict(), checkpoint_path + \"best_model.pth\")\n",
    "               best_test_loss = avg_test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = mobilenet_v3_large(num_classes=NUM_CLASSES).to(device)\n",
    "teacher_model.load_state_dict(torch.load(f'{HOME}/cp/mbv3_large_ref/best_model.pth', weights_only=True))\n",
    "# summary(teacher_model, (3, 224, 224))\n",
    "student_model = mobilenet_v3_small(weights=None, width_mult=0.25, num_classes=NUM_CLASSES).to(device)\n",
    "student_model.load_state_dict(torch.load(f'{HOME}/cp/mbv3_small_reduce/best_model.pth', weights_only=True))\n",
    "# print(student_model.features)\n",
    "# print(student_model.avgpool)\n",
    "# student_model = StudentModelMBV3SmallReduce().to(device)\n",
    "# summary(student_model, (3, 224, 224))\n",
    "domain_classifier = DomainClassifier()\n",
    "optim = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
    "\n",
    "source_loader = DataLoader(source_dataset, batch_size=32, shuffle=True)\n",
    "target_loader = DataLoader(target_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# source_images = next(iter(source_loader))[0].to(device)\n",
    "# target_images = next(iter(target_loader))[0].to(device)\n",
    "# mixed_images = histogram_matching(source_images, target_images)\n",
    "# plt.imshow(mixed_images[0].permute(1, 2, 0))\n",
    "\n",
    "criterion_class = nn.CrossEntropyLoss()\n",
    "criterion_distillation = nn.KLDivLoss(reduction='batchmean')\n",
    "\n",
    "# checkpoint_path = f'{HOME}/cp/student_patchmix/'\n",
    "# checkpoint_path = f'{HOME}/cp/patchmix/'\n",
    "checkpoint_path = f'{HOME}/cp/histogram_matching_pretrained/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖Training on cuda\n",
      "\n",
      "\tTrain loss: 0.07232067759019616\n",
      "\tTrain acc: 0.07201946472019465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄Testing: 100%|██████████| 13/13 [00:01<00:00,  6.54batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest loss: 0.031124624537258613\n",
      "\tTest acc: 0.7268292682926829\n",
      "\n",
      "\tTrain loss: 0.044622421670714146\n",
      "\tTrain acc: 0.10778588807785888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄Testing: 100%|██████████| 13/13 [00:01<00:00,  8.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest loss: 0.05784065229136769\n",
      "\tTest acc: 0.4878048780487805\n",
      "\n",
      "\tTrain loss: 0.03794447955133851\n",
      "\tTrain acc: 0.13211678832116788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "📄Testing: 100%|██████████| 13/13 [00:01<00:00,  8.23batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTest loss: 0.06774614613230635\n",
      "\tTest acc: 0.3829268292682927\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[199], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train_patchmix(student_model, teacher_model, opt, loss_fn, source_loader, target_loader, test_loader, epochs=10, checkpoint_path=None, device='cpu')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_histogram_matching(student_model, teacher_model, optim, criterion_class, source_loader, target_loader, test_loader, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, checkpoint_path\u001b[38;5;241m=\u001b[39mcheckpoint_path, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "Cell \u001b[0;32mIn[197], line 34\u001b[0m, in \u001b[0;36mtrain_histogram_matching\u001b[0;34m(student_model, teacher_model, opt, loss_fn, source_loader, target_loader, test_loader, epochs, checkpoint_path, device)\u001b[0m\n\u001b[1;32m     32\u001b[0m train_loss, train_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     33\u001b[0m student_model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (source_images, source_labels), (target_images, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(source_loader, target_loader):\n\u001b[1;32m     35\u001b[0m     source_labels \u001b[38;5;241m=\u001b[39m source_labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     36\u001b[0m     source_images \u001b[38;5;241m=\u001b[39m source_images\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataset.py:350\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    349\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatasets[dataset_idx][sample_idx]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/datasets/folder.py:245\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    244\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[0;32m--> 245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader(path)\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/datasets/folder.py:284\u001b[0m, in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pil_loader(path)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torchvision/datasets/folder.py:264\u001b[0m, in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    263\u001b[0m     img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/Image.py:995\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    993\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m--> 995\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload()\n\u001b[1;32m    997\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/ImageFile.py:293\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    292\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 293\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mdecode(b)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_patchmix(student_model, teacher_model, opt, loss_fn, source_loader, target_loader, test_loader, epochs=10, checkpoint_path=None, device='cpu')\n",
    "train_histogram_matching(student_model, teacher_model, optim, criterion_class, source_loader, target_loader, test_loader, epochs=100, checkpoint_path=checkpoint_path, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
